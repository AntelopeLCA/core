{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Antelope core implementation","text":"<p>This package includes the reference version of Antelope life cycle assessment (LCA) software. Antelope simplifies the practice of LCA by creating different interfaces that handle different parts of the computational problem.</p>"},{"location":"#conceptual-overview","title":"Conceptual Overview","text":"<p>The antelope_interface declares a set of interfaces and creates a set of <code>EntityRef</code> catalog-reference classes for referring to LCA data objects. It is up to an implementation (i.e. this repo) to create working code for those objects.</p> <p>The present package provides a reference implementation for quantities, flows, and processes, which are the essential data types or \"entities\" for LCA computation.  It includes a set of providers,  which translate different data sources (ecospold and ecospold2, ILCD, OpenLCA) into antelope entities. Each provider class may include custom implementations of the different interfaces.</p> <p>implements the [quantity] interface for performing LCIA operations.  It also creates an LciaResult object that provides sophisticated capabilities  for reviewing and analyzing LCIA computations.  The core package also implements the [exchange] interface, which is </p> <p>The antelope_background package performs Tarjan  Ordering of data sources</p> <p>The antelope_foreground package provides the  ability to construct dynamic, modular life cycle models that make reference to datasets from different origins.</p> <p>Other implementations can be created independently as long as they inherit from the interface.</p>"},{"location":"code_layout/","title":"Package Layout","text":"<p>The <code>antelope_core</code> package contains a number of interdependent components. Each one is documented in the  API reference.</p> <ul> <li>entities</li> </ul>"},{"location":"entities/entities/","title":"Entities","text":"<p>               Bases: <code>BaseEntity</code></p> <p>All LC entities behave like dicts, but they all have some common properties, defined here.</p>"},{"location":"entities/entities/#antelope_core.entities.entities.LcEntity.is_entity","title":"<code>is_entity</code>  <code>property</code>","text":"<p>Used to distinguish between entities and catalog refs (which answer False)</p> <p>Returns:</p> Type Description <p>True for LcEntity subclasses</p>"},{"location":"entities/entities/#antelope_core.entities.entities.LcEntity.__eq__","title":"<code>__eq__(other)</code>","text":"<p>two entities are equal if their types, origins, and external references are the same. internal refs do not need to be equal; reference entities do not need to be equal</p> <p>Returns:</p> Type Description"},{"location":"entities/entities/#antelope_core.entities.entities.LcEntity.__hash__","title":"<code>__hash__()</code>","text":"<p>External ref is set by the end of init and is immutable (except for fragments-- which use uuid for hash)</p> <p>Returns:</p> Type Description"},{"location":"entities/entities/#antelope_core.entities.entities.LcEntity.get_properties","title":"<code>get_properties()</code>","text":"<p>dict of properties and values for a given entity</p> <p>Returns:</p> Type Description"},{"location":"entities/entities/#antelope_core.entities.entities.LcEntity.map_origin","title":"<code>map_origin(omap, fallback=None)</code>","text":"<p>This is used to propagate a change in origin semantics. Provide a dict that maps old origins to new origins. External ref should remain the same with respect to the new origin.</p> <p>Parameters:</p> Name Type Description Default <code>omap</code> <p>dict mapping old origin to new origin</p> required <code>fallback</code> <p>if present, use in cases where old origin not found</p> <code>None</code> <p>Returns:</p> Type Description"},{"location":"entities/flows/","title":"Flows","text":""},{"location":"entities/flows/#lcflow","title":"LcFlow","text":"<p>The Flow Interface</p> <p>The <code>LcFlow</code> class inherits the Flow interface defined in <code>antelope_interface</code>.  It includes  a name, a set of synonyms, and a context, defined as a tuple of hierarchical terms.  It also  includes a <code>lookup_cf</code> function where it performs the quantity relation on itself and stores the results in a cache.  </p> <p>               Bases: <code>LcEntity</code>, <code>Flow</code></p>"},{"location":"entities/flows/#antelope_core.entities.flows.LcFlow.new","title":"<code>new(name, ref_qty, **kwargs)</code>  <code>classmethod</code>","text":"<p>Parameters:</p> Name Type Description Default <code>name</code> <p>the name of the flow</p> required <code>ref_qty</code> <p>the reference quantity</p> required <p>Returns:</p> Type Description"},{"location":"entities/processes/","title":"Processes","text":""},{"location":"entities/processes/#lcprocess","title":"LcProcess","text":"<p>               Bases: <code>LcEntity</code></p>"},{"location":"entities/processes/#antelope_core.entities.processes.LcProcess.__init__","title":"<code>__init__(external_ref, **kwargs)</code>","text":"<p>THe process's data is a set of exchanges.</p> <p>A process's reference entity is a subset of these.  It is an error for these exchanges to have terminations (if they're terminated, they're not reference flows- they're dependencies). These references can be used as allocation keys for the exchanges.</p> <p>The entities in reference_entity and _exchanges are not necessarily the same, although they should hash the same.  Not sure whether this is a design flaw or not- but the important thing is that reference entities do not need to have exchange values associated with them (although they could).</p> <p>process.find_reference(key), references() [generator], and reference(flow) all return entries from _exchanges, not entries from reference_entity.  The only public interface to the objects in reference_entity is reference_entity itself.</p> <p>Parameters:</p> Name Type Description Default <code>entity_uuid</code> required <code>kwargs</code> <code>{}</code>"},{"location":"entities/processes/#antelope_core.entities.processes.LcProcess.add_exchange","title":"<code>add_exchange(flow, dirn, reference=None, value=None, termination=None, add_dups=False)</code>","text":"<p>This is used to create Exchanges and ExchangeValues and AllocatedExchanges.</p> <p>If the flow+dir+term is already in the exchange set:     if no reference is specified and/or no value is specified- nothing to do     otherwise (if reference and value are specified):         upgrade the exchange to an allocatedExchange and add the new reference exch val otherwise:     if reference is specified, create an AllocatedExchange     otherwise create an Exchange / ExchangeValue</p> <p>Parameters:</p> Name Type Description Default <code>flow</code> required <code>dirn</code> required <code>reference</code> <code>None</code> <code>value</code> <code>None</code> <code>termination</code> <p>None for reference or cutoff flows; a context for elementary flows; a valid external_ref for terminated intermediate flows.</p> <code>None</code> <code>add_dups</code> <p>(False) set to true to handle \"duplicate exchange\" errors by cumulating their values</p> <code>False</code> <p>Returns:</p> Type Description"},{"location":"entities/processes/#antelope_core.entities.processes.LcProcess.allocate_by_quantity","title":"<code>allocate_by_quantity(quantity)</code>","text":"<p>Store a quantity for partitioning allocation.  All non-reference exchanges will have their exchange values computed based on the total, determined by the quantity specified.  For each reference exchange, computes the magnitude of the quantity output from the unallocated process. Reference flows lacking characterization in that quantity will receive zero allocation.</p> <p>Each magnitude is the allocation numerator for that reference, and the sum of the magnitudes is the allocation denominator.</p> <p>Parameters:</p> Name Type Description Default <code>quantity</code> <p>an LcQuantity (or None to remove quantity allocation)</p> required <p>Returns:</p> Type Description"},{"location":"entities/processes/#antelope_core.entities.processes.LcProcess.allocation_factors","title":"<code>allocation_factors(quantity=None)</code>","text":"<p>Returns a dict mapping reference exchange to that reference's allocation factor according to the specified allocation quantity. If no quantity is specified, the current allocation quantity is used.  DOES NOT AFFECT CURRENT ALLOCATION.</p> <p>Parameters:</p> Name Type Description Default <code>quantity</code> <p>allocation quantity</p> <code>None</code> <p>Returns:</p> Type Description"},{"location":"entities/processes/#antelope_core.entities.processes.LcProcess.exchange_values","title":"<code>exchange_values(flow, direction=None)</code>","text":"<p>Yield full exchanges matching flow specification.  Flow specification required. Will only yield multiple results if there are multiple terminations for the same flow.</p> <p>Parameters:</p> Name Type Description Default <code>flow</code> required <code>direction</code> <code>None</code> <p>Returns:</p> Type Description"},{"location":"entities/processes/#antelope_core.entities.processes.LcProcess.find_reference","title":"<code>find_reference(spec=None, direction=None)</code>","text":"<p>returns a reference exchange matching the specification.</p> <p>If multiple results are found, filters out terminated exchanges</p> <p>Parameters:</p> Name Type Description Default <code>spec</code> <p>could be None, external_ref, flow, flow ref, or exchange</p> <code>None</code> <code>direction</code> <p>could be helpful if the object is a non-reference exchange</p> <code>None</code> <p>Returns:</p> Type Description"},{"location":"entities/processes/#antelope_core.entities.processes.LcProcess.inventory","title":"<code>inventory(ref_flow=None)</code>","text":"<p>generate a process's exchanges.  If no reference is supplied, generate unallocated exchanges, including all reference exchanges.  If a reference is supplied AND the process is allocated with respect to that reference, generate ExchangeValues as allocated to that reference flow, and exclude reference exchanges.  If a reference is supplied but the process is NOT allocated to that reference, generate unallocated ExchangeValues (excluding the reference itself).  Reference must be a flow or exchange found in the process's reference entity.</p> <p>Parameters:</p> Name Type Description Default <code>ref_flow</code> <code>None</code> <p>Returns:</p> Type Description"},{"location":"entities/processes/#antelope_core.entities.processes.LcProcess.is_allocated","title":"<code>is_allocated(reference, strict=False)</code>","text":"<p>Tests whether a process's exchanges contain allocation factors for a given reference.</p> <p>Parameters:</p> Name Type Description Default <code>reference</code> required <code>strict</code> <p>[False] if True, raise an exception if some (but not all) exchanges are missing allocations.</p> <code>False</code> <p>Returns:</p> Type Description <p>True - allocations exist; False - no allocations exist; raise MissingFactor - some allocations exist</p>"},{"location":"entities/processes/#antelope_core.entities.processes.LcProcess.new","title":"<code>new(name, **kwargs)</code>  <code>classmethod</code>","text":"<p>Parameters:</p> Name Type Description Default <code>name</code> <p>the name of the process</p> required <p>Returns:</p> Type Description"},{"location":"entities/processes/#antelope_core.entities.processes.LcProcess.set_reference","title":"<code>set_reference(flow, dirn)</code>","text":"<p>Exchange must already exist. fmr: If the exchange is currently terminated, the termination is removed. now: exchanges terminated to non-elementary context are now allowed</p> <p>Parameters:</p> Name Type Description Default <code>flow</code> required <code>dirn</code> required <p>Returns:</p> Type Description"},{"location":"entities/processes/#antelope_core.entities.processes.LcProcess.show_inventory","title":"<code>show_inventory(reference=None)</code>","text":"<p>Convenience wrapper around self.inventory() which:  * sorts the exchanges by reference, then by direction  * prints the exchanges to output  * provides an enumeration of exchanges for interactive access  = returns the exchanges as a sorted list.</p> <p>Parameters:</p> Name Type Description Default <code>reference</code> <code>None</code> <p>Returns:</p> Type Description"},{"location":"entities/processes/#antelope_core.entities.processes.LcProcess.test_allocation_consistency","title":"<code>test_allocation_consistency(flow=None, display=True)</code>","text":"<p>For each non-reference item in the inventory, test that the values allocated to each reference, weighted by the reference values, sum up to the un-allocated value.</p> <p>Parameters:</p> Name Type Description Default <code>flow</code> <p>[None] single flow to test; defaults to entire inventory</p> <code>None</code> <code>display</code> <p>[True] whether to print output to the screen</p> <code>True</code> <p>Returns:</p> Type Description"},{"location":"entities/quantities/","title":"LcQuantity","text":"<p>               Bases: <code>LcEntity</code></p>"},{"location":"entities/quantities/#antelope_core.entities.quantities.LcQuantity.__hash__","title":"<code>__hash__()</code>","text":"<p>This needs to be explicit, even though it is identical to the parent class, because otherwise the type is considered unhashable</p> <p>Returns:</p> Type Description"},{"location":"entities/quantities/#antelope_core.entities.quantities.LcQuantity.cf","title":"<code>cf(flow, locale='GLO', **kwargs)</code>","text":"<p>The semantics here may be confusing, but cf is flow-centered. It converts reports the amount in self that corresponds to a unit of the flow's reference quantity.</p> <p>Parameters:</p> Name Type Description Default <code>flow</code> required <code>locale</code> <code>'GLO'</code> <code>kwargs</code> <code>{}</code> <p>Returns:</p> Type Description"},{"location":"entities/quantities/#antelope_core.entities.quantities.LcQuantity.new","title":"<code>new(name, ref_unit, **kwargs)</code>  <code>classmethod</code>","text":"<p>Parameters:</p> Name Type Description Default <code>name</code> <p>the name of the quantity</p> required <code>ref_unit</code> <p>the string representation of the reference unit for the quantity</p> required <p>Returns:</p> Type Description"},{"location":"entities/quantities/#antelope_core.entities.quantities.LcQuantity.profile","title":"<code>profile(flow, **kwargs)</code>","text":"<p>This is a ridiculous hack because the profile doesn't depend on self at all.  So let's make it non-ridiculous by defaulting to self as ref_quantity, so it's not TOTALLY ridiculous</p> <p>Parameters:</p> Name Type Description Default <code>flow</code> required <code>kwargs</code> <code>{}</code> <p>Returns:</p> Type Description"},{"location":"entities/quantities/#antelope_core.entities.quantities.LcQuantity.set_qi","title":"<code>set_qi(qi)</code>","text":"<p>Configures the quantity to access its native term manager.  Can only be set once; otherwise ignored.</p> <p>Parameters:</p> Name Type Description Default <code>qi</code> required <p>Returns:</p> Type Description"},{"location":"reference/SUMMARY/","title":"SUMMARY","text":"<ul> <li>archives<ul> <li>archive_index</li> <li>basic_archive</li> <li>entity_store</li> <li>lc_archive</li> <li>quantity_manager</li> <li>term_manager</li> <li>tests</li> </ul> </li> <li>autorange</li> <li>catalog<ul> <li>catalog</li> <li>catalog_root</li> <li>configurator</li> <li>lc_catalog</li> <li>lc_resolver</li> <li>tests</li> </ul> </li> <li>catalog_query</li> <li>characterizations</li> <li>contexts</li> <li>data_sources<ul> <li>data_source</li> <li>ecoinvent</li> <li>ecoinvent_lcia</li> <li>gwp_ipcc_2007</li> <li>local</li> <li>tests</li> <li>traci</li> <li>uslci<ul> <li>uslci</li> </ul> </li> </ul> </li> <li>entities<ul> <li>anchors</li> <li>entities</li> <li>flows</li> <li>fragments</li> <li>processes</li> <li>quantities</li> <li>tests<ul> <li>base_testclass</li> </ul> </li> <li>xlsx_editor</li> </ul> </li> <li>exchanges</li> <li>file_accessor</li> <li>fragment_flows</li> <li>from_json</li> <li>implementations<ul> <li>background</li> <li>basic</li> <li>configure</li> <li>exchange</li> <li>index</li> <li>quantity</li> <li>tests</li> </ul> </li> <li>lc_resource</li> <li>lcia_engine<ul> <li>clookup</li> <li>lcia_engine</li> <li>tests</li> </ul> </li> <li>lcia_results</li> <li>providers<ul> <li>data</li> <li>ecoinvent_lcia</li> <li>ecospold</li> <li>ecospold2<ul> <li>ecospold2</li> <li>ecospold2_index</li> <li>master_data</li> </ul> </li> <li>file_store</li> <li>ilcd<ul> <li>ilcd</li> <li>ilcd_flowables</li> <li>ilcd_lcia</li> <li>index</li> <li>quantity</li> <li>tests</li> </ul> </li> <li>openlca<ul> <li>olca_accessor</li> <li>olca_ps_interpreter</li> <li>olca_ref_data</li> <li>openlca_jsonld</li> <li>parameters</li> <li>schema_mapping</li> </ul> </li> <li>parse_math</li> <li>tests</li> <li>traci<ul> <li>index</li> <li>q_info</li> <li>quantity</li> <li>traci_2_1_spreadsheet</li> </ul> </li> <li>xdb_client<ul> <li>implementation</li> <li>requester</li> <li>rest_client</li> <li>xdb_client</li> <li>xdb_entities</li> </ul> </li> <li>xl_dict</li> <li>xml_widgets</li> </ul> </li> <li>tests</li> </ul>"},{"location":"reference/autorange/","title":"autorange","text":"<p>autorange.py</p> <p>Scales numerical values by powers of 1000 to present engineering notation. Also scales metric prefixes to match.</p>"},{"location":"reference/autorange/#autorange.AutoRange","title":"<code>AutoRange</code>","text":"<p>               Bases: <code>object</code></p>"},{"location":"reference/autorange/#autorange.AutoRange.numeral","title":"<code>numeral</code>  <code>property</code>","text":"<p>report scaling factor as multiplicative numeral</p> <p>Returns:</p> Type Description"},{"location":"reference/autorange/#autorange.AutoRange.__init__","title":"<code>__init__(rng, bias=0, kg_to_t=True, disallow_prefix=None)</code>","text":"<p>creates an object for computing auto-ranged values.  The input argument should be the largest value that is expected to appear in the context.  It will be ranged to fall between 0-1000 (absolute value); this can be adjusted with the 'bias' param: one order per integer value up (pos) or down (neg)</p> <p>Parameters:</p> Name Type Description Default <code>rng</code> <p>either a scalar (abs) or an iterable (max(abs))</p> required <code>bias</code> <p>[0] default range is 0-1000.  bias=1: 10-10,000; bias=-1: 0.1-100; etc; floats are operable</p> <code>0</code> <code>kg_to_t</code> <p>[True] correct kg to t in cases where the results are scaled up example: with kg_to_t = True, a unit of 'kg' autoranged to 'Mg' or larger will be converted to 't', 'Gg' to 'kt', etc, but a unit of 'kg' or smaller will not with kg_to_t False, no alteration is performed</p> <code>True</code> <code>disallow_prefix</code> <p>preifx(es) to add to DISALLOW ('MT', 'mol', 'PM'). can be string or iterable.</p> <code>None</code>"},{"location":"reference/autorange/#autorange.AutoRange.adj_unit","title":"<code>adj_unit(unit)</code>","text":"<p>This is the tricky, ad-hoc part.  Assume the first character in the unit string is a prefix IF it is found in the metric prefixes dictionary.  If it is not, assume it is unprefixed.</p> <p>Parameters:</p> Name Type Description Default <code>unit</code> <p>a unit string</p> required <p>Returns:</p> Type Description"},{"location":"reference/catalog_query/","title":"catalog_query","text":"<p>Query Interface -- used to operate catalog refs</p>"},{"location":"reference/catalog_query/#catalog_query.CatalogQuery","title":"<code>CatalogQuery</code>","text":"<p>               Bases: <code>BasicInterface</code>, <code>IndexInterface</code>, <code>BackgroundInterface</code>, <code>ExchangeInterface</code>, <code>QuantityInterface</code></p> <p>A CatalogQuery is a class that performs any supported query against a supplied catalog. Supported queries are defined in the lcatools.interfaces, which are all abstract. Implementations also subclass the abstract classes.</p> <p>This reduces code duplication (all the catalog needs to do is provide interfaces) and ensures consistent signatures.</p> <p>The arguments to a query should always be text strings, not entities.  When in doubt, use the external_ref.</p> <p>The EXCEPTION is the bg_lcia routine, which works best (auto-loads characterization factors) if the query quantity is a catalog ref.</p> <p>The catalog's resolver performs fuzzy matching, meaning that a generic query (such as 'local.ecoinvent') will return both exact resources and resources with greater semantic specificity (such as 'local.ecoinvent.3.2.apos'). All queries accept the \"strict=\" keyword: set to True to only accept exact matches.</p>"},{"location":"reference/catalog_query/#catalog_query.CatalogQuery.bg_lcia","title":"<code>bg_lcia(process, query_qty=None, ref_flow=None, **kwargs)</code>","text":"<p>returns an LciaResult object, aggregated as appropriate depending on the interface's privacy level. This can only be implemented at the query level because it requires access to lci()</p> <p>Parameters:</p> Name Type Description Default <code>process</code> <p>must have a background interface</p> required <code>query_qty</code> <p>an operable quantity_ref, or catalog default may be used if omitted</p> <code>None</code> <code>ref_flow</code> <code>None</code> <code>kwargs</code> <code>{}</code> <p>Returns:</p> Type Description"},{"location":"reference/catalog_query/#catalog_query.CatalogQuery.cascade","title":"<code>cascade(origin)</code>","text":"<p>Generate a new query for the specified origin. Enables the query to follow the origins of foreign objects found locally. If not found locally, the current query is used instead</p> <p>Parameters:</p> Name Type Description Default <code>origin</code> required <p>Returns:</p> Type Description"},{"location":"reference/catalog_query/#catalog_query.CatalogQuery.characterize","title":"<code>characterize(flowable, ref_quantity, query_quantity, value, context=None, location='GLO', **kwargs)</code>","text":"<p>This is an Xdb innovation: we do not need or want an implementation-specific characterize routine-- just like with make_ref, the point of the catalog query is to localize all characterizations to the LciaEngine.</p> <p>We simply duplicate the characterize() code from the core QuantityImplementation</p> <p>Parameters:</p> Name Type Description Default <code>flowable</code> required <code>ref_quantity</code> required <code>query_quantity</code> required <code>value</code> required <code>context</code> <code>None</code> <code>location</code> <code>'GLO'</code> <code>kwargs</code> <code>{}</code> <p>Returns:</p> Type Description"},{"location":"reference/catalog_query/#catalog_query.CatalogQuery.clear_seen_characterizations","title":"<code>clear_seen_characterizations(quantity)</code>","text":"<p>An ugly hack to deal with the absolutely terrible way we are working around our slow-ass Qdb implementation the proper solution is for qdb lookup to be local,  fast and correct, so as to not require caching at all.</p> <p>Parameters:</p> Name Type Description Default <code>quantity</code> required <p>Returns:</p> Type Description"},{"location":"reference/catalog_query/#catalog_query.CatalogQuery.get","title":"<code>get(eid, **kwargs)</code>","text":"<p>Retrieve entity by external Id. This will take any interface and should keep trying until it finds a match. It first matches canonical entities, because that is the point of canonical entities.</p> <p>Parameters:</p> Name Type Description Default <code>eid</code> <p>an external Id</p> required <p>Returns:</p> Type Description"},{"location":"reference/catalog_query/#catalog_query.CatalogQuery.resolve","title":"<code>resolve(itype=INTERFACE_TYPES, strict=False)</code>","text":"<p>Secure access to all known resources but do not answer any query</p> <p>Parameters:</p> Name Type Description Default <code>itype</code> <p>default: all interfaces</p> <code>INTERFACE_TYPES</code> <code>strict</code> <p>[False]</p> <code>False</code> <p>Returns:</p> Type Description"},{"location":"reference/catalog_query/#catalog_query.CatalogQuery.synonyms","title":"<code>synonyms(item, **kwargs)</code>","text":"<p>Potentially controversial? include canonical as well as provincial synonyms for catalog queries??</p> <p>Parameters:</p> Name Type Description Default <code>item</code> required <code>kwargs</code> <code>{}</code> <p>Returns:</p> Type Description"},{"location":"reference/catalog_query/#catalog_query.CatalogQuery.sys_lcia","title":"<code>sys_lcia(process, query_qty, observed=None, ref_flow=None, **kwargs)</code>","text":"<p>Reimplement this to detect pydantic LciaResult models and de-reference them</p> <p>Parameters:</p> Name Type Description Default <code>process</code> required <code>query_qty</code> required <code>observed</code> <code>None</code> <code>ref_flow</code> <code>None</code> <code>kwargs</code> <code>{}</code> <p>Returns:</p> Type Description"},{"location":"reference/characterizations/","title":"characterizations","text":"<p>Characterizations are one of the two forms of quantitative information in LCA. A characterization relates two different quantities of measurement (known as a reference quantity and a query quantity) for one particular flowable substance, in a specific environmental context and geographic locale.</p> <p>A QRResult is a namedtuple that documents the result of a \"quantity relation\" calculation- it reports:  - the flowable  - the reference quantity  - the query quantity  - the context / compartment  - the locale  - the origin of the characterization data  - the value of the characterization</p>"},{"location":"reference/characterizations/#characterizations.Characterization","title":"<code>Characterization</code>","text":"<p>               Bases: <code>object</code></p> <p>A characterization is an affiliation of a flow and a quantity. Characterizations are inherently naively spatialized, with factors stored in a dict of locations, and the 'GLO' location being used as the default.</p> <p>Note: the !only! place a Characterization is created is in TermManager.add_characterization()</p>"},{"location":"reference/characterizations/#characterizations.Characterization.__eq__","title":"<code>__eq__(other)</code>","text":"<p>returns True if the hash elements are all the same</p>"},{"location":"reference/characterizations/#characterizations.Characterization.__eq__--this-is-clearly-broken","title":"This is clearly broken","text":""},{"location":"reference/characterizations/#characterizations.Characterization.__eq__--returns-true-if-all-of-others-location-specific-values-equal-selfs-values-for-the-same-location","title":"Returns true if all of other's location-specific values equal self's values for the same location","text":"<p>Parameters:</p> Name Type Description Default <code>other</code> required <p>Returns:</p> Type Description"},{"location":"reference/characterizations/#characterizations.Characterization.__init__","title":"<code>__init__(flow_name, ref_quantity, query_quantity, context, origin=None, **kwargs)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>flow_name</code> <p>a canonical string</p> required <code>quantity</code> required <code>value</code> <p>passed to add_value if present</p> required <code>location</code> <p>'GLO' passed to add_value if present</p> required <code>origin</code> <p>of data, if applicable</p> <code>None</code> <p>Returns:</p> Type Description"},{"location":"reference/characterizations/#characterizations.Characterization.serialize","title":"<code>serialize(values=False, concise=False)</code>","text":"<p>The \"concise\" option is used within term manager when query quantity, context, and flowable are already serialized</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>False</code> <code>concise</code> <code>False</code> <p>Returns:</p> Type Description"},{"location":"reference/characterizations/#characterizations.LocaleMismatch","title":"<code>LocaleMismatch</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Requested locale is not found</p>"},{"location":"reference/characterizations/#characterizations.MissingContext","title":"<code>MissingContext</code>","text":"<p>               Bases: <code>Exception</code></p> <p>context cannot be None</p>"},{"location":"reference/characterizations/#characterizations.MissingReference","title":"<code>MissingReference</code>","text":"<p>               Bases: <code>Exception</code></p> <p>A flow must have a reference quantity to be characterized</p>"},{"location":"reference/contexts/","title":"contexts","text":"<p>Contexts in this sense are environmental compartments, except they have the added capability to keep lists of origins.</p> <p>Edelen and Ingwersen et al 2017: \"Recommendations: ...setting an exclusive or inclusive nomenclature for flow context information that includes directionality and environmental compartment information.\"</p> <p>In the antelope architecture, there are two different objectives for handling contexts as-presented by the data source.</p> <p>In the default case, for every static resource or stand-alone archive a \"TermManager\" is created which is captive to  the archive.  The role of this class is to collect information from the data source in as close to its native  presentation as possible. This creates an \"inclusive\" nomenclature for the source.</p> <p>In the Catalog case, catalog's local quantity DB is an LciaEngine, which is also shared among all foreground  resources.  In this case the objective is to match a given context to the existing (exclusive) nomenclature built-in  to the LciaEngine, so that contexts are guaranteed to coincide during LCIA.</p> <p>In order to accomplish this, the native add_context() method needs to be expansive, fault tolerant, and widely accepting of diverse inputs, whereas find_matching_context() needs to be more discerning and rigorous.  Thus the former accepts a tuple of string terms or a context, but the latter requires a context.  find_matching_context searches first bottom-up then top-down to look for matches.  It requires an input context to have an origin already specified, so that the resources can assign \"hints\" that map local terms to canonical contexts on an origin-specific basis.</p> <p>Note that a \"matching\" generally requires an exact (case-insensitive) match to an entry in the contexts database. Curation of the synonym set is required.</p> <p>Because contexts must be directional, some terms are protected as ambiguous: \"air\", \"water\", and \"ground\" should be avoided in favor of explicit \"from air\" or \"to air\" or synonyms.</p> <p>The NullContext is a singleton defined in this file that is meant to imply no specific context.  It is interpreted in two different ways:  - on the characterization side, NullContext indicates the characterization has no specific context, and thus applies to    all contexts, as long as a more applicable characterization is not found.  - on the query side, NullContext indicates that a context was specified but no match was found.  Queries with    NullContext should not match any existing characterizations (except NullContext itself).</p> <p>The NullContext should be returned by the context manager</p>"},{"location":"reference/contexts/#contexts.Context","title":"<code>Context</code>","text":"<p>               Bases: <code>Compartment</code></p> <p>If 'resources' or 'emissions' match any terms in a compartment, it is considered 'elementary', along with all its subcompartments.</p> <p>A context has a natural directional \"sense\", which is either 'Source', 'Sink', or None.  A Source context generates flows which may be inputs to the activity; a Sink context absorbs flows which are output from the activity.</p> <p>If a context has a parent, it inherits the sense of the parent- specifying the opposite sense will raise an error.</p>"},{"location":"reference/contexts/#contexts.Context.elementary","title":"<code>elementary</code>  <code>property</code>","text":"<p>A context's \"elementary-ness\" is determined by the top-most parent.  Everything inherits from above. If the (lower cased) parent context is found in ELEMENTARY, it's elementary.</p> <p>The only way to make a context elementary is to name it such, or give it an elementary parent.</p> <p>Returns:</p> Type Description"},{"location":"reference/contexts/#contexts.Context.validate","title":"<code>validate()</code>  <code>staticmethod</code>","text":"<p>Need this for termination checking</p> <p>Returns:</p> Type Description"},{"location":"reference/contexts/#contexts.ContextManager","title":"<code>ContextManager</code>","text":"<p>               Bases: <code>CompartmentManager</code></p>"},{"location":"reference/contexts/#contexts.ContextManager.add_context_hint","title":"<code>add_context_hint(origin, term, canonical)</code>","text":"<p>Method for linking foreign context names to canonical contexts</p> <p>Parameters:</p> Name Type Description Default <code>origin</code> <p>origin of foreign context</p> required <code>term</code> <p>foreign context name</p> required <code>canonical</code> <p>recognized synonym for canonical context that should match the foreign one</p> required <p>Returns:</p> Type Description"},{"location":"reference/contexts/#contexts.ContextManager.find_matching_context","title":"<code>find_matching_context(context)</code>","text":"<p>A complicated function to both (1) retrieve the best / most-specific \"canonical\" context for a given \"foreign\" (i.e. incoming) context and also (2) add the full semantic content of the foreign context to the canonical context manager.</p> <p>(1) is accomplished by a heuristic both-first search, first looking at the foreign context from most-specific to least-specific and trying to find a match.  if no match is found, we go back from least-to-most specific, using a slightly broader set of possible matches including heuristic names derived from contextual senses. If no match at all is found, then NullContext is returned -- the foreign context matches no canonical context.</p> <p>(2) If a canonical context is found, then all non-matching contexts from least-specific to most-specific, are mapped onto existing sub-contexts of the match, or if none is found, collapsed into the match.</p> <p>Parameters:</p> Name Type Description Default <code>context</code> required <p>Returns:</p> Type Description"},{"location":"reference/contexts/#contexts.FrozenElementary","title":"<code>FrozenElementary</code>","text":"<p>               Bases: <code>Exception</code></p> <p>top-level elementary contexts may not be assigned non-elementary parents</p>"},{"location":"reference/contexts/#contexts.ImmutableContextName","title":"<code>ImmutableContextName</code>","text":"<p>               Bases: <code>Exception</code></p> <p>A context's hash comes from its name and thus the name may not be changed.</p>"},{"location":"reference/contexts/#contexts.ProtectedTerm","title":"<code>ProtectedTerm</code>","text":"<p>               Bases: <code>Exception</code></p> <p>currently triggered by the stale contexts file-- leading to an error in which \"emissions;to water;low population density, long-term\" and \"emissions;to air;low population density, long-term\" are synonyms in basic TermManagers. Should not present problems in LciaEngines, but the specific case is not tested.</p> <p>Solution is to patch the local-contexts.json file to exclude this redundant term for water. Justification: the canonical contexts should be well-behaved and not contain any inherent conflicts. It is a nomenclature problem for the two contexts to have the same name.</p>"},{"location":"reference/exchanges/","title":"exchanges","text":""},{"location":"reference/exchanges/#exchanges.DissipationExchange","title":"<code>DissipationExchange</code>","text":"<p>               Bases: <code>ExchangeValue</code></p> <p>Composition / Dissipation mechanics can be encapsulated entirely into the exchange object- the problem  is reduced to a serialization / deserialization problem.</p> <p>Composition / Dissipation probably conflicts with Allocation, i.e. it is not supported to add a dissipation factor to an AllocatedExchange.</p> <p>This is a problem because the allocated exchange is also the secret sauce being used to implement processflow parameters- and would presumably be the same mechanism to implement dissipation parameters.</p> <p>best solution would be to fold reference spec higher up in inheritance- also need an ironclad way to determine  the input flow (or to not support dissipation for processes with more than one reference flow) and simply make flow_quantity not None be the key to interpret the exchange value as a dissipation rate. except that I don't want to squash the non-dissipation exchange value.</p> <p>Maybe I should not be worrying about this right now.</p>"},{"location":"reference/exchanges/#exchanges.DissipationExchange.content","title":"<code>content(ref_flow=None)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>ref_flow</code> <p>a flow LcEntity</p> <code>None</code> <p>Returns:</p> Type Description"},{"location":"reference/exchanges/#exchanges.Exchange","title":"<code>Exchange</code>","text":"<p>               Bases: <code>object</code></p> <p>An exchange is an affiliation of a process, a flow, and a direction. An exchange does not include an exchange value- though presumably a valued exchange would be a subclass.</p> <p>An exchange may specify a uuid of a terminating process; tests for equality will distinguish differently-terminated flows. (ecoinvent)</p>"},{"location":"reference/exchanges/#exchanges.Exchange.lkey","title":"<code>lkey</code>  <code>property</code>","text":"<p>Long key, for testing equality with exchange refs whose terminations may be tuples</p> <p>Returns:</p> Type Description"},{"location":"reference/exchanges/#exchanges.Exchange.__init__","title":"<code>__init__(process, flow, direction, termination=None, comment=None)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>process</code> required <code>flow</code> required <code>direction</code> required <code>termination</code> <p>external id of terminating process or None (note: this is uuid for ecospold2)</p> <code>None</code> <code>comment</code> <p>documentary information about the exchange</p> <code>None</code> <p>Returns:</p> Type Description"},{"location":"reference/exchanges/#exchanges.Exchange.is_allocated","title":"<code>is_allocated(reference)</code>","text":"<p>Stub for compatibility</p> <p>Parameters:</p> Name Type Description Default <code>reference</code> required <p>Returns:</p> Type Description"},{"location":"reference/exchanges/#exchanges.ExchangeValue","title":"<code>ExchangeValue</code>","text":"<p>               Bases: <code>Exchange</code></p> <p>An ExchangeValue is an exchange with a single value (corresponding to unallocated exchange value) plus a dict of values allocated to different reference flows.</p>"},{"location":"reference/exchanges/#exchanges.ExchangeValue.value","title":"<code>value</code>  <code>property</code> <code>writable</code>","text":"<p>unallocated value</p> <p>Returns:</p> Type Description"},{"location":"reference/exchanges/#exchanges.ExchangeValue.values","title":"<code>values</code>  <code>property</code>","text":"<p>Some Good Question here about what to use for the key part- can't go wrong with str</p> <p>Returns:</p> Type Description"},{"location":"reference/exchanges/#exchanges.ExchangeValue.__getitem__","title":"<code>__getitem__(item)</code>","text":"<p>Implements the exchange relation-- computes the quantity of self that is exchanged for a unit of item, according to whatever allocation is specified for the exchange or process.  self and item must share the same process (tested as external_ref to allow entities and references to interoperate)</p> <p>If self is a reference exchange, the exchange relation will equal either 0.0 or 1.0 depending on whether item is self or a different reference.  FOR NOW: Reference exchanges cannot</p> <p>When an exchange is asked for its value with respect to a particular reference, lookup the allocation in the value_dict.  IF there is no value_dict, then the default _value is returned AS LONG AS the process has only 0 or 1 reference exchange.</p> <p>Allocated exchange values should add up to unallocated value.  When using the exchange values, don't forget to normalize by the chosen reference flow's input value (i.e. utilize an inbound exchange when computing node weight or when constructing A + B matrices)</p> <p>Parameters:</p> Name Type Description Default <code>item</code> required <p>Returns:</p> Type Description"},{"location":"reference/exchanges/#exchanges.ExchangeValue.__setitem__","title":"<code>__setitem__(key, value)</code>","text":"<p>Used to set custom or \"causal\" allocation factors.  Here the allocation should be specified as a portion of the unallocated exchange value to be allocated to the reference.  The entered values will be normalized by the reference exchange's reference value when they are retrieved, to report the exchange value per unit of reference.</p> <p>This approach makes consistency of causal allocation easy to check: the allocation factors should simply add up to the unallocated factor. (this does not apply in ecoinvent, where the different co-products are pre-normalized and basically co-inhabiting the same process, and the unallocated factors are not present. The normalization must still occur, though, because ecoinvent still does use the sign of reference exchanges to indicate directionality)</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <p>a reference exchange</p> required <code>value</code> required <p>Returns:</p> Type Description"},{"location":"reference/exchanges/#exchanges.ExchangeValue.from_allocated","title":"<code>from_allocated(allocated, reference)</code>  <code>classmethod</code>","text":"<p>Use to flatten an allocated process inventory into a standalone inventory</p> <p>Parameters:</p> Name Type Description Default <code>allocated</code> required <code>reference</code> <p>a reference exchange</p> required <p>Returns:</p> Type Description"},{"location":"reference/exchanges/#exchanges.ExchangeValue.is_allocated","title":"<code>is_allocated(key)</code>","text":"<p>Report whether the exchange is allocated with respect to a given reference.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <p>an exchange</p> required <p>Returns:</p> Type Description"},{"location":"reference/exchanges/#exchanges.ExchangeValue.remove_allocation","title":"<code>remove_allocation(key)</code>","text":"<p>Removes allocation if it exists; doesn't complain if it doesn't.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <p>a reference exchange.</p> required <p>Returns:</p> Type Description"},{"location":"reference/exchanges/#exchanges.MarketExchange","title":"<code>MarketExchange</code>","text":"<p>               Bases: <code>Exchange</code></p> <p>A MarketExchange is an alternative implementation of an ExchangeValue that handles the multiple-input process case, i.e. when several processes produce the same product, and the database must balance them according to some apportionment of market value or production volume.</p> <p>The client code has to explicitly create a market exchange.  How does it know to do that? in the case of ecospold2, it has to determine whether the process has duplicate [non-zero] flows with activityLinkIds.</p> <p>In other cases, it will be foreground / linker code that does it.</p> <p>Add market suppliers using dictionary notation.  Use exchange values or production volumes, but do it consistently. The exchange value returned is always the individual supplier's value divided by the sum of values.</p>"},{"location":"reference/file_accessor/","title":"file_accessor","text":"<p>FileAccessor, for standardizing access to antelope resources on a filesystem having the following structure:</p> <p>{DATA ROOT}/[origin]/[interface]/[ds_type]/[source_file]  - source {DATA ROOT}/[origin]/[interface]/[ds_type]/config.json    - configuration</p> <p>A filesystem having this structure will enable automatic registration of resources, taking origin, interface, and ds_type from the directory structure and the source+config files as-discovered by traversing the filesystem.</p> <p>Should probably alter gen_sources to only return the one \"best\" source per path, instead of generating all of them. [One] problem with that is that, for instance, for Tarjan background I would need to ignore files that end with ORDERING_SUFFIX, but I can't import anything from antelope_background without creating a dependency loop.</p> <p>For now, generating the sources is probably fine.</p>"},{"location":"reference/file_accessor/#file_accessor.FileAccessor","title":"<code>FileAccessor</code>","text":"<p>               Bases: <code>object</code></p>"},{"location":"reference/file_accessor/#file_accessor.FileAccessor.source","title":"<code>source(org, iface)</code>","text":"<p>Return the \"best\" (right now: first) single source</p> <p>Parameters:</p> Name Type Description Default <code>org</code> required <code>iface</code> required <p>Returns:</p> Type Description"},{"location":"reference/file_accessor/#file_accessor.FileAccessor.write_config","title":"<code>write_config(source, **kwargs)</code>  <code>staticmethod</code>","text":"<p>Note: use the config argument add_interfaces=[list] to allow a resource to implement additional interfaces.</p> <p>Parameters:</p> Name Type Description Default <code>source</code> required <code>kwargs</code> <code>{}</code> <p>Returns:</p> Type Description"},{"location":"reference/file_accessor/#file_accessor.ResourceLoader","title":"<code>ResourceLoader</code>","text":"<p>               Bases: <code>FileAccessor</code></p> <p>This class crawls a directory structure and adds all the specified resources to the catalog provided as an input argument.</p> <p>After loading all pre-initialized resources, the class runs check_bg on each origin to auto-generate a background ordering within the catalog's filespace if one does not already exist.</p>"},{"location":"reference/file_accessor/#file_accessor.ResourceLoader.load_resources","title":"<code>load_resources(cat, origin=None, check=False, replace=True)</code>","text":"<p>For named origin (or all origins), load resources into the catalog. this will not open the resources, unless check=True</p> <p>Parameters:</p> Name Type Description Default <code>cat</code> required <code>origin</code> <code>None</code> <code>check</code> <p>[False] whether to load the resources and check background</p> <code>False</code> <code>replace</code> <p>[True] whether to replace an existing resource with the new one</p> <code>True</code> <p>Returns:</p> Type Description"},{"location":"reference/fragment_flows/","title":"fragment_flows","text":""},{"location":"reference/fragment_flows/#fragment_flows.CumulatingFlows","title":"<code>CumulatingFlows</code>","text":"<p>               Bases: <code>Exception</code></p> <p>when a fragment includes multiple instances of the reference flow having consistent (i.e. not complementary) directions. Not handled in subfragment traversal bc no valid test case</p>"},{"location":"reference/fragment_flows/#fragment_flows.FragmentFlow","title":"<code>FragmentFlow</code>","text":"<p>               Bases: <code>object</code></p> <p>A FragmentFlow is a an immutable record of a traversal query. essentially an enhanced NodeCache record which can be easily serialized to an antelope fragmentflow record.</p> <p>A fragment traversal generates an array of FragmentFlow objects.</p> <p>X    \"fragmentID\": 8, - added by antelope X    \"fragmentStageID\": 80,</p> <p>f    \"fragmentFlowID\": 167, f    \"name\": \"UO Local Collection\", f    \"shortName\": \"Scenario\", f    \"flowID\": 371, f    \"direction\": \"Output\", f    \"parentFragmentFlowID\": 168, f    \"isBackground\": false,</p> <p>w    \"nodeWeight\": 1.0,</p> <p>t    \"nodeType\": \"Process\", t    \"processID\": 62,</p> <ul> <li>\"isConserved\": true,</li> <li>\"flowPropertyMagnitudes\": [   {     \"flowPropertyID\": 23,     \"unit\": \"kg\",     \"magnitude\": 1.0   } ]</li> </ul>"},{"location":"reference/fragment_flows/#fragment_flows.FragmentFlow.__eq__","title":"<code>__eq__(other)</code>","text":"<p>FragmentFlows are equal if they have the same fragment and termination.  Formerly magnitude too but why? answer why: because if not, then two traversals from two different scenarios can appear equal answer why not: because of LciaResult issues, presumably- let's put this on the list for later</p> <p>Parameters:</p> Name Type Description Default <code>other</code> required <p>Returns:</p> Type Description"},{"location":"reference/fragment_flows/#fragment_flows.FragmentFlow.__init__","title":"<code>__init__(fragment, magnitude, node_weight, term, is_conserved, match_ev=None, match_term=None, flow_conversion=1.0)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>fragment</code> required <code>magnitude</code> required <code>node_weight</code> <p>flow (or balance) magnitude * flow conversion / anchor inflow magnitude</p> required <code>term</code> required <code>is_conserved</code> required <code>match_ev</code> <code>None</code> <code>match_term</code> <code>None</code> <code>flow_conversion</code> <p>[1.0] stored in the FragmentFlow for information purposes only. Negative value indicates a direction change at the anchor (driven anchor)</p> <code>1.0</code>"},{"location":"reference/fragment_flows/#fragment_flows.FragmentFlow.aggregate_subfragments","title":"<code>aggregate_subfragments(subfrags, scenarios=None)</code>","text":"<p>We need to save the full traversal specification (</p> <p>Parameters:</p> Name Type Description Default <code>subfrags</code> required <code>scenarios</code> <code>None</code> <p>Returns:</p> Type Description"},{"location":"reference/fragment_flows/#fragment_flows.FragmentFlow.from_process_inventory","title":"<code>from_process_inventory(query, process, ref_flow, elementary=False, exterior=False)</code>  <code>classmethod</code>","text":"<p>expands the named process's inventory into a list of FragmentFlows amenable to LCIA computation.</p> <p>generate FragmentFlows of the process's intermediate exchanges.  the ensuing list should be suitable to feed directly into frag_flow_lcia() to generate a contribution analysis</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <p>only requires .get(), so an implementation will work fine</p> required <code>process</code> required <code>ref_flow</code> required <code>elementary</code> <p>[False] if True, also generate FFs for elementary exchanges (these will otherwise get computed via unobserved_exchanges()</p> <code>False</code> <code>exterior</code> <p>[False] if True, also generate FFs for non-elementary exterior exchanges</p> <code>False</code> <p>Returns:</p> Type Description"},{"location":"reference/fragment_flows/#fragment_flows.FragmentFlow.screen_name","title":"<code>screen_name(length=80)</code>","text":"<p>auto-compact for display</p> <p>Returns:</p> Type Description"},{"location":"reference/fragment_flows/#fragment_flows.FragmentInventoryDeprecated","title":"<code>FragmentInventoryDeprecated</code>","text":"<p>               Bases: <code>Exception</code></p> <p>The \"inventory\" term for fragments is deprecated.  \"unit_inventory\" is now \"unit_flows\" and \"inventory\" is what it has always meant: \"cutoffs\".  And the old \"cutoffs\" is gone because it literally never worked.</p>"},{"location":"reference/fragment_flows/#fragment_flows.frag_flow_lcia","title":"<code>frag_flow_lcia(fragmentflows, quantity_ref, scenario=None, **kwargs)</code>","text":"<p>Recursive function to compute LCIA of a traversal record contained in a set of Fragment Flows. Note: refresh is no longer supported during traversal</p> <p>Parameters:</p> Name Type Description Default <code>fragmentflows</code> required <code>quantity_ref</code> required <code>scenario</code> <p>necessary if any remote traversals are required</p> <code>None</code> <code>ignore_uncached</code> <p>[True] whether to allow zero scores for un-cached, un-computable fragments</p> required <p>Returns:</p> Type Description"},{"location":"reference/from_json/","title":"from_json","text":""},{"location":"reference/from_json/#from_json.from_json","title":"<code>from_json(fname)</code>","text":"<p>Routine to extract the contents of a json file.  no longer pretends to support PY2.</p> <p>Parameters:</p> Name Type Description Default <code>fname</code> <p>json file, optionally gzipped</p> required <p>Returns:</p> Type Description <p>a json-derived dict</p>"},{"location":"reference/lc_resource/","title":"lc_resource","text":""},{"location":"reference/lc_resource/#lc_resource.LcResource","title":"<code>LcResource</code>","text":"<p>               Bases: <code>object</code></p> <p>This is a record that links a semantic reference to a physical data source, and specifies the capabilities (and someday, access limitations) of the data source.</p> <p>The LcResource serializes to a json file with the following format: { ref: [ { \"dataSource\": source, \"dataSourceType\": ds_type, .... }, ... ] } where ref is the semantic reference.</p>"},{"location":"reference/lc_resource/#lc_resource.LcResource.__init__","title":"<code>__init__(origin, source, ds_type, interfaces=None, privacy=0, priority=50, static=False, preload_archive=None, config=None, **kwargs)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>origin</code> <p>semantic reference to data origin</p> required <code>source</code> <p>physical data source; 'None' allowed if 'downloadLink' argument provided</p> required <code>ds_type</code> <p>data source type</p> required <code>interfaces</code> <p>list which can include 'entity', 'foreground', or 'background'. Default 'foreground'</p> <code>None</code> <code>privacy</code> <p>Ignored / No longer used.</p> <code>0</code> <code>priority</code> <p>[50] priority level.. numeric (nominally 0-100), lowest priority resource is loaded first</p> <code>50</code> <code>static</code> <p>[False] if True, load_all() after initializing</p> <code>False</code> <code>preload_archive</code> <p>[None] use to assign an existing archive</p> <code>None</code> <code>config</code> <p>ConfigureInterface specifications</p> <code>None</code> <code>kwargs</code> <p>additional keyword arguments to constructor. Some interesting ones: download: a dict containing 'url' and optional 'md5sum' fields prefix: often used when accessing zipped archives token: a jwt used for authenticating to xdb 'options': popped with values used as kwargs (per ResourceSpec)</p> <code>{}</code>"},{"location":"reference/lc_resource/#lc_resource.LcResource.from_dict","title":"<code>from_dict(ref, d)</code>  <code>classmethod</code>","text":"<p>Returns a single LcResource loaded from a dict.  only required field is 'dataSourceType'. other fields are passed to the constructor and either interpreted directly or added as supplemental args</p> <p>If 'dataSource' is not present, one had better hope that url is present in the dict to download the source</p> <p>Parameters:</p> Name Type Description Default <code>ref</code> required <code>d</code> required <p>Returns:</p> Type Description"},{"location":"reference/lc_resource/#lc_resource.LcResource.from_file","title":"<code>from_file(file)</code>  <code>classmethod</code>","text":"<p>generates LcResources contained in the named file, sorted by increasing priority.  The filename and the reference must be the same.</p> <p>Parameters:</p> Name Type Description Default <code>file</code> required <p>Returns:</p> Type Description <p>an ordered list of resources</p>"},{"location":"reference/lc_resource/#lc_resource.LcResource.matches","title":"<code>matches(k)</code>","text":"<p>Pretty cheesy.  When we serialize a set of resources, we need to make sure not to include self twice.  To make the comparison concrete, use a serialized resource as input.</p> <p>We were using dataSource as a unique identifier for resource entries; but the introduction of download links  breaks that because a downloadable resource has no source until it's been downloaded.  The solution is to fallback to download.url ONLY IF the resource has no source specified.</p> <p>Parameters:</p> Name Type Description Default <code>k</code> <p>a serialized LcResource</p> required <p>Returns:</p> Type Description"},{"location":"reference/lc_resource/#lc_resource.LcResource.write_to_file","title":"<code>write_to_file(path, assign_ref=None, apply_config=None)</code>","text":"<p>Adds the resource to a file whose name is the resource's semantic reference. If the same datasource is already present in the file, replace it with the current resource.  otherwise append.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <p>directory to store the resource file.</p> required <code>assign_ref</code> <p>assign this ref instead of the resource's current ref</p> <code>None</code> <code>apply_config</code> <p>overwrites configuration with supplied dict</p> <code>None</code> <p>Returns:</p> Type Description"},{"location":"reference/lc_resource/#lc_resource.ResourceInvalid","title":"<code>ResourceInvalid</code>","text":"<p>               Bases: <code>Exception</code></p> <p>resource points to an invalid filename</p>"},{"location":"reference/lcia_results/","title":"lcia_results","text":"<p>This object replaces the LciaResult types spelled out in Antelope-- instead, it serializes to an LCIA result directly.</p>"},{"location":"reference/lcia_results/#lcia_results.AggregateLciaResult","title":"<code>AggregateLciaResult</code>","text":"<p>               Bases: <code>object</code></p> <p>contains an entityId which could be a process or a fragment (but presents as a process, i.e. with exchanges) The Aggregate score is constructed from individual LCIA Details (exchange value x characterization factor)</p>"},{"location":"reference/lcia_results/#lcia_results.AggregateLciaResult.details","title":"<code>details()</code>","text":"<p>generator of nonzero detailed results</p> <p>Returns:</p> Type Description"},{"location":"reference/lcia_results/#lcia_results.AggregateLciaResult.serialize","title":"<code>serialize(detailed=False)</code>","text":"<p>If detailed is True, this should return DisaggregatedLciaScores If detailed is False, this should return SummaryLciaScores</p> <p>Parameters:</p> Name Type Description Default <code>detailed</code> <code>False</code> <p>Returns:</p> Type Description"},{"location":"reference/lcia_results/#lcia_results.DetailedLciaResult","title":"<code>DetailedLciaResult</code>","text":"<p>               Bases: <code>object</code></p> <p>Contains exchange, factor, result</p>"},{"location":"reference/lcia_results/#lcia_results.DetailedLciaResult.__init__","title":"<code>__init__(lc_result, exchange, qrresult)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>lc_result</code> required <code>exchange</code> required <code>qrresult</code> <p>meets the QRResult spec: has properties 'flowable', 'ref', 'query', 'context', 'locale', 'origin', 'value' 'ref' has to have property 'unit' 'context' has to be a context (with 'sense')</p> required"},{"location":"reference/lcia_results/#lcia_results.LciaResult","title":"<code>LciaResult</code>","text":"<p>               Bases: <code>object</code></p> <p>An LCIA result object contains a collection of LCIA results for a related set of entities, called components.  Each  component is an AggregateLciaResult, which itself is a collection of either detailed LCIA results or summary scores.</p> <p>Each component which is a FragmentFlow represents a specific traversal scenario and is thus static.</p> <p>Each component which is a process will contain actual exchanges and factors, which are scenario-sensitive, and  so is (theoretically) dynamic. This is not yet useful in practice.  LCIA Results are in sharp need of testing /  refactoring.</p>"},{"location":"reference/lcia_results/#lcia_results.LciaResult.failed_summaries","title":"<code>failed_summaries</code>  <code>property</code>","text":"<p>A list of Summary results that failed to be added to an existing summary. This is mainly diagnostic and should be removed soon. Note the difiference from self.errors(), which is meant to store input exchanges that could not be converted to the query quantity during LCIA.</p> <p>Returns:</p> Type Description"},{"location":"reference/lcia_results/#lcia_results.LciaResult.__init__","title":"<code>__init__(quantity, scenario=None, private=False, scale=1.0, autorange=False)</code>","text":"<p>If private, the LciaResult will not return any unaggregated results</p> <p>Parameters:</p> Name Type Description Default <code>quantity</code> required <code>scenario</code> <code>None</code> <code>private</code> <code>False</code>"},{"location":"reference/lcia_results/#lcia_results.LciaResult.a_total","title":"<code>a_total()</code>","text":"<p>I don't want any logic in total()</p> <p>Returns:</p> Type Description"},{"location":"reference/lcia_results/#lcia_results.LciaResult.aggregate","title":"<code>aggregate(key=lambda x: x.get('StageName'), entity_id=None)</code>","text":"<p>returns a new LciaResult object in which the components of the original LciaResult object are aggregated into static values according to a key.  The key is a lambda expression that is applied to each AggregateLciaResult component's entity property (components where the lambda fails will all be grouped together).</p> <p>The special key '*' will aggregate all components together.  'entity_id' argument is required in this case to provide a distinguishing key for the result (falls back to \"aggregated result\").</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <p>default: lambda x: x.fragment['StageName'] -- assuming the payload is a FragmentFlow</p> <code>lambda x: get('StageName')</code> <code>entity_id</code> <p>a descriptive string for the entity, to allow the aggregation to be distinguished in subsequent aggregations.  Use 'None' at your peril</p> <code>None</code> <p>Returns:</p> Type Description"},{"location":"reference/lcia_results/#lcia_results.LciaResult.contrib","title":"<code>contrib(percent=False, count=None)</code>","text":"<p>Convert the LCIA result to a result with a unitary value.  If the score is an Aggregated score, it will first be aggregated by flow name</p> <p>Parameters:</p> Name Type Description Default <code>percent</code> <p>[False] if True, the score will add up to 100</p> <code>False</code> <code>count</code> <p>[None] number of distinct categories to report (plus remainder)</p> <code>None</code> <p>Returns:</p> Type Description"},{"location":"reference/lcia_results/#lcia_results.LciaResult.contrib_new","title":"<code>contrib_new(*args, autorange=None)</code>","text":"<p>re-implement contrib query with a better spec.</p> <p>Queries are specified as entries from self.keys(). One way to get the keys to be more legible is to first perform an aggregation using self.aggregate().</p> <p>The current getitem method, which uses a fuzzy match (self._match_keys()) is not currently used.</p> <p>Parameters:</p> Name Type Description Default <code>args</code> <p>A sequential list of components to query.  The special component '*' can be used to select the balance of results.</p> <code>()</code> <code>autorange</code> <p>[None] do not alter autorange settings.  [True / False]: activate or deactivate auto-ranging.</p> <code>None</code> <p>Returns:</p> Type Description <p>a 2-tuple: results, balance where results is a list having the same length as the number of arguments, and balance is a float reporting the remainder.  sum(results, balance) == self.total().  If '*' is specified as one of the queries, balance will always be 0.</p>"},{"location":"reference/lcia_results/#lcia_results.LciaResult.contrib_query","title":"<code>contrib_query(stages=None)</code>","text":"<p>returns a list of scores</p> <p>Parameters:</p> Name Type Description Default <code>stages</code> <p>[None] a list of stages to query, or None to return all components. Specify '*' to return a 1-item list containing just the total.</p> <code>None</code> <p>Returns:</p> Type Description"},{"location":"reference/lcia_results/#lcia_results.LciaResult.cutoffs","title":"<code>cutoffs()</code>","text":"<p>Generates exchanges for which no factor was found during LCIA.</p> <p>Returns:</p> Type Description"},{"location":"reference/lcia_results/#lcia_results.LciaResult.errors","title":"<code>errors()</code>","text":"<p>generates exchanges that could not be converted to the target quantity due to a conversion error. Note the difference from self.failed_summaries, which reports summary scores that could not be added.</p> <p>Returns:</p> Type Description"},{"location":"reference/lcia_results/#lcia_results.LciaResult.flatten","title":"<code>flatten(_apply_scale=1.0)</code>","text":"<p>Return a new LciaResult in which all groupings have been replaced by a set of AggregatedLciaScores, one  per elementary flow. Performs some inline testing via equality assertions, but this still really needs unit testing, especially around matters of internal scale versus applied scale</p> <p>Returns:</p> Type Description"},{"location":"reference/lcia_results/#lcia_results.LciaResult.scale_result","title":"<code>scale_result(scale)</code>","text":"<p>why is this a function?</p>"},{"location":"reference/lcia_results/#lcia_results.LciaResult.serialize_components","title":"<code>serialize_components(detailed=False)</code>","text":"<p>If detailed is True, this should return DisaggregatedLciaScores If detailed is False, this should return SummaryLciaScores</p> <p>Parameters:</p> Name Type Description Default <code>detailed</code> <code>False</code> <p>Returns:</p> Type Description"},{"location":"reference/lcia_results/#lcia_results.LciaResult.set_autorange","title":"<code>set_autorange(value=None, **kwargs)</code>","text":"<p>Update the AutoRange object. Should be done before results are presented, if auto-ranging is in use.</p> <p>Auto-ranging affects the following outputs:  * any show() or printed string  * the results of contrib_new()  * a_total()</p> <p>No other outputs are affected.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>None</code> <p>Returns:</p> Type Description"},{"location":"reference/lcia_results/#lcia_results.LciaResult.show_components","title":"<code>show_components(percent=False, count=100, threshold=None)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>percent</code> <code>False</code> <code>count</code> <p>[None] a maximum number of components to print</p> <code>100</code> <code>threshold</code> <p>[None] an absolute value below which scores are aggregated</p> <code>None</code> <p>Returns:</p> Type Description"},{"location":"reference/lcia_results/#lcia_results.LciaResult.show_details","title":"<code>show_details(key=None, count=100, threshold=None)</code>","text":"<p>Sorting by parts is not ideal but it will have to do.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>None</code> <code>count</code> <code>100</code> <code>threshold</code> <code>None</code> <p>Returns:</p> Type Description"},{"location":"reference/lcia_results/#lcia_results.MixedComponents","title":"<code>MixedComponents</code>","text":"<p>               Bases: <code>Exception</code></p> <p>We are now suddenly deciding that an LciaResult may not contain a mixture of AggregateLciaScores and SummaryLciaScores</p>"},{"location":"reference/lcia_results/#lcia_results.StringEntity","title":"<code>StringEntity</code>","text":"<p>               Bases: <code>object</code></p> <p>To be used in cases where a component's entity is a plain string, to still allow aggregation</p>"},{"location":"reference/lcia_results/#lcia_results.SummaryLciaResult","title":"<code>SummaryLciaResult</code>","text":"<p>               Bases: <code>object</code></p> <p>A container for a separately computed Lcia result, especially for the results of a fragment LCIA. Includes a node weight and a unit score-- its cumulative result is the product of these. If the unit score is a number, the summary is static.</p> <p>However, the unit_score can itself be an LciaResult, making the datatype recursive.</p> <p>This has add functionality, for merging repeated instances of the same fragment during traversal</p>"},{"location":"reference/lcia_results/#lcia_results.SummaryLciaResult.result","title":"<code>result</code>  <code>property</code>","text":"<p>must workalike with both AggregateLciaScores and DetailedLciaResults</p> <p>Returns:</p> Type Description"},{"location":"reference/lcia_results/#lcia_results.SummaryLciaResult.__add__","title":"<code>__add__(other)</code>","text":"<p>Add two summary LCIA results together.  This only works under the following circumstances:  * different instances of the same entity are being added (e.g. two instances of the same flow).    In this case, the two summaries' entities must compare as equal and their unit scores must be equal.    The node weights are added.  Scale is ignored (scale is inherited from the primary summary)</p> <ul> <li>Two static-valued summaries are added together.  In this case, either the scores must be equal (in which case    the node weights are summed) or the node weights must be equal, and the unit scores are summed.</li> </ul> <p>This is the sort of garbage that should be unittested.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> required <p>Returns:</p> Type Description"},{"location":"reference/lcia_results/#lcia_results.SummaryLciaResult.__init__","title":"<code>__init__(lc_result, entity, node_weight, unit_score)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>lc_result</code> <p>who \"owns\" you. scale report by their scale. entity_id must either have get_uuid() or be hashable</p> required <code>entity</code> <p>a hashable identifier</p> required <code>node_weight</code> <p>stand-in for exchange value</p> required <code>unit_score</code> <p>stand-in for factor value</p> required"},{"location":"reference/lcia_results/#lcia_results.SummaryLciaResult.serialize","title":"<code>serialize(detailed=False)</code>","text":"<p>If detailed is True, this should return DisaggregatedLciaScores If detailed is False, this should return SummaryLciaScores</p> <p>Parameters:</p> Name Type Description Default <code>detailed</code> <code>False</code> <p>Returns:</p> Type Description"},{"location":"reference/lcia_results/#lcia_results.show_lcia","title":"<code>show_lcia(lcia_results)</code>","text":"<p>Takes in a dict of uuids to lcia results, and summarizes them in a neat table</p> <p>Parameters:</p> Name Type Description Default <code>lcia_results</code> required <p>Returns:</p> Type Description"},{"location":"reference/archives/__init__/","title":"init","text":""},{"location":"reference/archives/__init__/#archives.CheckTerms","title":"<code>CheckTerms</code>","text":"<p>               Bases: <code>object</code></p> <p>A utility for reviewing the integrity of exchanges in an archive</p>"},{"location":"reference/archives/__init__/#archives.Qdb","title":"<code>Qdb</code>","text":"<p>               Bases: <code>BasicArchive</code></p> <p>A simple archive that just contains the 25-odd reference (non-LCIA) quantities of the ELCD database circa v3.2</p>"},{"location":"reference/archives/__init__/#archives.Qdb.new","title":"<code>new(ref='local.qdb')</code>  <code>classmethod</code>","text":"<p>Create a Quantity database containing the ILCD reference quantities.  Specify a ref if desired.</p> <p>Parameters:</p> Name Type Description Default <code>ref</code> <p>['local.qdb']</p> <code>'local.qdb'</code>"},{"location":"reference/archives/__init__/#archives.Qdb.new_flow","title":"<code>new_flow(name, ref_quantity=None, **kwargs)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>name</code> required <code>ref_quantity</code> <p>defaults to \"Number of items\"</p> <code>None</code> <code>kwargs</code> <code>{}</code> <p>Returns:</p> Type Description"},{"location":"reference/archives/__init__/#archives.archive_factory","title":"<code>archive_factory(ds_type)</code>","text":"<p>Returns an archive class</p> <p>Parameters:</p> Name Type Description Default <code>ds_type</code> required <p>Returns:</p> Type Description"},{"location":"reference/archives/__init__/#archives.archive_from_json","title":"<code>archive_from_json(fname, factory=archive_factory, catalog=None, **archive_kwargs)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>fname</code> <p>JSON filename</p> required <code>factory</code> <p>function returning a class</p> <code>archive_factory</code> <code>catalog</code> <p>[None] necessary to retrieve upstream archives, if specified</p> <code>None</code> <p>Returns:</p> Type Description <p>an ArchiveInterface</p>"},{"location":"reference/archives/__init__/#archives.create_archive","title":"<code>create_archive(source, ds_type, factory=archive_factory, **kwargs)</code>","text":"<p>Create an archive from a source and type specification.</p> <p>Parameters:</p> Name Type Description Default <code>source</code> required <code>ds_type</code> required <code>factory</code> <p>override archive factory with fancier version</p> <code>archive_factory</code> <code>kwargs</code> <code>{}</code> <p>Returns:</p> Type Description"},{"location":"reference/archives/archive_index/","title":"archive_index","text":""},{"location":"reference/archives/archive_index/#archives.archive_index.BasicIndex","title":"<code>BasicIndex</code>","text":"<p>               Bases: <code>AbstractIndex</code>, <code>BasicArchive</code></p>"},{"location":"reference/archives/archive_index/#archives.archive_index.BasicIndex.write_to_file","title":"<code>write_to_file(filename, gzip=True, **kwargs)</code>","text":"<p>created to make gzip=True by default for index archives</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> required <code>gzip</code> <code>True</code> <code>kwargs</code> <code>{}</code> <p>Returns:</p> Type Description"},{"location":"reference/archives/archive_index/#archives.archive_index.LcIndex","title":"<code>LcIndex</code>","text":"<p>               Bases: <code>AbstractIndex</code>, <code>LcArchive</code></p>"},{"location":"reference/archives/archive_index/#archives.archive_index.LcIndex.write_to_file","title":"<code>write_to_file(filename, gzip=True, **kwargs)</code>","text":"<p>created to make gzip=True by default for index archives</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> required <code>gzip</code> <code>True</code> <code>kwargs</code> <code>{}</code> <p>Returns:</p> Type Description"},{"location":"reference/archives/basic_archive/","title":"basic_archive","text":""},{"location":"reference/archives/basic_archive/#archives.basic_archive.BASIC_ENTITY_TYPES","title":"<code>BASIC_ENTITY_TYPES = ('quantity', 'flow')</code>  <code>module-attribute</code>","text":"<p>LcArchive Stored Configuration.</p> <p>add these objects with archive.add_config() applied in sequence with archive.apply_config()</p>"},{"location":"reference/archives/basic_archive/#archives.basic_archive.BasicArchive","title":"<code>BasicArchive</code>","text":"<p>               Bases: <code>EntityStore</code></p> <p>Adds on basic functionality to the archive interface: add new entities; deserialize entities.</p> <p>The Basic Archive also introduces the Term Manager, which is used to handle flow characterization information.</p> <p>Each archive must have a term manager; however, the same term manager can be shared among several archives.  If no TermManager is provided at instantiation as an input argument, then the archive will create a captive term manager that only includes entities from that archive.</p> <p>ALternatively, a term manager can be created first and supplied as an argument to each created archive, which would then allow them to share their terms in common with one another.</p> <p>The BasicArchive should be used for all archives that only contain flows and quantities (and contexts in the future)</p>"},{"location":"reference/archives/basic_archive/#archives.basic_archive.BasicArchive.__getitem__","title":"<code>__getitem__(item)</code>","text":"<p>Note: this user-friendliness check adds 20% to the execution time of getitem-- so avoid it if possible (use _get_entity directly -- especially now that upstream is now deprecated) (note that _get_entity does not get contexts)</p> <p>Parameters:</p> Name Type Description Default <code>item</code> required <p>Returns:</p> Type Description"},{"location":"reference/archives/basic_archive/#archives.basic_archive.BasicArchive.entity_from_json","title":"<code>entity_from_json(e)</code>","text":"<p>Create an LcEntity subclass from a json-derived dict</p> <p>this could use some serious refactoring</p> <p>Parameters:</p> Name Type Description Default <code>e</code> required <p>Returns:</p> Type Description"},{"location":"reference/archives/basic_archive/#archives.basic_archive.BasicArchive.export_quantities","title":"<code>export_quantities(filename, *quantities, domesticate=True, values=True, gzip=False)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>filename</code> required <code>quantities</code> <p>positional args are quantities to serialize</p> <code>()</code> <code>domesticate</code> <p>[True- new archive becomes reference]  if False, the qty source origin will remain canonical</p> <code>True</code> <code>values</code> <p>[True- new archive stores cfs] if False the export will only include flowable+context lists</p> <code>True</code> <code>gzip</code> <p>[False] whether to gzip the file</p> <code>False</code> <p>Returns:</p> Type Description"},{"location":"reference/archives/basic_archive/#archives.basic_archive.BasicArchive.from_already_open_file","title":"<code>from_already_open_file(j, filename, ref=None, **kwargs)</code>  <code>classmethod</code>","text":"<p>This is an in-between function that should probably be refactored away / folded into archive_from_json (which is the only place it's used)</p> <p>Parameters:</p> Name Type Description Default <code>j</code> required <code>filename</code> required <code>ref</code> <p>incoming ref from catalog</p> <code>None</code> <code>kwargs</code> <code>{}</code> <p>Returns:</p> Type Description"},{"location":"reference/archives/basic_archive/#archives.basic_archive.BasicArchive.from_file","title":"<code>from_file(filename, ref=None, **init_args)</code>  <code>classmethod</code>","text":"<p>BasicArchive factory from minimal dictionary.  Must include at least one of 'dataSource' or 'dataReference' fields and 0 or more flows or quantities; but note that any flow present must have its reference quantities included. The method is inherited by LcArchives which permit processes as well; any process must have its exchanged flows (and their respective quantities) included.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <p>The name of the file to be loaded</p> required <code>ref</code> <p>fallback reference to use if none is specified in source file</p> <code>None</code> <p>Returns:</p> Type Description"},{"location":"reference/archives/basic_archive/#archives.basic_archive.BasicArchive.load_from_dict","title":"<code>load_from_dict(j, _check=True, jsonfile=None)</code>","text":"<p>Archives loaded from JSON files are considered static.</p> <p>Parameters:</p> Name Type Description Default <code>j</code> required <code>_check</code> <p>whether to run check_counter to print out statistics at the end</p> <code>True</code> <code>jsonfile</code> <p>[None] if present, add to the list of sources for the canonical ref</p> <code>None</code> <p>Returns:</p> Type Description"},{"location":"reference/archives/basic_archive/#archives.basic_archive.BasicArchive.search","title":"<code>search(etype=None, count=None, offset=None, **kwargs)</code>","text":"<p>Implement pagination</p> <p>Parameters:</p> Name Type Description Default <code>etype</code> <code>None</code> <code>count</code> <code>None</code> <code>offset</code> <code>None</code> <code>kwargs</code> <code>{}</code> <p>Returns:</p> Type Description"},{"location":"reference/archives/basic_archive/#archives.basic_archive.BasicArchive.serialize","title":"<code>serialize(characterizations=False, values=False, domesticate=False)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>characterizations</code> <code>False</code> <code>values</code> <code>False</code> <code>domesticate</code> <p>[False] if True, omit entities' origins so that they will appear to be from the new archive upon serialization</p> <code>False</code> <p>Returns:</p> Type Description"},{"location":"reference/archives/entity_store/","title":"entity_store","text":"<p>A repository of typed entities, retrievable by their external reference</p> <p>Entity object API:   entity.entity_type --&gt; string used for groupung   entity.external_ref --&gt; lookup name   entity.origin --&gt; one-time settable parameter, set by the entity store   entity.validate() --&gt; must return True [for valid entities and False for invalid ones]   entity.name --&gt; printable name</p> <p>Optional:   entity.uuid --? used for entity retrieval</p>"},{"location":"reference/archives/entity_store/#archives.entity_store.EntityStore","title":"<code>EntityStore</code>","text":"<p>               Bases: <code>object</code></p>"},{"location":"reference/archives/entity_store/#archives.entity_store.EntityStore.names","title":"<code>names</code>  <code>property</code>","text":"<p>Return a mapping of data source to semantic reference, based on the catalog_names property.  This is used by a catalog interface to convert entity origins from physical to semantic.</p> <p>If a single data source has multiple semantic origins, only the most-downstream one will be kept.  If there are multiple semantic origins for the same data source in the same archive, one will be kept at random. This should be avoided and I should probably test for it when setting catalog_names.</p> <p>Returns:</p> Type Description"},{"location":"reference/archives/entity_store/#archives.entity_store.EntityStore.source","title":"<code>source</code>  <code>property</code>","text":"<p>The catalog's original source is the \"master descriptor\" of the catalog's content. This is required for subclass methods to work properly, in the event that the original source is called upon.</p> <p>Returns:</p> Type Description"},{"location":"reference/archives/entity_store/#archives.entity_store.EntityStore.__getitem__","title":"<code>__getitem__(item)</code>","text":"<p>Client-facing entity retrieval.  item is a key that can be converted to a valid UUID from self._ref_to_key()--  either a literal UUID, or a string containing something matching a naive UUID regex.</p> <p>First checks upstream, then local.</p> <p>Returns None if nothing is found</p> <p>NOTE: IT IS REALLY PATHOLOGICALLY BROKEN TO RETURN None INSTEAD OF RAISING KeyError  #FounderCode</p> <p>Parameters:</p> Name Type Description Default <code>item</code> required <p>Returns:</p> Type Description"},{"location":"reference/archives/entity_store/#archives.entity_store.EntityStore.__init__","title":"<code>__init__(source, ref=None, quiet=True, static=False, dataReference=None, ns_uuid=None, no_validate=None, **kwargs)</code>","text":"<p>An EntityStore is a provenance structure for a collection of entities.  Ostensibly, an EntityStore has a single source from which entities are collected.  The source is a resolvable URI that indicates a data resource from which data describing the entities can be extracted.  The exact manner of extracting data from resources is subclass-dependent.</p> <p>The desired key is specified during the call to _add(entity, key).  Internally, if the entity has a 'uuid' attribute and it is set (validity not checked), then the uuid is .  If the external references do not contain UUIDs, it is recommended to derive a UUID3 using an archive-specific, stable namespace ID.  The class-level _ns_uuid_required attribute governs this option:  - if True, an ns_uuid argument must be provided when the class is instantiated.  This is consistent with a    use case in which it is desirable to have predictable, fixed UUIDs (i.e. to interface with a data system    that requires stable UUIDs)</p> <ul> <li> <p>if False, a random ns_uuid is generated, and used to create a UUID anytime an entity is given a non-UUID    external_ref</p> </li> <li> <p>if None, UUID3 are not used and any supplied ns_uuid argument is ignored. external_refs must always be UUIDs.</p> </li> </ul> <p>There is still some refactoring to be done, to try to eliminate the need for externally visible UUIDs anywhere.</p> <p>An archive has a single semantic reference that describes the data context from which its native entities were gathered.  The reference is given using dot-separated hierarchical terms in order of decreasing semantic significance from left to right.  The leftmost specifier should describe the maintainer of the  resource (which defaults to 'local' when a reference argument is not provided), followed by arbitrarily  more precise specifications. Some examples are:  local.lcia.traci.2.1.spreadsheet  ecoinvent.3.2.undefined</p> <p>The purpose for the source / reference distinction is that in principle many different sources can all provide the same semantic content: for instance, ecoinvent can be accessed from the website or from a file on the user's computer.  In principle, if the semantic reference for two archives is the same, the archives should contain excerpts of the same data, even if drawn from different sources.</p> <p>An entity is uniquely identified by its link property, which is made from concatenating the semantic origin and a stable reference known as an 'external_ref', as 'origin/external_ref'.  The first slash is the delimiter between origin and reference. Examples:</p> <p>elcd.3.2/processes/00043bd2-4563-4d73-8df8-b84b5d8902fc uslci.ecospold/Acetic acid, at plant</p> <p>Note that the inclusion of embedded whitespace, commas, and other characters indicate that these semantic origins are not proper URIs.</p> <p>It is hoped that the user community will help develop and maintain a consistent and easily interpreted namespace for semantic origins.  If this is done, it should be possible to identify any published entity with a concise reference.</p> <p>When an entity is first added to an archive, it is assigned that archive's reference as its origin, following the expectation that data about the same reference from different sources is the same data.</p> <p>When an entity with a different origin is added to an archive, it is good practice to add a mapping from that origin to its source in the receiving archive's \"catalog_names\" dictionary.  However, since the entity itself does not know its archive's source, this cannot be done automatically.</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <p>physical data source-- where the information is being drawn from</p> required <code>ref</code> <p>optional semantic reference for the data source. gets added to catalog_names.</p> <code>None</code> <code>quiet</code> <code>True</code> <code>static</code> <p>[False] whether archive is expected to be unchanging.</p> <code>False</code> <code>dataReference</code> <p>alternative to ref</p> <code>None</code> <code>ns_uuid</code> <p>required to store entities by common name.  Used to generate uuid3 from string inputs.</p> <code>None</code> <code>no_validate</code> <p>if True, skip validation on entity add</p> <code>None</code> <code>kwargs</code> <p>any other information that should be serialized with the archive</p> <code>{}</code>"},{"location":"reference/archives/entity_store/#archives.entity_store.EntityStore.create_descendant","title":"<code>create_descendant(archive_path, signifier=None, force=False)</code>","text":"<p>Saves the archive to a new source with a new semantic reference.  The new semantic ref is derived by  (a) first removing any trailing ref that matches [0-9]{8+}  (b) appending the descendant signifier  (c) appending the current date in YYYYMMDD format</p> <p>After that:  1. The new semantic ref is added to catalog_names,  2. the source is set to archive_path/semantic.ref.json.gz,  3. load_all() is executed,  4. the archive is saved to the new source.</p> <p>Parameters:</p> Name Type Description Default <code>archive_path</code> <p>where to store the archive</p> required <code>signifier</code> <p>A nonzero-length string matching [A-Za-z0-9_-]+.  If not supplied, then the semantic ref is unchanged except for the date tag.</p> <code>None</code> <code>force</code> <p>overwrite if file exists</p> <code>False</code> <p>Returns:</p> Type Description <p>new semantic ref.</p>"},{"location":"reference/archives/entity_store/#archives.entity_store.EntityStore.find_partial_id","title":"<code>find_partial_id(uid, startswith=True)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>uid</code> <p>is a fragmentary (or complete) uuid string.</p> required <code>startswith</code> <p>[True] use .startswith instead of full regex</p> <code>True</code> <p>Returns:</p> Type Description <p>result set</p>"},{"location":"reference/archives/entity_store/#archives.entity_store.EntityStore.get_uuid","title":"<code>get_uuid(key)</code>","text":"<p>Deprecated.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> required <p>Returns:</p> Type Description"},{"location":"reference/archives/entity_store/#archives.entity_store.EntityStore.retrieve_or_fetch_entity","title":"<code>retrieve_or_fetch_entity(key, **kwargs)</code>","text":"<p>Client-facing function to retrieve entity by ID, first checking in the archive, then from the source.</p> <p>Input is flexible-- could be a UUID or key (partial uuid is just not useful)</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <p>the identifying string (uuid or external ref)</p> required <code>kwargs</code> <p>used to pass provider-specific information</p> <code>{}</code> <p>Returns:</p> Type Description"},{"location":"reference/archives/entity_store/#archives.entity_store.EntityStore.serialize","title":"<code>serialize(apply_changes=True, **kwargs)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>apply_changes</code> <p>[True] any properties assigned to catalog refs are applied to the entities prior to saving</p> <code>True</code> <code>kwargs</code> <code>{}</code> <p>Returns:</p> Type Description"},{"location":"reference/archives/entity_store/#archives.entity_store.EntityStore.validate_entity_list","title":"<code>validate_entity_list()</code>","text":"<p>This whole thing is crufty and untested and never used and should be abandoned</p> <p>Returns:</p> Type Description"},{"location":"reference/archives/entity_store/#archives.entity_store.EntityStore.write_to_file","title":"<code>write_to_file(filename, gzip=False, complete=False, **kwargs)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>filename</code> required <code>gzip</code> <code>False</code> <code>complete</code> <code>False</code> <code>kwargs</code> <p>whatever is required by the subclass's serialize method</p> <code>{}</code> <p>Returns:</p> Type Description"},{"location":"reference/archives/lc_archive/","title":"lc_archive","text":"<p>Interim classes with useful building blocks</p>"},{"location":"reference/archives/lc_archive/#archives.lc_archive.LcArchive","title":"<code>LcArchive</code>","text":"<p>               Bases: <code>BasicArchive</code></p> <p>A class meant for storing and managing LCA data collections.  Adds processes as a supported entity type (contrast with LcForeground which adds fragments).</p> <p>To support processes, adds inventory, background, and configure interfaces.</p>"},{"location":"reference/archives/lc_archive/#archives.lc_archive.LcArchive.load_from_dict","title":"<code>load_from_dict(j, _check=True, jsonfile=None)</code>","text":"<p>Archives loaded from JSON files are considered static.</p> <p>Parameters:</p> Name Type Description Default <code>j</code> required <code>_check</code> <code>True</code> <p>Returns:</p> Type Description"},{"location":"reference/archives/lc_archive/#archives.lc_archive.LcArchive.serialize","title":"<code>serialize(exchanges=False, characterizations=False, values=False, domesticate=False)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>exchanges</code> <code>False</code> <code>characterizations</code> <code>False</code> <code>values</code> <code>False</code> <code>domesticate</code> <p>[False] if True, omit entities' origins so that they will appear to be from the new archive upon serialization</p> <code>False</code> <p>Returns:</p> Type Description"},{"location":"reference/archives/quantity_manager/","title":"quantity_manager","text":""},{"location":"reference/archives/quantity_manager/#archives.quantity_manager.QuantityManager","title":"<code>QuantityManager</code>","text":"<p>               Bases: <code>SynonymDict</code></p>"},{"location":"reference/archives/quantity_manager/#archives.quantity_manager.QuantityManager.add_quantity","title":"<code>add_quantity(quantity)</code>","text":"<p>Prunes terms on quantity unit mismatch</p> <p>Parameters:</p> Name Type Description Default <code>quantity</code> required <p>Returns:</p> Type Description"},{"location":"reference/archives/quantity_manager/#archives.quantity_manager.QuantitySynonyms","title":"<code>QuantitySynonyms</code>","text":"<p>               Bases: <code>SynonymSet</code></p> <p>QuantitySynonyms are string terms that all refer to the same quantity of measure. They must all have the same unit, because they are used to define the unit of measure of flowables.  To repeat: quantity instances that have the same dimensionality but different units (e.g. kWh and MJ) are NOT SYNONYMS but distinct quantities. The LciaEngine should be able to handle conversions between these kinds of quantities.</p>"},{"location":"reference/archives/term_manager/","title":"term_manager","text":"<p>Edelen and Ingwersen et al 2017: Recommendations: \"... separating flowable names from context and unit information ...\"</p> <p>Term Manager - used to handle string references to entities that are known by several synonyms.  Specifically:  - contexts, which are drawn from flows' specified 'Compartment' or other classifying properties  - flowables, which are drawn from flows' uuid and external link, and Name, CasNumber, Synonyms properties  - quantities, which should be recognizable by external ref or uuid</p> <p>The main objective of the TermManager is to enable the use of generalized synonym matching in performing LCIA. It collects two kinds of mapping information: mapping string terms to flowables and contexts; and mapping (quantity, flowable, context) tuples to [regionalized] characterization objects.</p> <p>LciaEngine is designed to handle information from multiple origins to operate as a qdb in a catalog context.  The subclass adds canonical lists of flowables and contexts that would be redundant if loaded into individual archives, introduces \"smart\" hierarchical context lookup (CLookup), and adds the ability to quell biogenic CO2 emissions. Someday, it might make sense to expose it as a massive, central graph db.</p>"},{"location":"reference/archives/term_manager/#archives.term_manager--interface","title":"INTERFACE","text":"<p>The TermManager is assumed to implement the following interface: Required for external operability:  - is_lcia_engine: [bool] whether the term manager performs flow and context matching  - is_context(obj): [bool] whether the supplied object maps to a known Context;;; hmm, this was implemented twice  - getitem(obj): retrieve a context or None **note: this is because archives all return None for failed getitem,     which I know is bad but I haven't been moved to change it yet)  - get_canonical(qty): return the best-fit quantity, or raise EntityNotFou  - synonyms()  # currently required by BasicImplementation</p> <p>Required by the default implementation: Post data:  - add_quantity()  - add_context()  - add_flow()  - add_characterization()  - add_from_json()</p> <p>retrieve data:  - serialize()  - flows_for_flowable()  - factors_for_flowable()  - factors_for_quantity()  - get_flowable()  - flowables()  - quantities()  - contexts()</p>"},{"location":"reference/archives/term_manager/#archives.term_manager.FlowableConflict","title":"<code>FlowableConflict</code>","text":"<p>               Bases: <code>Exception</code></p> <p>A list of synonyms indicates two or more flowables</p>"},{"location":"reference/archives/term_manager/#archives.term_manager.NoFQEntry","title":"<code>NoFQEntry</code>","text":"<p>               Bases: <code>Exception</code></p> <p>This exception has the specific meaning that there is no lookup for the named flow-quantity pair</p>"},{"location":"reference/archives/term_manager/#archives.term_manager.TermManager","title":"<code>TermManager</code>","text":"<p>               Bases: <code>object</code></p> <p>A TermManager is an archive-specific mapping of string terms to flowables and contexts.  During normal operation it is captive to an archive and automatically harvests flowable and context terms from flows when added to the archive.  It also hosts a set of CLookups for the archive's quantities, which enable fuzzy traversal of context hierarchies to find best-fit characterization factors.</p> <p>When a new entity is added to the archive, there are two connections to make: combine uuids and human-readable descriptors into a common database of synonyms, and connect those sets of synonyms to a set of entities known to the local archive.</p> <p>When harvesting terms from a new flow, the general approach is to merge the new entry with an existing entry if the existing one uniquely matches.  If there is more than one match, there are three general strategies:</p> <p>'prune': trim off the parts that match existing entries and make a new entry with only the distinct terms.    this creates a larger more diffuse</p> <p>'merge': merge all the terms from the new entry and any existing entries together</p> <p>The mapping is prolific in both cases- adds a flowable-to-flow mapping for every flowable that matches a given flow (merge_strategy='merge' ensures that this is exactly one flowable), and adds the CF to every flowable that matches.</p> <p>USAGE MODEL: TODO The Term Manager is basically a giant pile of Characterization objects, grouped by canonical query quantity, flowable, and context. The basic TermManager enforces a restriction of one CF per qq | fb | cx combination.  The LciaEngine subclass uses a CLookup that can either be strict or non-strict, but nonetheless enforces one CF per qq | fb | cx | origin combination.</p> <p>There are thus four things the Term Manager must be able to do:  - store names of flowables and contexts from source data  - retrieve canonical flowable and context names from the store  - store characterizations, properly indexed by canonical names  - retrieve characterizations according to a query</p> <p>The components used to accomplish this are:  _cm and _fm: the context and flowable synonym sets  _flow_map: reverse-maps flowable terms to flows</p> <p>_q_dict: a 3-level nested dictionary:      defaultdict: quantity uuid -&gt; defaultdict: flowable -&gt; CLookup: context-&gt; {CFs}    - first level defaultdict maps quantity uuid to second level      - second level defaultdict maps flowable canonical name to CLookup / subclass        - third level CLookup maps context to a set of CFs  _fq_map: reverse-maps flowable canonical name to a set of quantities that characterize it</p>"},{"location":"reference/archives/term_manager/#archives.term_manager.TermManager.__getitem__","title":"<code>__getitem__(item)</code>","text":"<p>TermManager.getitem retrieves a context known to the TermManager, or None if one is not found. Getitem exposes only the contexts, since flow external_refs are used as flowable synonyms</p> <p>Parameters:</p> Name Type Description Default <code>item</code> required <p>Returns:</p> Type Description"},{"location":"reference/archives/term_manager/#archives.term_manager.TermManager.__init__","title":"<code>__init__(contexts=None, flowables=None, quantities=None, merge_strategy='graft', quiet=True)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>contexts</code> <p>optional filename to initialize CompartmentManager</p> <code>None</code> <code>flowables</code> <p>optional filename to initialize FlowablesDict</p> <code>None</code> <code>merge_strategy</code> <p>(can also be specified at add_flow())  'graft': - on conflict, follow incoming flow's link or name; add new terms to the existing flowable and discard conflicting terms.  solves many \"shared CAS number\" problems-- by depriving the new flowable of the CAS identifier  'prune' or 'distinct': - on conflict, create a new flowable containing only new terms, discard all conflicting terms. This is the default for flows added with no context (so that distinct intermediate flows with the same name e.g. \"bolt 10mm\" could have different characterizations. If you want to prevent this, give your flow any nonempty context)  'merge': - aggressively merge all co-synonymous flowables.  not tested.</p> <code>'graft'</code> <code>quiet</code> <code>True</code>"},{"location":"reference/archives/term_manager/#archives.term_manager.TermManager.add_characterization","title":"<code>add_characterization(flowable, ref_quantity, query_quantity, value, context=None, origin=None, location=None, overwrite=False)</code>","text":"<p>Replacement for flow-based add_characterization.  THE ONLY place to create Characterization objects. Add them to all flowables that match the supplied flow.</p> <p>Parameters:</p> Name Type Description Default <code>flowable</code> <p>if not known to the flowables dict, added as a new flowable</p> required <code>ref_quantity</code> <p>[entity or ref]</p> required <code>query_quantity</code> <p>[entity or ref]</p> required <code>value</code> <p>mandatory. either a numeric value or a dict mapping locations to values</p> required <code>context</code> <p>the context for which the characterization applies.  Should be a string or tuple.  None means the factor applies to all contexts.</p> <code>None</code> <code>overwrite</code> <p>whether to overwrite an existing value if it already exists (ignored if value is a dict)</p> <code>False</code> <code>location</code> <p>(ignored if value is a dict) 'GLO' used if no location is provided</p> <code>None</code> <code>origin</code> <p>(optional; origin of value; defaults to quantity.origin)</p> <code>None</code> <p>Returns:</p> Type Description <p>created or updated characterization</p>"},{"location":"reference/archives/term_manager/#archives.term_manager.TermManager.add_context","title":"<code>add_context(context, *terms, origin=None)</code>","text":"<p>We are using conflict='attach' by default so that 'emissions' and 'resources' can be attached to 'Elementary flows' if it exists. It may cause undesirable side-effects if different intermediate categories use similar terms, e.g. ('buildings', 'heat', 'steam') and ('chemical', 'heat', 'process') could result in InconsistentLineage  (or else something crazy like ('chemical', 'buildings', 'heat', ('process', 'steam')) )</p> <p>Parameters:</p> Name Type Description Default <code>context</code> required <code>origin</code> <p>apply origin to context if it has none</p> <code>None</code> <p>Returns:</p> Type Description"},{"location":"reference/archives/term_manager/#archives.term_manager.TermManager.add_flow","title":"<code>add_flow(flow, merge_strategy=None)</code>","text":"<p>We take a flow from outside and add its known terms. That means  - adding flow's reference quantity  - merging any context with the local context tree;  - adding flowable terms to the flowables list;  - mapping flow to all flowables (assigning flowable if none is found)</p> <p>Note that all flows having null context are forced to be distinct from one another. If you want two flowables to share properties, you must add them having non-null contexts. not sure how I feel about this but it does work.</p> <p>Parameters:</p> Name Type Description Default <code>flow</code> required <code>merge_strategy</code> <p>overrule default merge strategy</p> <code>None</code> <p>Returns:</p> Type Description <p>the Flowable object to which the flow's terms have been added</p>"},{"location":"reference/archives/term_manager/#archives.term_manager.TermManager.add_flow_terms","title":"<code>add_flow_terms(flow, merge_strategy=None)</code>","text":"<p>This process takes in an inbound FlowInterface instance, identifies the flowable(s) that match its terms, and adds new terms to the existing or new flowable.  May update a flow's name in case of conflict.</p> <p>Parameters:</p> Name Type Description Default <code>flow</code> required <code>merge_strategy</code> <code>None</code> <p>Returns:</p> Type Description"},{"location":"reference/archives/term_manager/#archives.term_manager.TermManager.add_from_json","title":"<code>add_from_json(j, q_map, origin=None)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>j</code> required <code>q_map</code> <p>a dict whose keys are external_refs and uuids, and whose values are quantities</p> required <code>origin</code> <code>None</code> <p>Returns:</p> Type Description"},{"location":"reference/archives/term_manager/#archives.term_manager.TermManager.factors_for_flowable","title":"<code>factors_for_flowable(flowable, quantity=None, context=None, **kwargs)</code>","text":"<p>This is the method that actually performs the lookup.  Other methods are wrappers for this.</p> <p>If context is None, this is \"unspecified\". It matches all CFs regardless of context.</p> <p>Core to this is getting a canonical context, which is done by getitem.  In TermManager, this returns None for contexts that are not known</p> <p>Parameters:</p> Name Type Description Default <code>flowable</code> <p>a string</p> required <code>quantity</code> <p>a quantity known to the quantity manager</p> <code>None</code> <code>context</code> <p>[None] default provide all contexts; must explicitly provide 'none' to filter by null context</p> <code>None</code> <p>Returns:</p> Type Description"},{"location":"reference/archives/term_manager/#archives.term_manager.TermManager.factors_for_quantity","title":"<code>factors_for_quantity(quantity, flowable=None, context=None, **kwargs)</code>","text":"<p>param dist [0] only used if compartment is specified. by default report only exact matches.</p> <p>Parameters:</p> Name Type Description Default <code>quantity</code> required <code>flowable</code> <code>None</code> <code>context</code> <code>None</code> <p>Returns:</p> Type Description"},{"location":"reference/archives/term_manager/#archives.term_manager.TermManager.flowables","title":"<code>flowables(search=None, origin=None, quantity=None)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>origin</code> <p>used in subclass</p> <code>None</code> <code>search</code> <code>None</code> <code>quantity</code> <code>None</code> <p>Returns:</p> Type Description"},{"location":"reference/archives/term_manager/#archives.term_manager.TermManager.get_flowable","title":"<code>get_flowable(term, strict=True)</code>","text":"<p>Input is a Flow or str</p> <p>Parameters:</p> Name Type Description Default <code>term</code> required <code>strict</code> <p>[True] if the input corresponds to more than one flowable and strict is True, raise FlowableConflict</p> <code>True</code> <p>Returns:</p> Type Description"},{"location":"reference/archives/term_manager/#archives.term_manager.TermManager.serialize","title":"<code>serialize(origin, *quantities, values=False)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>origin</code> <p>CFs are limited to: (for quantities belonging to origin) all CFs (for other quantities) only CFs that match origin. If origin is None, all quantities are serialized with all CFs</p> required <code>quantities</code> <code>()</code> <code>values</code> <code>False</code> <p>Returns:</p> Type Description <p>3-tuple: - serialized term manager as dict, - set of query quantity external refs, - set of reference quantity uuids == not sure WHY UUIDs rather than external refs, but that is what characterizations.py gives us</p>"},{"location":"reference/archives/term_manager/#archives.term_manager.TermManager.synonyms","title":"<code>synonyms(term)</code>","text":"<p>Search for synonyms, first in contexts, then flowables, then quantities. The somewhat awkward structure here is because of the dynamics of returning generators-- using try: return self._cm.synonyms(term) except KeyError: ... the KeyError was not getting caught because the generator was already returned before iterating.</p> <p>contexts are searched first, then quantities, then flowables</p> <p>Parameters:</p> Name Type Description Default <code>term</code> required <p>Returns:</p> Type Description"},{"location":"reference/archives/term_manager/#archives.term_manager.TermManager.unmatched_flowables","title":"<code>unmatched_flowables(flowables)</code>","text":"<p>Given an iterable of flowable strings, return a list of entries that were not recognized as synonyms to known flowables</p> <p>Parameters:</p> Name Type Description Default <code>flowables</code> required <p>Returns:</p> Type Description"},{"location":"reference/archives/tests/__init__/","title":"tests","text":""},{"location":"reference/catalog/__init__/","title":"init","text":""},{"location":"reference/catalog/catalog/","title":"catalog","text":"<p>The LcCatalog provides a semantic interface to a collection of (local and remote) read-only LcArchives, which provide access to physical data.</p> <p>It is made up of the following components:</p> <ul> <li>built on an LciaEngine</li> <li>local, persistent storage of resources, indexes, cache data + etc</li> <li>A resolver, which translates semantic origins into resources.  Input: semantic ref. output: CatalogInterface.</li> <li>an interface generator, which creates archive accessors on demand based on resource information from the resolver</li> </ul> <p>From the catalog_ref file, the catalog should meet the following spec:           Automatic - entity information            catalog.query(origin) - returns a query interface            catalog.lookup(origin, external_ref) - returns the origin of the lowest-priority resource resolving the ref            catalog.fetch(origin, external_ref) - return a reference to the object that can be queried + handled</p> <pre><code>      LC Queries:\n       see lcatools.interfaces.*\n</code></pre>"},{"location":"reference/catalog/catalog/#catalog.catalog.StaticCatalog","title":"<code>StaticCatalog</code>","text":"<p>               Bases: <code>object</code></p> <p>Provides query-based access to LCI information. The static version is ideal for creating read-only web resources from curated LcCatalogs. However, it must already exist. Only an LcCatalog (or subclasses) support de novo instantiation.</p> <p>A catalog is stored in the local file system and creates and stores resources relative to its root directory. Subfolders (all accessors return absolute paths): Public subfolders:  LcCatalog.resource_dir  LcCatalog.archive_dir</p> <p>Public filenames:  LcCatalog.cache_file(src) returns a sha1 hash of the source filename in the [absolute] cache dir  LcCatalog.download_file(src) returns a sha1 hash of the source filename in the [absolute] download dir</p> <p>Private folders + files:  LcCatalog._download_dir  LcCatalog._index_dir  LcCatalog._index_file(src) returns a sha1 hash of the source filename in the [absolute] index dir  LcCatalog._cache_dir  LcCatalog._entity_cache: local entities file in root  LcCatalog._reference_qtys: reference quantities file in root  LcCatalog._compartments: local compartments file (outmoded in Context Refactor)</p>"},{"location":"reference/catalog/catalog/#catalog.catalog.StaticCatalog.names","title":"<code>names</code>  <code>property</code>","text":"<p>List known references.</p> <p>Returns:</p> Type Description"},{"location":"reference/catalog/catalog/#catalog.catalog.StaticCatalog.qdb","title":"<code>qdb</code>  <code>property</code>","text":"<p>Provides query access to the quantity database. Should be like cat.query('local.qdb'), except that it provides a basic query- which is what internal quantities use themselves</p> <p>Returns:</p> Type Description"},{"location":"reference/catalog/catalog/#catalog.catalog.StaticCatalog.__init__","title":"<code>__init__(rootdir, strict_clookup=True, **kwargs)</code>","text":"<p>Instantiates a catalog based on the resources provided in resource_dir</p> <p>Parameters:</p> Name Type Description Default <code>rootdir</code> <p>directory storing LcResource files.</p> required <code>strict_clookup</code> <p>[True] whether to enforce uniqueness on characterization factors (raise an error when a non-matching duplicate characterization is encountered). If False, selection among conflicting factors is not well defined and may be done interactively or unpredictably</p> <code>True</code> <code>kwargs</code> <p>passed to Qdb</p> <code>{}</code>"},{"location":"reference/catalog/catalog/#catalog.catalog.StaticCatalog.add_nickname","title":"<code>add_nickname(nickname, origin, interface=None)</code>","text":"<p>alternate names for origins (optional interface) in the catalog</p> <p>Parameters:</p> Name Type Description Default <code>nickname</code> <p>short name to be used</p> required <code>origin</code> <p>origin to refer to</p> required <code>interface</code> <p>[None] interface to specify</p> <code>None</code> <p>Returns:</p> Type Description"},{"location":"reference/catalog/catalog/#catalog.catalog.StaticCatalog.gen_interfaces","title":"<code>gen_interfaces(origin, itype=None, strict=False)</code>","text":"<p>Generator of interfaces by spec</p> <p>Parameters:</p> Name Type Description Default <code>origin</code> required <code>itype</code> <p>single interface or iterable of interfaces</p> <code>None</code> <code>strict</code> <p>passed to resolver</p> <code>False</code> <p>Returns:</p> Type Description"},{"location":"reference/catalog/catalog/#catalog.catalog.StaticCatalog.get_resource","title":"<code>get_resource(name, iface=None, source=None, strict=True)</code>","text":"<p>retrieve a resource by providing enough information to identify it uniquely.  If strict is True (default), then parameters are matched exactly and more than one match raises an exception. If strict is False, then origins are matched approximately and the first (lowest-priority) match is returned.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <p>nickname or origin</p> required <code>iface</code> <code>None</code> <code>source</code> <code>None</code> <code>strict</code> <code>True</code> <p>Returns:</p> Type Description"},{"location":"reference/catalog/catalog/#catalog.catalog.StaticCatalog.lookup","title":"<code>lookup(catalog_ref)</code>","text":"<p>Attempts to return a valid grounded reference matching the one supplied. :deprecated keep_properties: [False] if True, apply incoming ref's properties to grounded ref, probably with a prefix or something.</p> <p>Parameters:</p> Name Type Description Default <code>catalog_ref</code> required <p>Returns:</p> Type Description"},{"location":"reference/catalog/catalog/#catalog.catalog.StaticCatalog.query","title":"<code>query(origin, strict=False, refresh=False, cache=True, **kwargs)</code>","text":"<p>Returns a query using the first interface to match the origin.</p> <p>Parameters:</p> Name Type Description Default <code>origin</code> required <code>strict</code> <p>[False] whether the resolver should match the origin exactly, as opposed to returning more highly specified matches.  e.g. with strict=False, a request for 'local.traci' could be satisfied by 'local.traci.2.1' whereas if strict=True, only a resource matching 'local.traci' exactly will be returned</p> <code>False</code> <code>refresh</code> <p>[False] by default, the catalog stores a CatalogQuery instance for every requested origin.  With refresh=True, any prior instance will be replaced with a fresh one.</p> <code>False</code> <code>cache</code> <p>[True] whether to retain the query</p> <code>True</code> <code>kwargs</code> <code>{}</code> <p>Returns:</p> Type Description"},{"location":"reference/catalog/catalog/#catalog.catalog.StaticCatalog.resources","title":"<code>resources(origin=None, loaded=None)</code>","text":"<p>Generate a list of resources known to the resolver.  Optionally filter by origin prefix and by whether the resource has been loaded.</p> <p>Parameters:</p> Name Type Description Default <code>origin</code> <code>None</code> <code>loaded</code> <p>True | False | [None]</p> <code>None</code> <p>Returns:</p> Type Description"},{"location":"reference/catalog/catalog_root/","title":"catalog_root","text":"<p>CATALOG_ROOT specifies the local folder that stores the reference catalog It must either:  - be specified in an environment variable os.environ['ANTELOPE_CATALOG_ROOT'],  - or as a file in the local directory named antelope_catalog_root</p> <p>Used as a default location for testing and benchmarking.</p>"},{"location":"reference/catalog/configurator/","title":"configurator","text":""},{"location":"reference/catalog/configurator/#catalog.configurator.Configurator","title":"<code>Configurator</code>","text":"<p>               Bases: <code>object</code></p>"},{"location":"reference/catalog/configurator/#catalog.configurator.Configurator.add_config","title":"<code>add_config(option, *args)</code>","text":"<p>Add a configuration setting to the resource, and apply it to the archive.</p> <p>Parameters:</p> Name Type Description Default <code>option</code> <p>the option being configured</p> required <code>args</code> <p>the arguments, in the proper sequence</p> <code>()</code> <p>Returns:</p> Type Description <p>None if archive doesn't support configuration; False if unsuccessful, True if successful</p>"},{"location":"reference/catalog/configurator/#catalog.configurator.Configurator.check_contexts","title":"<code>check_contexts()</code>","text":"<p>Compares contexts known to the resource with contexts known to the captive LCIA engine.  Prints matching contexts. Returns a list of non-matching contexts.</p> <p>Returns:</p> Type Description"},{"location":"reference/catalog/configurator/#catalog.configurator.Configurator.check_quantities","title":"<code>check_quantities()</code>","text":"<p>Compares quantities known to the resource with quantities known to the captive LCIA engine.  Prints recognized quantities. Returns a list of unknown quantities.</p> <p>Returns:</p> Type Description"},{"location":"reference/catalog/configurator/#catalog.configurator.Configurator.unmatched_flowables","title":"<code>unmatched_flowables()</code>","text":"<p>Compares flowables known to the resource with flowables known to the captive LCIA engine.  Returns a list of non-matching flowables (does not print known flowables).</p> <p>Returns:</p> Type Description"},{"location":"reference/catalog/lc_catalog/","title":"lc_catalog","text":""},{"location":"reference/catalog/lc_catalog/#catalog.lc_catalog.LcCatalog","title":"<code>LcCatalog</code>","text":"<p>               Bases: <code>StaticCatalog</code></p> <p>A catalog that supports adding and manipulating resources during runtime</p>"},{"location":"reference/catalog/lc_catalog/#catalog.lc_catalog.LcCatalog.add_existing_archive","title":"<code>add_existing_archive(archive, interfaces=None, store=True, **kwargs)</code>","text":"<p>Makes a resource record out of an existing archive.  by default, saves it in the catalog's resource dir</p> <p>Parameters:</p> Name Type Description Default <code>archive</code> required <code>interfaces</code> <code>None</code> <code>store</code> <p>[True] if False, don't save the record - use it for this session only</p> <code>True</code> <code>kwargs</code> <code>{}</code> <p>Returns:</p> Type Description"},{"location":"reference/catalog/lc_catalog/#catalog.lc_catalog.LcCatalog.add_resource","title":"<code>add_resource(resource, store=True, replace=False)</code>","text":"<p>Add an existing LcResource to the catalog.</p> <p>Parameters:</p> Name Type Description Default <code>resource</code> required <code>store</code> <p>[True] permanently store this resource</p> <code>True</code> <code>replace</code> <p>[False] if the resource already exists, remove it and replace it with the new resource</p> <code>False</code> <p>Returns:</p> Type Description"},{"location":"reference/catalog/lc_catalog/#catalog.lc_catalog.LcCatalog.blackbook_authenticate","title":"<code>blackbook_authenticate(blackbook_url=None, username=None, password=None, token=None, **kwargs)</code>","text":"<p>Opens an authenticated session with the designated blackbook server.  Credentials can either be provided to the method as arguments, or if omitted, they can be obtained through a form.  If a token is provided, it is used in lieu of a password workflow</p> <p>Parameters:</p> Name Type Description Default <code>blackbook_url</code> <code>None</code> <code>username</code> <code>None</code> <code>password</code> <code>None</code> <code>token</code> <code>None</code> <code>kwargs</code> <p>passed to RestClient. save_credentials=True.  verify: provide path to self-signed certificate</p> <code>{}</code> <p>Returns:</p> Type Description"},{"location":"reference/catalog/lc_catalog/#catalog.lc_catalog.LcCatalog.blackbook_request_third_party_resource","title":"<code>blackbook_request_third_party_resource(origin, resource_for)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>origin</code> <p>the data resource</p> required <code>resource_for</code> <p>the foreground that needs access</p> required <p>Returns:</p> Type Description"},{"location":"reference/catalog/lc_catalog/#catalog.lc_catalog.LcCatalog.create_descendant","title":"<code>create_descendant(origin, interface=None, source=None, force=False, signifier=None, strict=True, priority=None, **kwargs)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>origin</code> required <code>interface</code> <code>None</code> <code>source</code> <code>None</code> <code>force</code> <p>overwrite if exists</p> <code>False</code> <code>signifier</code> <p>semantic descriptor for the new descendant (optional)</p> <code>None</code> <code>strict</code> <code>True</code> <code>priority</code> <code>None</code> <code>kwargs</code> <code>{}</code> <p>Returns:</p> Type Description"},{"location":"reference/catalog/lc_catalog/#catalog.lc_catalog.LcCatalog.create_source_cache","title":"<code>create_source_cache(source, static=False)</code>","text":"<p>Creates a cache of the named source's current contents, to speed up access to commonly used entities. source must be either a key present in self.sources, or a name or nickname found in self.names</p> <p>Parameters:</p> Name Type Description Default <code>source</code> required <code>static</code> <p>[False] create archives of a static archive (use to force archival of a complete database)</p> <code>False</code> <p>Returns:</p> Type Description"},{"location":"reference/catalog/lc_catalog/#catalog.lc_catalog.LcCatalog.delete_resource","title":"<code>delete_resource(resource, delete_source=None, delete_cache=True)</code>","text":"<p>Removes the resource from the resolver and also removes the serialization of the resource. Also deletes the resource's source (as well as all files in the same directory that start with the same name) under the following circumstances:  (resource is internal AND resources_with_source(resource.source) is empty AND resource.source is a file) This can be overridden using he delete_source param (see below)</p> <p>We also need to remove any implementations that use the resource.</p> <p>Parameters:</p> Name Type Description Default <code>resource</code> <p>an LcResource</p> required <code>delete_source</code> <p>[None] If None, follow default behavior. If True, delete the source even if it is not internal (source will not be deleted if other resources refer to it OR if it is not a file). If False, do not delete the source.</p> <code>None</code> <code>delete_cache</code> <p>[True] whether to delete cache files (you could keep them around if you expect to need them again and you don't think the contents will have changed)</p> <code>True</code> <p>Returns:</p> Type Description"},{"location":"reference/catalog/lc_catalog/#catalog.lc_catalog.LcCatalog.download_file","title":"<code>download_file(url=None, md5sum=None, force=False, localize=True)</code>","text":"<p>Download a file from a remote location into the catalog and return its local path.  Optionally validate the download with an MD5 digest.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>None</code> <code>md5sum</code> <code>None</code> <code>force</code> <code>False</code> <code>localize</code> <p>whether to return the filename relative to the catalog root</p> <code>True</code> <p>Returns:</p> Type Description <p>the full path to the downloaded file</p>"},{"location":"reference/catalog/lc_catalog/#catalog.lc_catalog.LcCatalog.gen_interfaces","title":"<code>gen_interfaces(origin, itype=None, strict=False)</code>","text":"<p>Override parent method to also create local backgrounds</p> <p>Parameters:</p> Name Type Description Default <code>origin</code> required <code>itype</code> <code>None</code> <code>strict</code> <code>False</code> <p>Returns:</p> Type Description"},{"location":"reference/catalog/lc_catalog/#catalog.lc_catalog.LcCatalog.get_blackbook_resources","title":"<code>get_blackbook_resources(origin, store=False, assign_ref=None, **kwargs)</code>","text":"<p>Use a blackbook server to obtain resources for a given origin.</p> <p>Parameters:</p> Name Type Description Default <code>origin</code> required <code>store</code> <p>whether to save resources. by default we don't, assuming the tokens are short-lived.</p> <code>False</code> <code>assign_ref</code> <p>give the resource a named ref locally</p> <code>None</code> <code>kwargs</code> <p>init args to add to returned resources, such as 'verify' certificate paths</p> <code>{}</code> <p>Returns:</p> Type Description"},{"location":"reference/catalog/lc_catalog/#catalog.lc_catalog.LcCatalog.index_ref","title":"<code>index_ref(origin, interface=None, source=None, priority=60, save=True, force=False, strict=True)</code>","text":"<p>Creates an index for the specified resource.  'origin' and 'interface' must resolve to one or more LcResources that all have the same source specification.  That source archive gets indexed, and index resources are created for all the LcResources that were returned.</p> <p>Performs load_all() on the source archive, writes the archive to a compressed json file in the local index directory, and creates a new LcResource pointing to the JSON file.   Aborts if the index file already exists (override with force=True).</p> <p>Parameters:</p> Name Type Description Default <code>origin</code> required <code>interface</code> <p>[None]</p> <code>None</code> <code>source</code> <p>find_single_source input</p> <code>None</code> <code>priority</code> <p>[60] priority setting for the new index -- authentic source is highest</p> <code>60</code> <code>save</code> <p>[True] whether to save the index</p> <code>True</code> <code>force</code> <p>[False] if True, overwrite existing index</p> <code>False</code> <code>strict</code> <p>[True] whether to be strict</p> <code>True</code> <p>Returns:</p> Type Description"},{"location":"reference/catalog/lc_catalog/#catalog.lc_catalog.LcCatalog.make_tester","title":"<code>make_tester(**kwargs)</code>  <code>classmethod</code>","text":"<p>This is no longer necessary; the same thing can be accomplished just by calling the constructor with no root.</p> <p>Parameters:</p> Name Type Description Default <code>kwargs</code> <code>{}</code> <p>Returns:</p> Type Description"},{"location":"reference/catalog/lc_catalog/#catalog.lc_catalog.LcCatalog.new_resource","title":"<code>new_resource(reference, source, ds_type, store=True, **kwargs)</code>","text":"<p>Create a new data resource by specifying its properties directly to the constructor</p> <p>Parameters:</p> Name Type Description Default <code>reference</code> required <code>source</code> required <code>ds_type</code> required <code>store</code> <p>[True] permanently store this resource</p> <code>True</code> <code>kwargs</code> <p>interfaces=None, priority=0, static=False; **kwargs passed to archive constructor</p> <code>{}</code> <p>Returns:</p> Type Description"},{"location":"reference/catalog/lc_catalog/#catalog.lc_catalog.LcCatalog.purge_resource_archive","title":"<code>purge_resource_archive(resource)</code>","text":"<ul> <li>find all cached queries that could return the resource</li> <li>check their cached ifaces to see if they use our archive</li> <li>delete those entries from the cache</li> </ul> <p>Parameters:</p> Name Type Description Default <code>resource</code> <code>LcResource</code> required <p>Returns:</p> Type Description"},{"location":"reference/catalog/lc_catalog/#catalog.lc_catalog.LcCatalog.refresh_xdb_tokens","title":"<code>refresh_xdb_tokens(remote_origin=None)</code>","text":"<p>requires an active blackbook client (try blackbook_authenticate() if it has expired)</p> <p>Parameters:</p> Name Type Description Default <code>remote_origin</code> <code>None</code> <p>Returns:</p> Type Description"},{"location":"reference/catalog/lc_resolver/","title":"lc_resolver","text":""},{"location":"reference/catalog/lc_resolver/#catalog.lc_resolver.LcCatalogResolver","title":"<code>LcCatalogResolver</code>","text":"<p>               Bases: <code>object</code></p> <p>The resolver maintains a collection of resources, and translates semantic origins into physical archives. The Catalog supplies a request and a level requirement  It also acts as a factory for those resources, so when a request is provided, it is answered with a live archive.</p> <p>Then the Catalog turns that into a static archive and keeps a list of it. The catalog also keeps a separate  list of foreground foregrounds (which are not static; which contain fragments). These can be converted into static  archives by turning the fragments into processes.</p> <p>This file could probably be re-thought, especially in the era of resources delivered via web.  For now, we will  monkeypatch.</p>"},{"location":"reference/catalog/lc_resolver/#catalog.lc_resolver.LcCatalogResolver.origins","title":"<code>origins</code>  <code>property</code>","text":"<p>Generates pairs: origin, list of supported interfaces</p> <p>Returns:</p> Type Description"},{"location":"reference/catalog/lc_resolver/#catalog.lc_resolver.LcCatalogResolver.add_resource","title":"<code>add_resource(resource, store=True)</code>","text":"<p>Add a resource to the resolver's list.  By default, save the resource permanently as a file in resources dir.</p> <p>Parameters:</p> Name Type Description Default <code>resource</code> required <code>store</code> <p>[True] if False, add the resource to memory only</p> <code>True</code> <p>Returns:</p> Type Description"},{"location":"reference/catalog/lc_resolver/#catalog.lc_resolver.LcCatalogResolver.delete_origin","title":"<code>delete_origin(origin)</code>","text":"<p>remove all resources for a given origin.</p> <p>Parameters:</p> Name Type Description Default <code>origin</code> required <p>Returns:</p> Type Description"},{"location":"reference/catalog/lc_resolver/#catalog.lc_resolver.LcCatalogResolver.get_resource","title":"<code>get_resource(ref=None, iface=None, source=None, strict=True, include_internal=True)</code>","text":"<p>The purpose of this function is to allow a user to retrieve a resource by providing enough information to identify it uniquely.  If strict is True (default), then parameters are matched exactly and more than one match raises an exception. If strict is False, then origins are matched approximately and the first (lowest-priority) match is returned.</p> <p>The convention is that no two resources should have the same source, so if a source is provided then the output of resources_with_source() is used.  Otherwise, the output of resolve() is used.  Internal resources (indexes and archives) are never returned. [WHY?]</p> <p>Returns:</p> Type Description <p>a single LcResource</p>"},{"location":"reference/catalog/lc_resolver/#catalog.lc_resolver.LcCatalogResolver.resolve","title":"<code>resolve(req, interfaces=None, strict=False)</code>","text":"<p>Fuzzy resolver returns all resources that match the request and have equal or greater specificity. 'uslci.clean' will match queries for 'uslci' but not for 'uslci.original' or 'uslci.clean.allocated'. However, 'uslci.clean.allocated' will match a query for 'uslci.clean'</p> <p>Parameters:</p> Name Type Description Default <code>req</code> required <code>interfaces</code> <p>could be a single interface specification or a list</p> <code>None</code> <code>strict</code> <p>[False] if true, only yields interface for which req matches ref</p> <code>False</code> <p>Returns:</p> Type Description"},{"location":"reference/catalog/tests/__init__/","title":"tests","text":""},{"location":"reference/data_sources/__init__/","title":"init","text":""},{"location":"reference/data_sources/data_source/","title":"data_source","text":""},{"location":"reference/data_sources/data_source/#data_sources.data_source.DataCollection","title":"<code>DataCollection</code>","text":"<p>               Bases: <code>DataSource</code></p> <p>A container for a number of related data sources.  Uses a factory to generate the data sources, and then spools out their results.</p>"},{"location":"reference/data_sources/data_source/#data_sources.data_source.DataSource","title":"<code>DataSource</code>","text":"<p>               Bases: <code>object</code></p> <p>An abstract class that defines how data sources are handled.</p>"},{"location":"reference/data_sources/data_source/#data_sources.data_source.DataSource.origins","title":"<code>origins</code>  <code>property</code>","text":"<p>Generates a list of semantic origins the DataSource knows how to instantiate</p> <p>Returns:</p> Type Description"},{"location":"reference/data_sources/data_source/#data_sources.data_source.DataSource.interfaces","title":"<code>interfaces(ref)</code>","text":"<p>Generates a list of interfaces known for the given reference. the reference must be in the list of origins.</p> <p>Parameters:</p> Name Type Description Default <code>ref</code> required <p>Returns:</p> Type Description"},{"location":"reference/data_sources/data_source/#data_sources.data_source.DataSource.make_resources","title":"<code>make_resources(ref)</code>","text":"<p>Generates an exhaustive sequence of LcResource objects for a given reference.</p> <p>Parameters:</p> Name Type Description Default <code>ref</code> required <p>Returns:</p> Type Description"},{"location":"reference/data_sources/data_source/#data_sources.data_source.DataSource.test_params","title":"<code>test_params(ref, interface)</code>","text":"<p>User supplies a reference and interface. This function returns a 2-tuple:   - kwargs to pass as input arguments   - expected output</p> <p>This function can't be written until the tests are designed.</p> <p>Parameters:</p> Name Type Description Default <code>ref</code> required <code>interface</code> required <p>Returns:</p> Type Description"},{"location":"reference/data_sources/ecoinvent/","title":"ecoinvent","text":""},{"location":"reference/data_sources/ecoinvent/#data_sources.ecoinvent.Ecoinvent2Base","title":"<code>Ecoinvent2Base</code>","text":"<p>               Bases: <code>DataSource</code></p>"},{"location":"reference/data_sources/ecoinvent/#data_sources.ecoinvent.Ecoinvent2Base.origins","title":"<code>origins</code>  <code>property</code>","text":"<p>Generates a list of semantic origins the DataSource knows how to instantiate</p> <p>Returns:</p> Type Description"},{"location":"reference/data_sources/ecoinvent/#data_sources.ecoinvent.Ecoinvent2Base.interfaces","title":"<code>interfaces(ref)</code>","text":"<p>Generates a list of interfaces known for the given reference. the reference must be in the list of origins.</p> <p>Parameters:</p> Name Type Description Default <code>ref</code> required <p>Returns:</p> Type Description"},{"location":"reference/data_sources/ecoinvent/#data_sources.ecoinvent.Ecoinvent2Base.make_resources","title":"<code>make_resources(ref)</code>","text":"<p>Generates an exhaustive sequence of LcResource objects for a given reference.</p> <p>Parameters:</p> Name Type Description Default <code>ref</code> required <p>Returns:</p> Type Description"},{"location":"reference/data_sources/ecoinvent/#data_sources.ecoinvent.EcoinventConfig","title":"<code>EcoinventConfig</code>","text":"<p>               Bases: <code>DataCollection</code></p> <p>Ecoinvent Configurator This DataCollection generates LcResource objects for ecoinvent archives.  The only required input is the root folder containing the ecoinvent data.  Within this folder should be subfolders named after the major and minor version of the database (e.g. \"3.3\"). Within the subfolders should be the archives.</p> <p>Archives must be named according to ecoinvent's various conventions:  #1#2_#3_ecoSpold02#4 where  #1 is one of ('current_Version_' or 'ecoinvent ')  #2 is the major and minor version ('2.2', '3.01', '3.1', '3.2', etc)  #3 is the system model ('apos', 'cutoff', 'consequential', or 'consequential_longterm')  #4 is either omitted (in the case of an expanded directory) or an archive extension ('.zip' or '.7z')</p> <p>Within the archives, either compressed or expanded, the datasets are assumed to be in a subfolder called 'datasets'</p> <p>The class does not currently support loading undefined data collections, but this could be added in the future.</p>"},{"location":"reference/data_sources/ecoinvent_lcia/","title":"ecoinvent_lcia","text":""},{"location":"reference/data_sources/gwp_ipcc_2007/","title":"gwp_ipcc_2007","text":""},{"location":"reference/data_sources/gwp_ipcc_2007/#data_sources.gwp_ipcc_2007.GwpIpcc2007","title":"<code>GwpIpcc2007</code>","text":"<p>               Bases: <code>DataSource</code></p>"},{"location":"reference/data_sources/gwp_ipcc_2007/#data_sources.gwp_ipcc_2007.GwpIpcc2007.origins","title":"<code>origins</code>  <code>property</code>","text":"<p>There's a precedence issue here, becaue the class MUST yield the same reference name as what's encoded in the JSON file, but it is wasteful to load the JSON file just to learn the canonical ref.  The \"proper\" way to do this is to [better] manage the workflow by which the JSON file is created (i.e. in antelope_utilities) and then use the same ref for both paths.</p> <p>heh- I hint at this challenge in the definite source by naming it AUTHORIZED_REF</p> <p>Returns:</p> Type Description"},{"location":"reference/data_sources/local/","title":"local","text":"<p>Code for generating a catalog populated with local data sources.  This is where active workflow development can occur.  See GitHub root / workflow.txt for thoughts.</p> <p>MAIN IDEA:  local.py:   The local config file. specifies source locations and resource-specific configurations for data sources.   It must define the following variables:    CATALOG_ROOT = location to build a permanent data catalog    TEST_ROOT = location to store temporary test materials (blown away after every use)    RESOURCES_CONFIG = a dict mapping source nicknames to instantiation parameters.     The instantiation parameters have two required keys:      'source': key whose value is an executable DataSource subclass      'enable_test': key whose absence (or falsity) will suppress tests.     All other kv pairs in the dict are passed as input arguments to the DataSource.</p> <p>data_source.py:   provides an abstract class for specifying data sources.  Each data source should be defined as a   subclass of DataSource that implements its interface.</p> <p>tests/test_local.py:   uses local.py to generate and validate the persistent catalog at the location specified in CATALOG_ROOT.</p> <p>TO ADD A NEW DATA SOURCE:</p> <ol> <li>Produce a resource factory for your data source.</li> </ol> <p>1a. Create or locate an appropriate DataSource subclass, and implement its abstract methods:      references: generate a list of semantic references the class knows how to instantiate      interfaces(ref): generate a list of interfaces known for the given ref (ref must be in references)      make_resources(ref): generate an exhaustive sequence of LcResource objects for a given ref</p> <p>1b. Make sure the resources created by your DataSource subclass include any necessary configuration information</p> <ol> <li>Provide configuration info for your data source</li> </ol> <p>2a. Import your DataSource subclass here.</p> <p>2b. Create an entry in RESOURCES_CONFIG with at minimum the 'source' and 'enable_test' keys, as well as any      necessary input arguments.</p> <ol> <li>Run python -m unittest lcatools/data_sources/tests/test_local.py</li> </ol>"},{"location":"reference/data_sources/local/#data_sources.local.RESOURCES_CONFIG","title":"<code>RESOURCES_CONFIG = {'ipcc2007': {'source': GwpIpcc2007, 'enable_test': True}, 'uslci': {'source': UsLciConfig, 'enable_test': True}, 'traci': {'source': TraciConfig, 'data_root': '/data/LCI/TRACI/', 'enable_test': True}}</code>  <code>module-attribute</code>","text":"<p>RESOURCES_CONFIG_LOCAL = {     'ecoinvent': {         'source': EcoinventConfig,         'data_root': '/data/LCI/Ecoinvent/',         'enable_test': False     },     'calrecycle': {         'source': CalRecycleConfig,         'data_root': '/data/GitHub/CalRecycle/LCA_Data/',         'enable_test': False     },     'ecoinvent_lcia': {         'source': EcoinventLciaConfig,         'version': '3.1',         'data_root': '/data/LCI/Ecoinvent/LCIA/',         'enable_test': False     } }</p> <p>RESOURCES_CONFIG.update(RESOURCES_CONFIG_LOCAL)  # still trying to figure out the best way to do this</p>"},{"location":"reference/data_sources/traci/","title":"traci","text":""},{"location":"reference/data_sources/traci/#data_sources.traci.TraciConfig","title":"<code>TraciConfig</code>","text":"<p>               Bases: <code>DataSource</code></p>"},{"location":"reference/data_sources/traci/#data_sources.traci.TraciConfig.make_resources","title":"<code>make_resources(ref)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>ref</code> <p>can be a full reference OR a version (e.g. '2.1')</p> required <p>Returns:</p> Type Description"},{"location":"reference/data_sources/tests/__init__/","title":"tests","text":""},{"location":"reference/data_sources/uslci/__init__/","title":"init","text":""},{"location":"reference/data_sources/uslci/uslci/","title":"uslci","text":""},{"location":"reference/data_sources/uslci/uslci/#data_sources.uslci.uslci.VALID_FORMATS","title":"<code>VALID_FORMATS = ('olca', 'ecospold')</code>  <code>module-attribute</code>","text":"<p>Former unset_reference - made superfluous by removing spurious set_reference() in OpenLcaJsonLDArchive._get_rx           [             \"0aaf1e13-5d80-37f9-b7bb-81a6b8965c71\",  # activity-as-reference             \"471bcc19-36f7-3ad8-b3ae-e39d2ab5fe44\",             \"Output\"           ], (actually, I think we brought this back as well)</p> <p>Former config hints - made superfluous by Context._auto_sense</p> <pre><code> [\"context\", \"water\", \"to water\"],\n [\"context\", \"air\", \"to air\"],\n</code></pre> <p>(actually not superfluous because of native contexts of the bonkers sort as  \"Elementary Flows / NETL Elementary Flows / Air\" which not even auto sense could catch so we're bringing em back</p>"},{"location":"reference/entities/__init__/","title":"init","text":""},{"location":"reference/entities/anchors/","title":"anchors","text":""},{"location":"reference/entities/anchors/#entities.anchors.Anchor","title":"<code>Anchor</code>","text":"<p>               Bases: <code>object</code></p> <p>An anchor is the distal partner to an exchange.</p>"},{"location":"reference/entities/anchors/#entities.anchors.Anchor.flow_conversion","title":"<code>flow_conversion</code>  <code>property</code>","text":"<p>express the parent's flow in terms of the quantity of the term flow. There are two ways to do this, each case involving the quantity relation on either the parent flow or the term flow, between the two quantities (parent flow's r.q. is the reference quantity; term flow's r.q. is the query quantity).</p> <p>In each case, we want the flow's native term manager to perform the conversion using ITS OWN canonical quantities.  The assumption is that the parent flow's r.q. is tied to our local LciaEngine, while the term flow's r.q. could be either local or remote.</p> <p>The QuantityRef.quantity_relation() implicitly assumes that the invoking quantity is the QUERY quantity, so the \"forward\" (natural parent-&gt;node) direction uses the remote flow's r.q. - but we do the \"reverse\" direction first because it's local.</p> <p>how to deal with scenario cfs? tbd problem is, the term doesn't know its own scenario</p> <p>Returns:</p> Type Description <p>float = amount in term_flow ref qty that corresponds to a unit of fragment flow's ref qty</p>"},{"location":"reference/entities/anchors/#entities.anchors.Anchor.is_context","title":"<code>is_context</code>  <code>property</code>","text":"<p>termination is a context</p> <p>Returns:</p> Type Description"},{"location":"reference/entities/anchors/#entities.anchors.Anchor.is_emission","title":"<code>is_emission</code>  <code>property</code>","text":"<p>Pending context refactor</p> <p>Returns:</p> Type Description"},{"location":"reference/entities/anchors/#entities.anchors.Anchor.is_frag","title":"<code>is_frag</code>  <code>property</code>","text":"<p>Termination is a fragment</p> <p>Returns:</p> Type Description"},{"location":"reference/entities/anchors/#entities.anchors.Anchor.is_subfrag","title":"<code>is_subfrag</code>  <code>property</code>","text":"<p>Termination is a non-self fragment.</p> <p>Returns:</p> Type Description"},{"location":"reference/entities/anchors/#entities.anchors.Anchor.__init__","title":"<code>__init__(parent, anchor_node, anchor_flow=None, descend=None)</code>","text":"<p>An anchor can be one of the following five types:  - null: a cut-off. The fragment is an input/output of the spanner  - foreground: the fragment is its own anchor.  - process: the fragment is anchored to a process with inventory  - sub-fragment: the fragment is anchored to another spanner  - context: the fragment is an exchange with a context</p> <p>Parameters:</p> Name Type Description Default <code>parent</code> required <code>anchor_node</code> required <code>anchor_flow</code> <code>None</code> <code>descend</code> <code>None</code>"},{"location":"reference/entities/anchors/#entities.anchors.Anchor.__str__","title":"<code>__str__()</code>","text":"<p>This is repeated at least once in the Anchor model</p> <p>Returns:</p> Type Description <p>'---:' = fragment I/O '-O  ' = foreground node '-*  ' = process '-#  ' - sub-fragment (aggregate) '-#::' - sub-fragment (descend) '-B ' - terminated background '--C ' - cut-off background '--? ' - ungrounded catalog ref</p>"},{"location":"reference/entities/anchors/#entities.anchors.Anchor.compute_unit_score","title":"<code>compute_unit_score(quantity_ref, refresh=False, **kwargs)</code>","text":"<p>four different ways to do this. 0- we are a subfragment-- no direct impacts unless non-descend, which is caught earlier 1- parent is bg: ask catalog to give us bg_lcia (process or fragment) 2- get fg lcia for unobserved exchanges</p> <p>If</p> <p>Parameters:</p> Name Type Description Default <code>quantity_ref</code> required <code>refresh</code> <code>False</code> <p>Returns:</p> Type Description"},{"location":"reference/entities/anchors/#entities.anchors.Anchor.score_cache","title":"<code>score_cache(quantity=None, refresh=False, **kwargs)</code>","text":"<p>only process-terminations are cached remote fragments that come back via the API can have cached scores as well, but local subfragments should not get cached.</p> <p>Parameters:</p> Name Type Description Default <code>quantity</code> <code>None</code> <code>refresh</code> <p>If True, re-compute unit score even if it is already present in the cache.</p> <code>False</code> <code>kwargs</code> <code>{}</code> <p>Returns:</p> Type Description"},{"location":"reference/entities/anchors/#entities.anchors.Anchor.unobserved_exchanges","title":"<code>unobserved_exchanges()</code>","text":"<p>Generator which yields exchanges from the term node's inventory that are not found among the child flows, for   LCIA purposes</p> <p>Challenge here going forward: we made some kind of normative decision early on that terminations do not know their own scenarios, that the fragment maps scenario to termination. The problem is that now terminations cannot themselves carry out traversal on the term_node because they don't know what scenarios to pass.</p> <p>The upshot is that we cannot meaningfully compute \"unobserved exchanges\" for subfragments, since we don't know our scenario.</p> <p>Returns:</p> Type Description"},{"location":"reference/entities/anchors/#entities.anchors.UnCachedScore","title":"<code>UnCachedScore</code>","text":"<p>               Bases: <code>Exception</code></p> <p>means that we have an LCIA-only node whose score has not been set for the requested LCIA method</p>"},{"location":"reference/entities/entities/","title":"entities","text":""},{"location":"reference/entities/entities/#entities.entities.LcEntity","title":"<code>LcEntity</code>","text":"<p>               Bases: <code>BaseEntity</code></p> <p>All LC entities behave like dicts, but they all have some common properties, defined here.</p>"},{"location":"reference/entities/entities/#entities.entities.LcEntity.is_entity","title":"<code>is_entity</code>  <code>property</code>","text":"<p>Used to distinguish between entities and catalog refs (which answer False)</p> <p>Returns:</p> Type Description <p>True for LcEntity subclasses</p>"},{"location":"reference/entities/entities/#entities.entities.LcEntity.__eq__","title":"<code>__eq__(other)</code>","text":"<p>two entities are equal if their types, origins, and external references are the same. internal refs do not need to be equal; reference entities do not need to be equal</p> <p>Returns:</p> Type Description"},{"location":"reference/entities/entities/#entities.entities.LcEntity.__hash__","title":"<code>__hash__()</code>","text":"<p>External ref is set by the end of init and is immutable (except for fragments-- which use uuid for hash)</p> <p>Returns:</p> Type Description"},{"location":"reference/entities/entities/#entities.entities.LcEntity.get_properties","title":"<code>get_properties()</code>","text":"<p>dict of properties and values for a given entity</p> <p>Returns:</p> Type Description"},{"location":"reference/entities/entities/#entities.entities.LcEntity.map_origin","title":"<code>map_origin(omap, fallback=None)</code>","text":"<p>This is used to propagate a change in origin semantics. Provide a dict that maps old origins to new origins. External ref should remain the same with respect to the new origin.</p> <p>Parameters:</p> Name Type Description Default <code>omap</code> <p>dict mapping old origin to new origin</p> required <code>fallback</code> <p>if present, use in cases where old origin not found</p> <code>None</code> <p>Returns:</p> Type Description"},{"location":"reference/entities/flows/","title":"flows","text":""},{"location":"reference/entities/flows/#entities.flows.LcFlow","title":"<code>LcFlow</code>","text":"<p>               Bases: <code>LcEntity</code>, <code>Flow</code></p>"},{"location":"reference/entities/flows/#entities.flows.LcFlow.new","title":"<code>new(name, ref_qty, **kwargs)</code>  <code>classmethod</code>","text":"<p>Parameters:</p> Name Type Description Default <code>name</code> <p>the name of the flow</p> required <code>ref_qty</code> <p>the reference quantity</p> required <p>Returns:</p> Type Description"},{"location":"reference/entities/fragments/","title":"fragments","text":""},{"location":"reference/entities/fragments/#entities.fragments.Fragment","title":"<code>Fragment</code>","text":"<p>               Bases: <code>LcEntity</code></p> <p>What can I say? THey're complicated. Conceptually, a fragment is a modeler's tool for keeping track of measurements of a specific material flow.</p> <p>A fragment's main purpose is to express a linkage between a parent node and a target or 'anchor' node by means of an observed flow.</p> <p>Fragments have the following broad functionalities:</p> <ul> <li>they can be named. external_ref can be set. not clear why this is only for fragments, but it is meant to  provide h-r semantic consistency / clarity during data use</li> <li>they can be observed. a fragment has a cached and an observed exchange value. the cached value is meant to  indicate its value upon creation, and observed is the default value returned upon quantitative queries.  observations take the form of a scenario specification and an exchange value (along with metadata such as dqi,  uncertainty, etc)</li> <li>they can be anchored, to data sets or to other models.  anchor points are also specified by scenario. anchors  can be toggled to \"descend\" (i.e. expand sub-fragments) or non-descend / roll-up sub-fragments</li> <li>they have child flows. \"reference flows\" have no parent and supply/consume a good or service through exchange  with a second party.  Child flows are then dependent on the reference flow. By traversing these links to their  ends, the entire \"span\" of the study can be enumerated. It is the job of the traversal engine to ensure that  traversal terminates upon reaching a background node (i.e. one with membership in a cycle) to a flat LCI.</li> <li>they can balance. Each fragment node (the thing that is 'anchored') can compute a balance during traversal,  assigning a designated child flow the magnitude of the balance at traversal time.  The quantity that is conserved  is precisely the designated balance flow's reference quantity.  all flows are queried for characterization  in computing the balance.</li> <li>STILL TBD: how to handle \"balancing\" into and out of anchored subfragments</li> </ul>"},{"location":"reference/entities/fragments/#entities.fragments.Fragment.unit","title":"<code>unit</code>  <code>property</code>","text":"<p>used for formatting the fragment in display</p> <p>Returns:</p> Type Description"},{"location":"reference/entities/fragments/#entities.fragments.Fragment.__hash__","title":"<code>__hash__()</code>","text":"<p>Fragments must use UUID as hash because the link is mutable</p> <p>Returns:</p> Type Description"},{"location":"reference/entities/fragments/#entities.fragments.Fragment.add_child","title":"<code>add_child(child)</code>","text":"<p>This should only be called from the child's set_parent function</p> <p>Parameters:</p> Name Type Description Default <code>child</code> required <p>Returns:</p> Type Description"},{"location":"reference/entities/fragments/#entities.fragments.Fragment.de_name","title":"<code>de_name()</code>","text":"<p>Remove a fragment's name</p> <p>Returns:</p> Type Description"},{"location":"reference/entities/fragments/#entities.fragments.Fragment.ev","title":"<code>ev(scenarios=None)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>scenarios</code> <p>either None, or an iterable of scenarios</p> <code>None</code> <p>Returns:</p> Type Description <p>matching scenario, matching ev</p>"},{"location":"reference/entities/fragments/#entities.fragments.Fragment.exchanges","title":"<code>exchanges(scenario=None)</code>","text":"<p>Generator for query compatibility with processes</p> <p>Parameters:</p> Name Type Description Default <code>scenario</code> <code>None</code> <p>Returns:</p> Type Description"},{"location":"reference/entities/fragments/#entities.fragments.Fragment.make_ref","title":"<code>make_ref(query)</code>","text":"<p>We do NOT want to make local fragments into refs-- but we DO want to make remote fragments into refs. so we simply neuter the workhorse function here.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> required <p>Returns:</p> Type Description"},{"location":"reference/entities/fragments/#entities.fragments.Fragment.new","title":"<code>new(flow, direction, **kwargs)</code>  <code>classmethod</code>","text":"<p>Parameters:</p> Name Type Description Default <code>flow</code> <p>entity or ref</p> required <code>direction</code> <p>\"Input\" or \"Output\" w/r/t parent (future: \"balance\" to be also accepted)</p> required <code>kwargs</code> <p>parent; exchange_value/observe; anchor/anchor_flow/descend; balance_flow (alt.), external_ref</p> <code>{}</code> <p>Returns:</p> Type Description"},{"location":"reference/entities/fragments/#entities.fragments.Fragment.nodes","title":"<code>nodes(scenario=None, descend=True)</code>","text":"<p>Report proximal terminal nodes for the fragment (recurse until a nondescend is reached)</p> <p>Parameters:</p> Name Type Description Default <code>scenario</code> <p>[None]</p> <code>None</code> <code>descend</code> <p>[True] if False, yield subfragments as nodes</p> <code>True</code> <p>Returns:</p> Type Description <p>generator of terminal nodes</p>"},{"location":"reference/entities/fragments/#entities.fragments.Fragment.reference","title":"<code>reference(flow=None)</code>","text":"<p>For process interoperability</p> <p>Returns:</p> Type Description"},{"location":"reference/entities/fragments/#entities.fragments.Fragment.remove_child","title":"<code>remove_child(child)</code>","text":"<p>This should only be called from the child's unset_parent function</p> <p>Parameters:</p> Name Type Description Default <code>child</code> required <p>Returns:</p> Type Description"},{"location":"reference/entities/fragments/#entities.fragments.Fragment.scale_evs","title":"<code>scale_evs(factor)</code>","text":"<p>needed when foregrounding terminations</p> <p>Parameters:</p> Name Type Description Default <code>factor</code> required <p>Returns:</p> Type Description"},{"location":"reference/entities/fragments/#entities.fragments.Fragment.set_balance_flow","title":"<code>set_balance_flow()</code>","text":"<p>A balance flow balances its own reference quantity.</p> <p>Returns:</p> Type Description"},{"location":"reference/entities/fragments/#entities.fragments.Fragment.tree","title":"<code>tree()</code>","text":"<p>This is real simple- just a recursive enumeration of child flows, depth first</p> <p>Returns:</p> Type Description"},{"location":"reference/entities/processes/","title":"processes","text":""},{"location":"reference/entities/processes/#entities.processes.LcProcess","title":"<code>LcProcess</code>","text":"<p>               Bases: <code>LcEntity</code></p>"},{"location":"reference/entities/processes/#entities.processes.LcProcess.__init__","title":"<code>__init__(external_ref, **kwargs)</code>","text":"<p>THe process's data is a set of exchanges.</p> <p>A process's reference entity is a subset of these.  It is an error for these exchanges to have terminations (if they're terminated, they're not reference flows- they're dependencies). These references can be used as allocation keys for the exchanges.</p> <p>The entities in reference_entity and _exchanges are not necessarily the same, although they should hash the same.  Not sure whether this is a design flaw or not- but the important thing is that reference entities do not need to have exchange values associated with them (although they could).</p> <p>process.find_reference(key), references() [generator], and reference(flow) all return entries from _exchanges, not entries from reference_entity.  The only public interface to the objects in reference_entity is reference_entity itself.</p> <p>Parameters:</p> Name Type Description Default <code>entity_uuid</code> required <code>kwargs</code> <code>{}</code>"},{"location":"reference/entities/processes/#entities.processes.LcProcess.add_exchange","title":"<code>add_exchange(flow, dirn, reference=None, value=None, termination=None, add_dups=False)</code>","text":"<p>This is used to create Exchanges and ExchangeValues and AllocatedExchanges.</p> <p>If the flow+dir+term is already in the exchange set:     if no reference is specified and/or no value is specified- nothing to do     otherwise (if reference and value are specified):         upgrade the exchange to an allocatedExchange and add the new reference exch val otherwise:     if reference is specified, create an AllocatedExchange     otherwise create an Exchange / ExchangeValue</p> <p>Parameters:</p> Name Type Description Default <code>flow</code> required <code>dirn</code> required <code>reference</code> <code>None</code> <code>value</code> <code>None</code> <code>termination</code> <p>None for reference or cutoff flows; a context for elementary flows; a valid external_ref for terminated intermediate flows.</p> <code>None</code> <code>add_dups</code> <p>(False) set to true to handle \"duplicate exchange\" errors by cumulating their values</p> <code>False</code> <p>Returns:</p> Type Description"},{"location":"reference/entities/processes/#entities.processes.LcProcess.allocate_by_quantity","title":"<code>allocate_by_quantity(quantity)</code>","text":"<p>Store a quantity for partitioning allocation.  All non-reference exchanges will have their exchange values computed based on the total, determined by the quantity specified.  For each reference exchange, computes the magnitude of the quantity output from the unallocated process. Reference flows lacking characterization in that quantity will receive zero allocation.</p> <p>Each magnitude is the allocation numerator for that reference, and the sum of the magnitudes is the allocation denominator.</p> <p>Parameters:</p> Name Type Description Default <code>quantity</code> <p>an LcQuantity (or None to remove quantity allocation)</p> required <p>Returns:</p> Type Description"},{"location":"reference/entities/processes/#entities.processes.LcProcess.allocation_factors","title":"<code>allocation_factors(quantity=None)</code>","text":"<p>Returns a dict mapping reference exchange to that reference's allocation factor according to the specified allocation quantity. If no quantity is specified, the current allocation quantity is used.  DOES NOT AFFECT CURRENT ALLOCATION.</p> <p>Parameters:</p> Name Type Description Default <code>quantity</code> <p>allocation quantity</p> <code>None</code> <p>Returns:</p> Type Description"},{"location":"reference/entities/processes/#entities.processes.LcProcess.exchange_values","title":"<code>exchange_values(flow, direction=None)</code>","text":"<p>Yield full exchanges matching flow specification.  Flow specification required. Will only yield multiple results if there are multiple terminations for the same flow.</p> <p>Parameters:</p> Name Type Description Default <code>flow</code> required <code>direction</code> <code>None</code> <p>Returns:</p> Type Description"},{"location":"reference/entities/processes/#entities.processes.LcProcess.find_reference","title":"<code>find_reference(spec=None, direction=None)</code>","text":"<p>returns a reference exchange matching the specification.</p> <p>If multiple results are found, filters out terminated exchanges</p> <p>Parameters:</p> Name Type Description Default <code>spec</code> <p>could be None, external_ref, flow, flow ref, or exchange</p> <code>None</code> <code>direction</code> <p>could be helpful if the object is a non-reference exchange</p> <code>None</code> <p>Returns:</p> Type Description"},{"location":"reference/entities/processes/#entities.processes.LcProcess.inventory","title":"<code>inventory(ref_flow=None)</code>","text":"<p>generate a process's exchanges.  If no reference is supplied, generate unallocated exchanges, including all reference exchanges.  If a reference is supplied AND the process is allocated with respect to that reference, generate ExchangeValues as allocated to that reference flow, and exclude reference exchanges.  If a reference is supplied but the process is NOT allocated to that reference, generate unallocated ExchangeValues (excluding the reference itself).  Reference must be a flow or exchange found in the process's reference entity.</p> <p>Parameters:</p> Name Type Description Default <code>ref_flow</code> <code>None</code> <p>Returns:</p> Type Description"},{"location":"reference/entities/processes/#entities.processes.LcProcess.is_allocated","title":"<code>is_allocated(reference, strict=False)</code>","text":"<p>Tests whether a process's exchanges contain allocation factors for a given reference.</p> <p>Parameters:</p> Name Type Description Default <code>reference</code> required <code>strict</code> <p>[False] if True, raise an exception if some (but not all) exchanges are missing allocations.</p> <code>False</code> <p>Returns:</p> Type Description <p>True - allocations exist; False - no allocations exist; raise MissingFactor - some allocations exist</p>"},{"location":"reference/entities/processes/#entities.processes.LcProcess.new","title":"<code>new(name, **kwargs)</code>  <code>classmethod</code>","text":"<p>Parameters:</p> Name Type Description Default <code>name</code> <p>the name of the process</p> required <p>Returns:</p> Type Description"},{"location":"reference/entities/processes/#entities.processes.LcProcess.set_reference","title":"<code>set_reference(flow, dirn)</code>","text":"<p>Exchange must already exist. fmr: If the exchange is currently terminated, the termination is removed. now: exchanges terminated to non-elementary context are now allowed</p> <p>Parameters:</p> Name Type Description Default <code>flow</code> required <code>dirn</code> required <p>Returns:</p> Type Description"},{"location":"reference/entities/processes/#entities.processes.LcProcess.show_inventory","title":"<code>show_inventory(reference=None)</code>","text":"<p>Convenience wrapper around self.inventory() which:  * sorts the exchanges by reference, then by direction  * prints the exchanges to output  * provides an enumeration of exchanges for interactive access  = returns the exchanges as a sorted list.</p> <p>Parameters:</p> Name Type Description Default <code>reference</code> <code>None</code> <p>Returns:</p> Type Description"},{"location":"reference/entities/processes/#entities.processes.LcProcess.test_allocation_consistency","title":"<code>test_allocation_consistency(flow=None, display=True)</code>","text":"<p>For each non-reference item in the inventory, test that the values allocated to each reference, weighted by the reference values, sum up to the un-allocated value.</p> <p>Parameters:</p> Name Type Description Default <code>flow</code> <p>[None] single flow to test; defaults to entire inventory</p> <code>None</code> <code>display</code> <p>[True] whether to print output to the screen</p> <code>True</code> <p>Returns:</p> Type Description"},{"location":"reference/entities/processes/#entities.processes.MultipleReferencesFound","title":"<code>MultipleReferencesFound</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Whereas AmbiguousReferenceError indicates that further filtering is possible; MultipleReferencesFound indicates that there is no way to provide additional information.</p>"},{"location":"reference/entities/quantities/","title":"quantities","text":""},{"location":"reference/entities/quantities/#entities.quantities.LcQuantity","title":"<code>LcQuantity</code>","text":"<p>               Bases: <code>LcEntity</code></p>"},{"location":"reference/entities/quantities/#entities.quantities.LcQuantity.__hash__","title":"<code>__hash__()</code>","text":"<p>This needs to be explicit, even though it is identical to the parent class, because otherwise the type is considered unhashable</p> <p>Returns:</p> Type Description"},{"location":"reference/entities/quantities/#entities.quantities.LcQuantity.cf","title":"<code>cf(flow, locale='GLO', **kwargs)</code>","text":"<p>The semantics here may be confusing, but cf is flow-centered. It converts reports the amount in self that corresponds to a unit of the flow's reference quantity.</p> <p>Parameters:</p> Name Type Description Default <code>flow</code> required <code>locale</code> <code>'GLO'</code> <code>kwargs</code> <code>{}</code> <p>Returns:</p> Type Description"},{"location":"reference/entities/quantities/#entities.quantities.LcQuantity.new","title":"<code>new(name, ref_unit, **kwargs)</code>  <code>classmethod</code>","text":"<p>Parameters:</p> Name Type Description Default <code>name</code> <p>the name of the quantity</p> required <code>ref_unit</code> <p>the string representation of the reference unit for the quantity</p> required <p>Returns:</p> Type Description"},{"location":"reference/entities/quantities/#entities.quantities.LcQuantity.profile","title":"<code>profile(flow, **kwargs)</code>","text":"<p>This is a ridiculous hack because the profile doesn't depend on self at all.  So let's make it non-ridiculous by defaulting to self as ref_quantity, so it's not TOTALLY ridiculous</p> <p>Parameters:</p> Name Type Description Default <code>flow</code> required <code>kwargs</code> <code>{}</code> <p>Returns:</p> Type Description"},{"location":"reference/entities/quantities/#entities.quantities.LcQuantity.set_qi","title":"<code>set_qi(qi)</code>","text":"<p>Configures the quantity to access its native term manager.  Can only be set once; otherwise ignored.</p> <p>Parameters:</p> Name Type Description Default <code>qi</code> required <p>Returns:</p> Type Description"},{"location":"reference/entities/quantities/#entities.quantities.LcUnit","title":"<code>LcUnit</code>","text":"<p>               Bases: <code>object</code></p> <p>Dummy class to store a reference to a unit definition Design decision: even though ILCD unitgroups have assigned UUIDs, we are not maintaining unitgroups</p>"},{"location":"reference/entities/xlsx_editor/","title":"xlsx_editor","text":"<p>Class for interchanging entities with an excel spreadsheet.</p> <p>There are two basic parts to this operation:  * we want to be able to write a subset of entities in an archive to an excel worksheet whose name is the same as the    entity_type. We do not want to mix different entity types in the same worksheet. We also only want to include    metadata-- quantitative data (exchanges and flow characterizations) are not meant to be manipulated in this way.    The export to Excel should include the required columns to the leftmost, followed by nonrequired properties.  For a    given entity/property pair, if the entity lacks that property the entry should be blank.</p> <ul> <li>We want to be able to read in metadata from a spreadsheet as well- creating new entities as needed, and modifying    existing entities nondestructively according to a policy with two options:<ul> <li>'defer': if a property exists for a given entity, let its current value stand. If a property does not exist and   the incoming specification is non-null, assign it..</li> <li>'overwrite': Assign all incoming non-null specifications</li> </ul> </li> </ul> <p>For the first one, the only capability of the archive that is needed is (arguably) external to the feature-- namely, the ability to generate the entities. Therefore I think it should be a utility function and not an object at all.</p> <p>For the second one here, this seems like more a capability of an archive rather than a separate class. I think this should be a context mgr.  We (for now) want to be strict about the sheet naming- let's take that flexibility away from the user.</p> <p>The required fields should be: external_ref, *signature_fields.  uuid is supported but not required</p>"},{"location":"reference/entities/xlsx_editor/#entities.xlsx_editor.XlsxArchiveUpdater","title":"<code>XlsxArchiveUpdater</code>","text":"<p>               Bases: <code>XlsxUpdater</code></p>"},{"location":"reference/entities/xlsx_editor/#entities.xlsx_editor.XlsxArchiveUpdater.__init__","title":"<code>__init__(archive, xlrd_like, merge='defer', quiet=True)</code>","text":"<p>Updates entity meta-information from a spreadsheet created from above. external_ref is used as a key; if an entity is not found, a new one is created.  'uuid' and reference fields are only used for creation of new entities. Note: uses the default sheet names of 'flow' and 'quantity'</p> <p>Parameters:</p> Name Type Description Default <code>archive</code> required <code>xlrd_like</code> <p>XLRD workbook-like object OR filename of XLS file</p> required <code>merge</code> <p>['defer'] - do not overwrite existing properties ['overwrite'] - do overwrite existing properties</p> <code>'defer'</code> <p>Returns:</p> Type Description"},{"location":"reference/entities/xlsx_editor/#entities.xlsx_editor.XlsxEntityTypeWriter","title":"<code>XlsxEntityTypeWriter</code>","text":"<p>               Bases: <code>object</code></p>"},{"location":"reference/entities/xlsx_editor/#entities.xlsx_editor.XlsxUpdater","title":"<code>XlsxUpdater</code>","text":"<p>               Bases: <code>object</code></p> <p>This class uses the contents of a properly formatted XLS file (or XLS-file-like object) to create or update entities in an archive.</p> <p>Uses sheet names that match the archive's \"_entity_types\" property, so 'flow' and 'quantity' nominally.  'flows'  and 'quantities' also work.</p> <p>Each sheet must be in strict tabular format, with the first row being headers and each subsequent row being one entity.</p> <p>The only required column is 'external_ref', though 'name' and 'reference' are recommended for new entities.  NOTE: for the time being, quantities require a 'referenceUnit' column and flows require a 'referenceQuantity' column, though the hope is to eliminate that requirement in the future. For quantities, the 'referenceUnit' column should be a unit string; for flows the 'referenceQuantity' column should be a known quantity signifier (external_ref, link, or canonical name recognized by the term manager)</p> <p>Optional columns include 'uuid' and 'origin'</p> <p>All other columns are assigned as properties.</p> <p>FLOW PROPERTIES If there is a sheet called 'flowproperties', then it is interpreted as a list of flow characterizations.  This sheet can have the following columns:  - 'flow'  - 'ref_quantity' - (optional) if present, used only as a check against the flow's native reference_entity  - 'ref_unit' - (optional) a convertible unit in ref_quantity  - 'quantity' - the quantity being characterized  - 'unit' - (optional) a convertible unit in quantity  - 'value' - the characterization factor  - 'context' - (optional) context for the characterization</p> <p>CELL CONTENTS Cells are read as strings, except for the following:  - if a cell's first character is '!', the subsequent characters are interpreted as an entity reference  - if a cell's first character is '*', the subsequent characters are EVALUATED, so obviously this is terribly    insecure, but it was intended to allow people to store lists, sets, and dicts.</p> <p>MERGE STRATEGY The updater has two merge strategies:   * \"defer\": (default) If an entity exists and has a property already defined, defer to the existing property   * \"overwrite\": Any non-null incoming property is assigned to the entity, overwriting any existing value.</p>"},{"location":"reference/entities/xlsx_editor/#entities.xlsx_editor.XlsxUpdater.__enter__","title":"<code>__enter__()</code>","text":"<p>Return self object to use with \"with\" statement.</p>"},{"location":"reference/entities/xlsx_editor/#entities.xlsx_editor.XlsxUpdater.__init__","title":"<code>__init__(xlrd_like, merge='defer', quiet=True)</code>","text":"<p>Updates entity meta-information from a spreadsheet created from above. external_ref is used as a key; if an entity is not found, a new one is created.  'uuid' and reference fields are only used for creation of new entities. Note: uses the default sheet names of 'flow' and 'quantity'</p> <p>Parameters:</p> Name Type Description Default <code>xlrd_like</code> <p>XLRD workbook-like object OR filename of XLS file</p> required <code>merge</code> <p>['defer'] - do not overwrite existing properties ['overwrite'] - do overwrite existing properties</p> <code>'defer'</code> <p>Returns:</p> Type Description"},{"location":"reference/entities/tests/__init__/","title":"init","text":""},{"location":"reference/entities/tests/base_testclass/","title":"base_testclass","text":"<p>Archive testing is divided up loosely into pre-entity (e.g. test_entity_store and test_base) and post-entity testing (e.g. this file).  Of course test_base has entities but they are more for the purpose of validating name setting.</p> <p>This class imports a minimal archive file created in antelope_utilities to contain a multioutput, nontrivial process (USLCI petroleum refining) and an intermediate process (a grid mix).  These don't do anything special but the refinery process can test both exchange generation / allocation and lcia.</p> <p>Subclass this to access that archive.  Current uses:</p>"},{"location":"reference/implementations/","title":"index","text":""},{"location":"reference/implementations/#implementations.index.IndexImplementation","title":"<code>IndexImplementation</code>","text":"<p>               Bases: <code>BasicImplementation</code>, <code>IndexInterface</code></p> <p>A CatalogInterface provides basic-level semantic data about entities</p> <p>Only requires the abstract ArchiveImplementation</p> <p>Attribute requirements for the archive:  - everything required by BasicImplementation  - entities_by_type()  - count_by_type()  - search(), including implicitly _narrow_search()</p>"},{"location":"reference/implementations/#implementations.index.IndexImplementation.lcia","title":"<code>lcia(**kwargs)</code>","text":"<p>Generate LCIA Methodologies or method collections- these are specified by having the singleton MetaQuantityUnit (and/or the unitstring '0') as a unit. They should not have indicators. They have a property 'impactCategories' which is a list of included lcia_methods</p> <p>Parameters:</p> Name Type Description Default <code>kwargs</code> <code>{}</code> <p>Returns:</p> Type Description"},{"location":"reference/implementations/#implementations.index.IndexImplementation.lcia_methods","title":"<code>lcia_methods(**kwargs)</code>","text":"<p>Generate LCIA Methods-- which are quantities that have defined indicators</p> <p>Parameters:</p> Name Type Description Default <code>kwargs</code> <code>{}</code> <p>Returns:</p> Type Description"},{"location":"reference/implementations/#implementations.index.IndexImplementation.targets","title":"<code>targets(flow_ref, direction=None, **kwargs)</code>","text":"<p>Generate processes in the archive that terminate a given exchange i.e. - have the same flow and a complementary direction.  If refs_only is specified, only report processes that terminate the exchange with a reference exchange.</p> <p>Parameters:</p> Name Type Description Default <code>flow_ref</code> <p>flow, exchange, or flow's external key</p> required <code>direction</code> <p>[None] filter</p> <code>None</code> <p>Returns:</p> Type Description"},{"location":"reference/implementations/#implementations.index.IndexImplementation.unmatched_flows","title":"<code>unmatched_flows(flows, **kwargs)</code>","text":"<p>Takes in a list of flows and generates a sublist of flows that were not recognized as synonyms to any local flows.</p> <p>Uses TermManager.get_flowable which tries the best of flow.synonyms, flow.name, str(flow)</p> <p>Parameters:</p> Name Type Description Default <code>flows</code> required <code>kwargs</code> <code>{}</code> <p>Returns:</p> Type Description"},{"location":"reference/implementations/__init__/","title":"init","text":""},{"location":"reference/implementations/background/","title":"background","text":""},{"location":"reference/implementations/background/#implementations.background.BackgroundImplementation","title":"<code>BackgroundImplementation</code>","text":"<p>               Bases: <code>BasicImplementation</code>, <code>BackgroundInterface</code></p> <p>The default Background Implementation exposes an ordinary inventory database as a collection of LCI results. Because it does not perform any ordering, there is no way to distinguish between foreground and background elements in a database using the proxy. It is thus inconsistent for the same resource to implement both inventory and [proxy] background interfaces.</p>"},{"location":"reference/implementations/background/#implementations.background.BackgroundImplementation.background_flows","title":"<code>background_flows(search=None, **kwargs)</code>","text":"<p>all process reference flows are background flows</p> <p>Parameters:</p> Name Type Description Default <code>search</code> <code>None</code> <code>kwargs</code> <code>{}</code> <p>Returns:</p> Type Description"},{"location":"reference/implementations/background/#implementations.background.BackgroundImplementation.consumers","title":"<code>consumers(process, ref_flow=None, **kwargs)</code>","text":"<p>Not supported for trivial backgrounds</p> <p>Parameters:</p> Name Type Description Default <code>process</code> required <code>ref_flow</code> <code>None</code> <code>kwargs</code> <code>{}</code> <p>Returns:</p> Type Description"},{"location":"reference/implementations/background/#implementations.background.BackgroundImplementation.cutoffs","title":"<code>cutoffs(process, ref_flow=None, **kwargs)</code>","text":"<p>All processes are LCI, so they have only exterior flows. Emissions are the exterior flows with non-elementary contexts</p> <p>Parameters:</p> Name Type Description Default <code>process</code> required <code>ref_flow</code> <code>None</code> <code>kwargs</code> <code>{}</code> <p>Returns:</p> Type Description"},{"location":"reference/implementations/background/#implementations.background.BackgroundImplementation.dependencies","title":"<code>dependencies(process, ref_flow=None, **kwargs)</code>","text":"<p>All processes are LCI, so they have no dependencies</p> <p>Parameters:</p> Name Type Description Default <code>process</code> required <code>ref_flow</code> <code>None</code> <code>kwargs</code> <code>{}</code> <p>Returns:</p> Type Description"},{"location":"reference/implementations/background/#implementations.background.BackgroundImplementation.emissions","title":"<code>emissions(process, ref_flow=None, **kwargs)</code>","text":"<p>All processes are LCI, so they have only exterior flows. Emissions are the exterior flows with elementary contexts</p> <p>Parameters:</p> Name Type Description Default <code>process</code> required <code>ref_flow</code> <code>None</code> <code>kwargs</code> <code>{}</code> <p>Returns:</p> Type Description"},{"location":"reference/implementations/background/#implementations.background.BackgroundImplementation.exterior_flows","title":"<code>exterior_flows(direction=None, search=None, **kwargs)</code>","text":"<p>Exterior flows are all flows that do not have interior terminations (i.e. not found in the index targets) Elementary contexts have a sense, but intermediate contexts do not [necessarily]- so we need some way to determine their directionality.  This whole implementation is just a stand-in anyway- the important thing is that this is handled correctly in tarjan</p> <p>Parameters:</p> Name Type Description Default <code>direction</code> <code>None</code> <code>search</code> <code>None</code> <code>kwargs</code> <code>{}</code> <p>Returns:</p> Type Description"},{"location":"reference/implementations/background/#implementations.background.BackgroundImplementation.foreground_flows","title":"<code>foreground_flows(search=None, **kwargs)</code>","text":"<p>No foreground flows in the proxy background</p> <p>Parameters:</p> Name Type Description Default <code>search</code> <code>None</code> <code>kwargs</code> <code>{}</code> <p>Returns:</p> Type Description"},{"location":"reference/implementations/background/#implementations.background.BackgroundImplementation.is_in_scc","title":"<code>is_in_scc(process, ref_flow=None, **kwargs)</code>","text":"<p>Distinction between is_in_background and is_in_scc will reveal the proxy nature of the interface</p> <p>Parameters:</p> Name Type Description Default <code>process</code> required <code>ref_flow</code> <code>None</code> <code>kwargs</code> <code>{}</code> <p>Returns:</p> Type Description"},{"location":"reference/implementations/background/#implementations.background.BackgroundImplementation.setup_bm","title":"<code>setup_bm(index=None)</code>","text":"<p>Requires an index interface or catalog query &lt;-- preferred This must provide .get() and .get_context() (so really it should maybe be 'basic' The trivial implementation uses .flows() and .targets() to mock up an exterior flows method</p> <p>Parameters:</p> Name Type Description Default <code>index</code> <code>None</code> <p>Returns:</p> Type Description"},{"location":"reference/implementations/background/#implementations.background.BackgroundImplementation.sys_lci","title":"<code>sys_lci(demand, **kwargs)</code>","text":"<p>For LCI, we simply yield process direct exchanges as LCI. For sys_lci, we should just do the same. yield the supplied demand as a degenerate LCI.</p> <p>Parameters:</p> Name Type Description Default <code>demand</code> required <code>kwargs</code> <code>{}</code> <p>Returns:</p> Type Description"},{"location":"reference/implementations/background/#implementations.background.BackgroundImplementation.sys_lcia","title":"<code>sys_lcia(process, query_qty, observed=None, ref_flow=None, **kwargs)</code>","text":"<p>returns an LciaResult object, aggregated as appropriate depending on the interface's privacy level. This is an ensemble function that stitches together bg functions with quantity access.</p> <p>Parameters:</p> Name Type Description Default <code>process</code> required <code>query_qty</code> <p>must be an operable quantity_ref. the process must have exchange access</p> required <code>observed</code> <p>iterable of DirectedFlows (flow: FlowSpec, direction: str)</p> <code>None</code> <code>ref_flow</code> <code>None</code> <code>kwargs</code> <code>{}</code> <p>Returns:</p> Type Description"},{"location":"reference/implementations/basic/","title":"basic","text":""},{"location":"reference/implementations/basic/#implementations.basic.BasicImplementation","title":"<code>BasicImplementation</code>","text":"<p>               Bases: <code>object</code></p>"},{"location":"reference/implementations/basic/#implementations.basic.BasicImplementation.__init__","title":"<code>__init__(archive, **kwargs)</code>","text":"<p>Provides common features for an interface implementation: namely, an archive and a privacy setting. Also provides access to certain common methods of the archive.  This should be the base class for interface-specific implementations.</p> <p>Requires an archive with the following attributes:  - ref - report semantic reference  - source - report physical data source  - static - a boolean indicating whether the full contents of the archive are loaded into memory  - get_uuid() - deprecated - only present for compatibility reasons  - getitem - retrieve already-loaded entity  - retrieve_or_fetch_entity() - _fetch abstract method must be implemented</p> <p>All of these requirements are met by the standard ArchiveImplementation, with the exception of the _fetch abstract method.</p> <p>Since a recent change that removed the 'basic' interface as a default for all resources, this must be explicitly assigned to at least one resource in order for a query to be valid.  The basic interface should be assigned to the resource that meets the following requirements:  - most comprehensive source of information about entity properties (e.g. documentary pseudo-interface)  - easiest to load (e.g. a non-static)</p> <p>Parameters:</p> Name Type Description Default <code>archive</code> <p>an LcArchive</p> required <code>privacy</code> <p>No longer used. Privacy is enforced at the server and not the resource (where it was phony from the beginning)</p> required"},{"location":"reference/implementations/basic/#implementations.basic.BasicImplementation.bg_lcia","title":"<code>bg_lcia(process, query_qty, ref_flow=None, *kwargs)</code>","text":"<p>This needs to be handled by a query with lci() access, or by a subclass</p> <p>Parameters:</p> Name Type Description Default <code>process</code> required <code>query_qty</code> required <code>ref_flow</code> <code>None</code> <code>kwargs</code> <code>()</code> <p>Returns:</p> Type Description"},{"location":"reference/implementations/basic/#implementations.basic.BasicImplementation.get","title":"<code>get(external_ref, **kwargs)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>external_ref</code> <p>may also be link, as long as requested origin is equal or lesser in specificity</p> required <code>kwargs</code> <code>{}</code> <p>Returns:</p> Type Description <p>entity or None</p>"},{"location":"reference/implementations/basic/#implementations.basic.BasicImplementation.get_context","title":"<code>get_context(term, **kwargs)</code>","text":"<p>I think this needs to be moved into the quantity interface</p> <p>Parameters:</p> Name Type Description Default <code>term</code> required <code>kwargs</code> <code>{}</code> <p>Returns:</p> Type Description"},{"location":"reference/implementations/basic/#implementations.basic.BasicImplementation.get_item","title":"<code>get_item(external_ref, item)</code>","text":"<p>In this, we accept either an external_ref or an entity reference itself.  If the latter, we dereference via the archive to an actual entity, which we then ask for the item.  If the dereference and the reference are the same, throws an error.</p> <p>Parameters:</p> Name Type Description Default <code>external_ref</code> required <code>item</code> required <p>Returns:</p> Type Description"},{"location":"reference/implementations/basic/#implementations.basic.BasicImplementation.is_lcia_engine","title":"<code>is_lcia_engine(**kwargs)</code>","text":"<p>suggests expansion to a graph-based TM</p> <p>Parameters:</p> Name Type Description Default <code>kwargs</code> <code>{}</code> <p>Returns:</p> Type Description"},{"location":"reference/implementations/basic/#implementations.basic.BasicImplementation.validate","title":"<code>validate()</code>","text":"<p>way to check that a query implementation is valid without querying anything</p> <p>Returns:</p> Type Description"},{"location":"reference/implementations/configure/","title":"configure","text":""},{"location":"reference/implementations/configure/#implementations.configure.ConfigureImplementation","title":"<code>ConfigureImplementation</code>","text":"<p>               Bases: <code>CoreConfigureImplementation</code></p>"},{"location":"reference/implementations/configure/#implementations.configure.ConfigureImplementation.characterize_flow","title":"<code>characterize_flow(flow_ref, quantity_ref, value, location='GLO', overwrite=False, **kwargs)</code>","text":"<p>A ConfigFlowCharacterization provides a procedural mechanism for specifying flow quantity characterizations after loading an archive.  The 'flow_ref' and 'quantity_ref' have to lookup successfully in the archive.</p> <p>Not clear how to deal with contexts</p> <p>Parameters:</p> Name Type Description Default <code>flow_ref</code> required <code>quantity_ref</code> required <code>value</code> required <code>location</code> <code>'GLO'</code> <code>overwrite</code> <code>False</code> <code>kwargs</code> <code>{}</code> <p>Returns:</p> Type Description"},{"location":"reference/implementations/configure/#implementations.configure.CoreConfigureImplementation","title":"<code>CoreConfigureImplementation</code>","text":"<p>               Bases: <code>BasicImplementation</code>, <code>ConfigureInterface</code></p>"},{"location":"reference/implementations/configure/#implementations.configure.CoreConfigureImplementation.apply_config","title":"<code>apply_config(config, **kwargs)</code>","text":"<p>Apply a collection of configuration objects to the archive.</p> <p>All options should be supplied as a dict of iterables, where the keys are the configuration methods and the entries in each iterable are tuples corresponding to the configuration parameters, properly ordered.</p> <p>Configuration options should be idempotent; applying them several times should have the same effect as applying them once.</p> <p>Returns:</p> Type Description"},{"location":"reference/implementations/configure/#implementations.configure.CoreConfigureImplementation.check_config","title":"<code>check_config(config, c_args, **kwargs)</code>","text":"<p>Uses the config schema valid_configs to validate config arguments.  A leading '0_' indicates that the argument is permitted to be None.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <p>a configuration entry</p> required <code>c_args</code> <p>a tuple of args</p> required <code>kwargs</code> <code>{}</code> <p>Returns:</p> Type Description"},{"location":"reference/implementations/configure/#implementations.configure.LcConfigureImplementation","title":"<code>LcConfigureImplementation</code>","text":"<p>               Bases: <code>ConfigureImplementation</code></p>"},{"location":"reference/implementations/configure/#implementations.configure.LcConfigureImplementation.allocate_by_quantity","title":"<code>allocate_by_quantity(process_ref, quantity_ref, overwrite=False, **kwargs)</code>","text":"<p>A ConfigAllocation provides a procedural mechanism for specifying quantity-wise allocations of processes at load time.  All that is required is a quantity; the process knows how to perform the allocation.  Note that reference flows not characterized with respect to the quantity will receive zero allocation.  So apply flow config first.</p> <p>Parameters:</p> Name Type Description Default <code>process_ref</code> required <code>quantity_ref</code> required <code>overwrite</code> <code>False</code> <code>kwargs</code> <code>{}</code> <p>Returns:</p> Type Description"},{"location":"reference/implementations/configure/#implementations.configure.LcConfigureImplementation.set_reference","title":"<code>set_reference(process_ref, flow_ref, direction=None, **kwargs)</code>","text":"<p>A ConfigSetReference indicates that a particular exchange should be marked a reference exchange.  All terms are required.  The flow and direction must uniquely identify an exchange.</p> <p>Parameters:</p> Name Type Description Default <code>process_ref</code> required <code>flow_ref</code> required <code>direction</code> <code>None</code> <code>kwargs</code> <code>{}</code> <p>Returns:</p> Type Description"},{"location":"reference/implementations/configure/#implementations.configure.LcConfigureImplementation.unset_reference","title":"<code>unset_reference(process_ref, flow_ref, direction=None, **kwargs)</code>","text":"<p>A ConfigBadReference provides a procedural mechanism for removing automatically-tagged reference flows, or for marking a byproduct as non-reference or non-allocatable.  The parts are 'process_ref', 'flow_ref', and 'direction', but if process_ref is None, then all instances of the flow_ref and direction will be marked non-reference.</p> <p>Difficult to validate because any of the three arguments is allowed to be None (and even in nontrivial combinations)</p> <p>Parameters:</p> Name Type Description Default <code>process_ref</code> required <code>flow_ref</code> required <code>direction</code> <code>None</code> <code>kwargs</code> <code>{}</code> <p>Returns:</p> Type Description"},{"location":"reference/implementations/exchange/","title":"exchange","text":""},{"location":"reference/implementations/exchange/#implementations.exchange.ExchangeImplementation","title":"<code>ExchangeImplementation</code>","text":"<p>               Bases: <code>BasicImplementation</code>, <code>ExchangeInterface</code></p> <p>This provides access to detailed exchange values and computes the exchange relation. Creates no additional requirements on the archive.</p>"},{"location":"reference/implementations/exchange/#implementations.exchange.ExchangeImplementation.exchange_relation","title":"<code>exchange_relation(process, ref_flow, exch_flow, direction, termination=None, **kwargs)</code>","text":"<p>This certainly should be tested for quantity-based and ecoinvent-style (exhaustive) allocation</p> <p>Parameters:</p> Name Type Description Default <code>process</code> required <code>ref_flow</code> required <code>exch_flow</code> required <code>direction</code> <p>can be None; however, if the process has mixed directions this will raise an error</p> required <code>termination</code> <code>None</code> <p>Returns:</p> Type Description"},{"location":"reference/implementations/exchange/#implementations.exchange.MixedDirections","title":"<code>MixedDirections</code>","text":"<p>               Bases: <code>Exception</code></p> <p>When exchange_relation is called without a direction but the process has mixed directions</p>"},{"location":"reference/implementations/quantity/","title":"quantity","text":"<p>Each archive now has a TermManager which interprets query arguments as synonyms for canonical flows and contexts.  This can also be upgraded to an LciaEngine, which extends the synonymization strategy to quantities as well</p>"},{"location":"reference/implementations/quantity/#implementations.quantity.QuantityConversion","title":"<code>QuantityConversion</code>","text":"<p>               Bases: <code>object</code></p> <p>A stack of Quantity Relation results that are composed sequentially in order to render a flow-quantity conversion. The first QRR added should report the query quantity (numerator) in terms of some reference quantity (denominator); then each subsequent QRR should include the prior ref quantity as the query quantity.</p> <p>QuantityConversion implements the interface of a QRResult (flowable, ref, query, context, value, locale, origin), 'context' is a cache of the [canonical] context used as query input; 'locale' is a '/' join of all found geographies; 'flowable' 'query' and 'origin' take from the first QR Result; 'ref' takes the last; value is computed as the product of all contained QRResults.</p> <p>For instance, a Quantity conversion from moles of CH4 to GWP 100 might include first the GWP conversion and then the mol conversion: QuantityConversion(QRResult('methane', 'kg', 'kg CO2eq', 'emissions to air', 'GLO', 'ipcc.2007', 25.0),                    QRResult('methane', 'mol', 'kg', None, 'GLO', 'local.qdb', 0.016)) giving the resulting value of 0.4.</p> <p>The QuantityConversion needs information to be fully defined: the query quantity and the query context, both of which should be canonical.  The canonical context is especially needed to test directionality for LCIA.</p> <p>For the context initially submitted, consult the exchange.</p>"},{"location":"reference/implementations/quantity/#implementations.quantity.QuantityConversion.context","title":"<code>context</code>  <code>property</code>","text":"<p>We want to return the canonical context if at all possible</p> <p>Returns:</p> Type Description"},{"location":"reference/implementations/quantity/#implementations.quantity.QuantityImplementation","title":"<code>QuantityImplementation</code>","text":"<p>               Bases: <code>BasicImplementation</code>, <code>QuantityInterface</code></p>"},{"location":"reference/implementations/quantity/#implementations.quantity.QuantityImplementation.cf","title":"<code>cf(flow, quantity, ref_quantity=None, context=None, locale='GLO', **kwargs)</code>","text":"<p>Should Always return a number and catch errors</p> <p>Parameters:</p> Name Type Description Default <code>flow</code> required <code>quantity</code> required <code>ref_quantity</code> <p>[None] taken from flow.reference_entity if flow is entity or locally known external_ref</p> <code>None</code> <code>context</code> <p>[None] taken from flow.reference_entity if flow is entity or locally known external_ref</p> <code>None</code> <code>locale</code> <code>'GLO'</code> <code>kwargs</code> <p>allow_proxy [False], strategy ['first'] -&gt; passed to quantity_relation</p> <code>{}</code> <p>Returns:</p> Type Description <p>the value of the QRResult found by the quantity_relation</p>"},{"location":"reference/implementations/quantity/#implementations.quantity.QuantityImplementation.characterize","title":"<code>characterize(flowable, ref_quantity, query_quantity, value, context=None, location='GLO', origin=None, **kwargs)</code>","text":"<p>We gotta be able to do this</p> <p>Parameters:</p> Name Type Description Default <code>flowable</code> <p>string</p> required <code>ref_quantity</code> <p>string</p> required <code>query_quantity</code> <p>string</p> required <code>value</code> <p>float</p> required <code>context</code> <p>string</p> <code>None</code> <code>location</code> <p>string</p> <code>'GLO'</code> <code>origin</code> <p>[self.origin]</p> <code>None</code> <code>kwargs</code> <p>overwrite=False</p> <code>{}</code> <p>Returns:</p> Type Description"},{"location":"reference/implementations/quantity/#implementations.quantity.QuantityImplementation.do_lcia","title":"<code>do_lcia(quantity, inventory, locale='GLO', group=None, dist=2, **kwargs)</code>","text":"<p>This is almost static. Could be moved into interface, except that it requires LciaResult (which is core).</p> <p>Successively implement the quantity relation over an iterable of exchanges.</p> <p>Parameters:</p> Name Type Description Default <code>quantity</code> required <code>inventory</code> <p>An iterable of exchange-like entries, having flow, direction, value, termination.  Currently also uses process.external_ref for hashing purposes, but that could conceivably be abandoned.</p> required <code>locale</code> <p>['GLO']</p> <code>'GLO'</code> <code>group</code> <p>How to group scores.  Should be a lambda that operates on inventory items. Default x -&gt; x.process</p> <code>None</code> <code>dist</code> <p>[2] controls how strictly to interpret exchange context. 0 - exact context matches only; 1 - match child contexts (code default) 2 - match parent contexts [this default] 3 - match any ancestor context, including Null</p> <code>2</code> <code>kwargs</code> <code>{}</code> <p>Returns:</p> Type Description"},{"location":"reference/implementations/quantity/#implementations.quantity.QuantityImplementation.get_canonical","title":"<code>get_canonical(quantity, **kwargs)</code>","text":"<p>Retrieve a canonical quantity from a qdb; else raises EntityNotFound</p> <p>Parameters:</p> Name Type Description Default <code>quantity</code> <p>external_id of quantity</p> required <p>Returns:</p> Type Description <p>quantity entity</p>"},{"location":"reference/implementations/quantity/#implementations.quantity.QuantityImplementation.lcia","title":"<code>lcia(process, ref_flow, quantity_ref, **kwargs)</code>","text":"<p>Implementation of foreground LCIA -- moved from LcCatalog</p> <p>Parameters:</p> Name Type Description Default <code>process</code> required <code>ref_flow</code> required <code>quantity_ref</code> required <code>kwargs</code> <code>{}</code> <p>Returns:</p> Type Description"},{"location":"reference/implementations/quantity/#implementations.quantity.QuantityImplementation.norm","title":"<code>norm(quantity, region=None, **kwargs)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>quantity</code> required <code>region</code> <code>None</code> <code>kwargs</code> <code>{}</code> <p>Returns:</p> Type Description"},{"location":"reference/implementations/quantity/#implementations.quantity.QuantityImplementation.profile","title":"<code>profile(flow, ref_quantity=None, context=None, complete=False, **kwargs)</code>","text":"<p>Generate characterizations for the named flow or flowable.  The positional argument is first used to retrieve a flow, and if successful, the reference quantity and context are taken for that flow.  Otherwise, the positional argument is interpreted as a flowable synonym and used to generate CFs, optionally filtered by context.  In that case, if no ref quantity is given then the CFs are returned as-reported; if a ref quantity is given then a ref quantity conversion is attempted and the resulting QRResult objects are returned.</p> <p>This whole interface desperately needs testing.</p> <p>Parameters:</p> Name Type Description Default <code>flow</code> required <code>ref_quantity</code> <p>[None]</p> <code>None</code> <code>context</code> <p>[None]</p> <code>None</code> <code>complete</code> <p>[False] if True, report all results including errors and geographic proxies</p> <code>False</code> <code>kwargs</code> <code>{}</code> <p>Returns:</p> Type Description"},{"location":"reference/implementations/quantity/#implementations.quantity.QuantityImplementation.quantity_conversions","title":"<code>quantity_conversions(flow, query_quantity, ref_quantity=None, context=None, locale='GLO', **kwargs)</code>","text":"<p>Return a comprehensive set of conversion results for the provided inputs.  This method catches errors and returns a null result if no factors are found.</p> <p>This function is a wrapper to handle inputs.</p> <p>Parameters:</p> Name Type Description Default <code>flow</code> <p>a string that is synonymous with a flowable characterized by the query quantity</p> required <code>query_quantity</code> <p>convert to this quantity</p> required <code>ref_quantity</code> <p>[None] convert for 1 unit of this quantity</p> <code>None</code> <code>context</code> <p>[None] a string synonym for a context / \"archetype\"? (&lt;== locale-specific?)</p> <code>None</code> <code>locale</code> <p>handled by CF; default 'GLO'</p> <code>'GLO'</code> <code>kwargs</code> <p>dist: CLookup distance (0=exact 1=subcompartments 2=parent compartment 3=all parents)</p> <code>{}</code> <p>Returns:</p> Type Description <p>a 3-tuple of lists of QuantityConversion objects: [valid conversions], [geographic proxy conversions], [mismatched ref unit conversions]</p>"},{"location":"reference/implementations/quantity/#implementations.quantity.do_lcia","title":"<code>do_lcia(quantity, inventory, locale=None, group=None, dist=2, quell_biogenic_co2=None, **kwargs)</code>","text":"<p>Successively implement the quantity relation over an iterable of exchanges.</p> <p>man, WHAT is the qdb DOING with all those LOC? (ans: seemingly a lot)</p> <p>Parameters:</p> Name Type Description Default <code>quantity</code> required <code>inventory</code> <p>An iterable of exchange-like entries, having flow, direction, value, termination.  Currently also uses process.external_ref for hashing purposes, but that could conceivably be abandoned.</p> required <code>locale</code> <p>['GLO']</p> <code>None</code> <code>group</code> <p>How to group scores.  Should be a lambda that operates on inventory items. Default x -&gt; x.process</p> <code>None</code> <code>dist</code> <p>[2] controls how strictly to interpret exchange context. 0 - exact context matches only; 1 - match child contexts (code default) 2 - match parent contexts [this default] 3 - match any ancestor context, including NullContext</p> <code>2</code> <code>quell_biogenic_co2</code> <p>suppressed. no longer used</p> <code>None</code> <code>kwargs</code> <code>{}</code> <p>Returns:</p> Type Description"},{"location":"reference/implementations/tests/__init__/","title":"tests","text":""},{"location":"reference/lcia_engine/__init__/","title":"init","text":""},{"location":"reference/lcia_engine/__init__/#lcia_engine.LciaDb","title":"<code>LciaDb</code>","text":"<p>               Bases: <code>Qdb</code></p> <p>Augments the Qdb with an LciaEngine instead of a TermManager</p>"},{"location":"reference/lcia_engine/__init__/#lcia_engine.LciaDb.__getitem__","title":"<code>__getitem__(item)</code>","text":"<p>Note: this user-friendliness check adds 20% to the execution time of getitem-- so avoid it if possible (use _get_entity directly -- especially now that upstream is now deprecated) (note that _get_entity does not get contexts)</p> <p>Parameters:</p> Name Type Description Default <code>item</code> required <p>Returns:</p> Type Description"},{"location":"reference/lcia_engine/__init__/#lcia_engine.LciaDb.add","title":"<code>add(entity)</code>","text":"<p>Add entity to archive, by link instead of external ref. If the entity has a uuid and uuid does not already exist, add it.  If the UUID does already exist, warn.</p> <p>Parameters:</p> Name Type Description Default <code>entity</code> required <p>Returns:</p> Type Description"},{"location":"reference/lcia_engine/clookup/","title":"clookup","text":"<p>The CLookup is a classic example of trying to solve a very complex data problem with a very complex data structure. It does not entirely succeed, but it works well enough as a stopgap until I have a chance to give an honest crack at a graph database.</p> <p>Flow characterization is the very complex data problem: the \"quantity relation\" maps a large, diverse set of inputs:  - flowable (substance)  - reference quantity (in our data system, tied to flowable)  - query quantity  - context / compartment  - location / locale to a numeric output, namely the amount of the query quantity that corresponds to a unit of the reference quantity. Technically, this amount also has uncertainty / other quantitative characteristics.</p> <p>The idea behind a CLookup is that it contains all known characterizations for a given flowable [substance] with respect to a given quantity.  The CLookup is selected by specifying the flowable and the quantity, and then the CLookup is used to retrieve a set of Characterization objects for a given context (hence the 'C' in 'CLookup'). The characterization already stores a mapping of locale to factor, and also stores the flowable (with its native reference quantity used to interpret the factor).</p> <p>So it solves a very narrow portion of the problem and leaves a lot to outside code.</p> <p>The dream would be to design a graph database that held all of these parameters and magically obtained all the factors that applied to a given query-- that graph database would replace the current Term Manager and everything else under its hood. But first we will learn to walk...</p>"},{"location":"reference/lcia_engine/clookup/#lcia_engine.clookup.CLookup","title":"<code>CLookup</code>","text":"<p>               Bases: <code>object</code></p> <p>A CLookup is a kind of fuzzy dictionary that maps context to best-available characterization. A given CLookup is associated with a single quantity and a specific flowable.  The query then provides the compartment and returns either: a set of best-available characterizations; a single characterization according to a selection rule; or a characterization factor (float) depending on which method is used.</p>"},{"location":"reference/lcia_engine/clookup/#lcia_engine.clookup.CLookup.__getitem__","title":"<code>__getitem__(item)</code>","text":"<p>Returns</p> <p>Parameters:</p> Name Type Description Default <code>item</code> required <p>Returns:</p> Type Description"},{"location":"reference/lcia_engine/clookup/#lcia_engine.clookup.CLookup.find","title":"<code>find(item, dist=1, return_first=True, origin=None)</code>","text":"<p>Hunt for a matching compartment. 'dist' param controls the depth of search:   dist = 0: equivalent to getitem   dist = 1: also check compartment's children (subcompartments), to any depth, returning all CFs encountered     (unless return_first is True, in which case all CFs from the first nonempty compartment found are returned)   dist = 2: also check compartment's parents (excluding root=Null context)   dist = 3: also check all compartment's parents until root. Useful for finding unit conversions. By default (dist==1), checks compartment self and children. Returns a set.</p> <p>Parameters:</p> Name Type Description Default <code>item</code> <p>a Compartment</p> required <code>dist</code> <p>how far to search (with limits) (default: 1= compartment + children)</p> <code>1</code> <code>return_first</code> <p>stop hunting as soon as a cf is found</p> <code>True</code> <code>origin</code> <p>[None] if present, only return cfs whose origins match the specification</p> <code>None</code> <p>Returns:</p> Type Description <p>a list of characterization factors that meet the query criteria, ordered by increasing dist</p>"},{"location":"reference/lcia_engine/clookup/#lcia_engine.clookup.CLookup.serialize_for_origin","title":"<code>serialize_for_origin(origin, values=False)</code>","text":"<p>Note: In the event that the CLookup includes multiple CFs for the same flowable and the same origin, only the first (at random) will be included, because originally I had disallowed multiple CFs for the same origin.</p> <p>Parameters:</p> Name Type Description Default <code>origin</code> required <code>values</code> <code>False</code> <p>Returns:</p> Type Description"},{"location":"reference/lcia_engine/clookup/#lcia_engine.clookup.SCLookup","title":"<code>SCLookup</code>","text":"<p>               Bases: <code>CLookup</code></p> <p>A Strict CLookup that permits only one CF to be stored per compartment and raises an error if an additional one is added.</p>"},{"location":"reference/lcia_engine/lcia_engine/","title":"lcia_engine","text":""},{"location":"reference/lcia_engine/lcia_engine/#lcia_engine.lcia_engine.LciaEngine","title":"<code>LciaEngine</code>","text":"<p>               Bases: <code>TermManager</code></p> <p>This adds several abilities:  * track flowables by origin    - identify flowables thhat are not recognized    - return flowables by origin (all, or only new)  * lookup CFs based on context hierarchy    - dist = 0: only exact matchh    - dist = 1: match or subcompartments    - dist = 2: match, subcompartments, or parent    - dist = 3: .. or any parent up to NullContext  * quell biogenic CO2 in quantity relation lookups</p>"},{"location":"reference/lcia_engine/lcia_engine/#lcia_engine.lcia_engine.LciaEngine.__getitem__","title":"<code>__getitem__(item)</code>","text":"<p>LciaEngine.getitem retrieves a canonical context by more intensively searching for matches from a given context.  Adds foreign context's full name as synonym if one is affirmatively found.  If one is not found, returns the NullContext.</p> <p>None is returned as None, to represent 'unspecified' (i.e. accept all) as opposed to 'no context' which isa context (accept only matching). (as tested)</p> <p>Parameters:</p> Name Type Description Default <code>item</code> required <p>Returns:</p> Type Description <p>a matching context or NullContext.</p>"},{"location":"reference/lcia_engine/lcia_engine/#lcia_engine.lcia_engine.LciaEngine.__init__","title":"<code>__init__(contexts=None, flowables=None, quantities=None, quell_biogenic_co2=None, strict_clookup=True, **kwargs)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>quantities</code> <code>None</code> <code>quell_biogenic_co2</code> <p>DEPRECATED</p> <code>None</code> <code>contexts</code> <code>None</code> <code>flowables</code> <code>None</code> <code>strict_clookup</code> <p>[True] whether to prohibit multiple CFs for each quantity / flowable / context tuple</p> <code>True</code> <code>kwargs</code> <p>from TermManager: quiet, merge_strategy</p> <code>{}</code>"},{"location":"reference/lcia_engine/lcia_engine/#lcia_engine.lcia_engine.LciaEngine.add_flow_terms","title":"<code>add_flow_terms(flow, merge_strategy=None)</code>","text":"<p>Subclass handles two problems: tracking flowables by origin and biogenic CO2.</p> <p>Should probably test this shit</p> <p>Under our scheme, it is a requirement that the flowables list used to initialize the LciaEngine is curated.</p> <p>biogenic: if ANY of the flow's terms match the biogenic regex AND the flow is CO2, set its name</p> <p>Parameters:</p> Name Type Description Default <code>flow</code> required <code>merge_strategy</code> <code>None</code> <p>Returns:</p> Type Description"},{"location":"reference/lcia_engine/lcia_engine/#lcia_engine.lcia_engine.LciaEngine.add_quantity","title":"<code>add_quantity(quantity)</code>","text":"<p>Here we are not picky about having duplicate quantities</p> <p>Parameters:</p> Name Type Description Default <code>quantity</code> required <p>Returns:</p> Type Description"},{"location":"reference/lcia_engine/lcia_engine/#lcia_engine.lcia_engine.LciaEngine.add_synonym","title":"<code>add_synonym(existing_term, synonym)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>existing_term</code> <p>flowable or quantity (cx is TBD)</p> required <code>synonym</code> <p>string term to add</p> required <p>Returns:</p> Type Description"},{"location":"reference/lcia_engine/lcia_engine/#lcia_engine.lcia_engine.LciaEngine.apply_hints","title":"<code>apply_hints(names, hints)</code>","text":"<p>Hints should be</p> <p>Parameters:</p> Name Type Description Default <code>names</code> <p>iterable of catalog names to which context hints will apply</p> required <code>hints</code> <p>an iterable of term, canonical pairs, where term is the context as known in the origin, and canonical is the corresponding canonical context.</p> required <p>Returns:</p> Type Description"},{"location":"reference/lcia_engine/lcia_engine/#lcia_engine.lcia_engine.LciaEngine.flowables","title":"<code>flowables(search=None, origin=None, new=False, **kwargs)</code>","text":"<p>Adds ability to filter by origin-- note this is exclusive to the ability to filter by quantity</p> <p>Parameters:</p> Name Type Description Default <code>search</code> <code>None</code> <code>origin</code> <code>None</code> <code>new</code> <p>[False] if True, only return flowables that were not known originally</p> <code>False</code> <p>Returns:</p> Type Description <p>generates flowable strings</p>"},{"location":"reference/lcia_engine/lcia_engine/#lcia_engine.lcia_engine.LciaEngine.get_canonical","title":"<code>get_canonical(quantity)</code>","text":"<p>We override this because here we are using canonical quantities and 'kg' is not a canonical quantity, but it always means mass</p> <p>Parameters:</p> Name Type Description Default <code>quantity</code> required <p>Returns:</p> Type Description"},{"location":"reference/lcia_engine/lcia_engine/#lcia_engine.lcia_engine.LciaEngine.import_cfs","title":"<code>import_cfs(quantity)</code>","text":"<p>Given a quantity, import its CFs into the local database.  Unfortunately this is still going to be slow because every part of the CF still needs to be canonicalized. The only thing that's saved is creating a new Characterization instance.</p> <p>Parameters:</p> Name Type Description Default <code>quantity</code> <p>this is a TRUE quantity whose query points to the authentic origin.</p> required <p>Returns:</p> Type Description"},{"location":"reference/lcia_engine/lcia_engine/#lcia_engine.lcia_engine.LciaEngine.merge_flowables","title":"<code>merge_flowables(dominant, *syns)</code>","text":"<p>Combine together a list of synonyms under a dominant term.  If the synonyms are existing flowables, they are merged with the dominant term; otherwise, they are added as synonyms.</p> <p>Parameters:</p> Name Type Description Default <code>dominant</code> <p>must be known to the flowables database</p> required <code>syns</code> <p>0 or more terms or flowables</p> <code>()</code> <p>Returns:</p> Type Description"},{"location":"reference/lcia_engine/lcia_engine/#lcia_engine.lcia_engine.LciaEngine.merge_quantities","title":"<code>merge_quantities(first, second)</code>","text":"<p>Absorb second into child of first.  Currently does not support remapping entries, so import_cfs(second) needs to be run again. Old factors will be left in so _fq_map still works.</p> <p>Parameters:</p> Name Type Description Default <code>first</code> required <code>second</code> required <p>Returns:</p> Type Description"},{"location":"reference/lcia_engine/tests/__init__/","title":"tests","text":""},{"location":"reference/providers/__init__/","title":"init","text":""},{"location":"reference/providers/__init__/#providers.PROVIDERS","title":"<code>PROVIDERS = _prov + ['EcoinventLcia', 'OpenLcaJsonLdArchive', 'Traci21Factors', 'XdbClient', 'OpenLcaRefData']</code>  <code>module-attribute</code>","text":""},{"location":"reference/providers/__init__/#providers.PROVIDERS--this-has-all-been-folded-into-archiveinit","title":"this has all been folded into archive.init","text":"<p>class ArchiveError(Exception):     pass</p> <p>def create_archive(source, ds_type, catalog=None, kwargs):     \"\"\"     Create an archive from a source and type specification.     :param source:     :param ds_type:     :param catalog: required to identify upstream archives, if specified     :param kwargs:     :return:     \"\"\"     if ds_type.lower() == 'json':         a = archive_from_json(source, factory=_provider_factory, catalog=catalog, kwargs)     else:         cls = _provider_factory(ds_type)         a = cls(source, **kwargs)     return a</p> <p>def _provider_factory(ds_type):     \"\"\"     Returns an archive class     :param ds_type:     :return:     \"\"\"     ds_type = ds_type.lower()     init_map = {         'lcarchive': LcArchive,         'ilcdarchive': IlcdArchive,         'ilcd': IlcdArchive,         'ilcdlcia': IlcdLcia,         'ilcd_lcia': IlcdLcia,         'ecospoldv1archive': EcospoldV1Archive,         'ecospold': EcospoldV1Archive,         'ecospoldv2archive': EcospoldV2Archive,         'ecospold2': EcospoldV2Archive,         'ecoinventspreadsheet': EcoinventSpreadsheet,         'ecoinventlcia': EcoinventLcia,         'ecoinvent_lcia': EcoinventLcia,         'openlcajsonldarchive': OpenLcaJsonLdArchive,         'openlca': OpenLcaJsonLdArchive,         'openlca_jsonld': OpenLcaJsonLdArchive,         'olca': OpenLcaJsonLdArchive,         'olca_jsonld': OpenLcaJsonLdArchive,         'traci2': Traci21Factors,         'traci': Traci21Factors,         'traci21factors': Traci21Factors,         'v1_client': AntelopeV1Client,         'antelope_v1_client': AntelopeV1Client,         'antelopev1client': AntelopeV1Client,         'antelopev1': AntelopeV1Client     }     try:         init_fcn = init_map[ds_type]         return init_fcn</p>"},{"location":"reference/providers/__init__/#providers.PROVIDERS--foregroundarchive-foregroundarchiveload","title":"'foregroundarchive': ForegroundArchive.load,","text":""},{"location":"reference/providers/__init__/#providers.PROVIDERS--foreground-foregroundarchiveload","title":"'foreground': ForegroundArchive.load","text":"<pre><code>except KeyError:\n    try:\n        mod = importlib.import_module('.%s' % ds_type, package='antelope_%s' % ds_type)\n    except ImportError as e:\n        raise ArchiveError(e)\n    return mod.init_fcn\n</code></pre> <p>def archive_from_json(fname, static=True, catalog=None, **archive_kwargs):     \"\"\"     :param fname: JSON filename     :param catalog: [None] necessary to retrieve upstream archives, if specified     :param static: [True]     :return: an ArchiveInterface     \"\"\"     j = from_json(fname)     archive_kwargs['quiet'] = True     archive_kwargs['static'] = static</p> <pre><code>if 'prefix' in j.keys():\n    archive_kwargs['prefix'] = j['prefix']\n\nif 'nsUuid' in j.keys():\n    archive_kwargs['ns_uuid'] = j['nsUuid']\n\nif j['dataSourceType'] == 'EcoinventSpreadsheet':\n    archive_kwargs['internal'] = bool(j['internal'])\n    archive_kwargs['version'] = j['version']\n\nif 'dataSourceReference' in j:\n    # old style\n    source = j['dataSourceReference']\nelse:\n    # new style\n    source = j['dataSource']\n\ntry:\n    a = archive_factory(source, j['dataSourceType'], **archive_kwargs)\nexcept KeyError:\n    raise ValueError('Unknown dataSourceType %s' % j['dataSourceType'])\n\nif 'upstreamReference' in j:\n    print('**Upstream reference encountered: %s\n</code></pre> <p>' % j['upstreamReference'])         if catalog is not None:             try:                 upstream = catalog.get_archive(j['upstreamReference'])                 a.set_upstream(upstream)             except KeyError:                 print('Upstream reference not found in catalog!')                 a.init_args['upstreamReference'] = j['upstreamReference']             except ValueError:                 print('Upstream reference is ambiguous!')                 a.init_args['upstreamReference'] = j['upstreamReference']         else:             a.init_args['upstreamReference'] = j['upstreamReference']</p> <pre><code>a.load_from_dict(j, jsonfile=fname)\nreturn a\n</code></pre>"},{"location":"reference/providers/ecoinvent_lcia/","title":"ecoinvent_lcia","text":"<p>The point of the ecoinvent LCIA methods is to ste^H^H^Hadapt the hard work of the Ecoinvent Centre, so as to develop LCIA methods and results for ecoinvent LCI that match their own results.</p> <p>2020-01-11 WARNING: this assumes mass as reference quantity by default, which leads to obvious quantity conversion errors for non-mass-reference indicators like land occupation.</p> <p>Solution requires access to Ecoinvent metadata in order to determine the reference quantities for flows.</p>"},{"location":"reference/providers/ecoinvent_lcia/#providers.ecoinvent_lcia.EcoinventLcia","title":"<code>EcoinventLcia</code>","text":"<p>               Bases: <code>BasicArchive</code></p> <p>Class to import the Ecoinvent LCIA implementation and construct a flow-cf-quantity catalog. The external keys are concatenations of the three</p>"},{"location":"reference/providers/ecoinvent_lcia/#providers.ecoinvent_lcia.EcoinventLcia.__init__","title":"<code>__init__(source, ei_archive=None, ref=None, mass_quantity=None, version=EI_LCIA_VERSION, ns_uuid=EI_LCIA_NSUUID, static=True, **kwargs)</code>","text":"<p>EI_LCIA_VERSION default is presently 3.1 for the spreadsheet named 'LCIA implementation v3.1 2014_08_13.xlsx'</p> <p>Parameters:</p> Name Type Description Default <code>source</code> required <code>ei_archive</code> <p>required to determine reference quantities for flows</p> <code>None</code> <code>ref</code> <p>hard-coded 'local.ecoinvent.[EI_LCIA_VERSION].lcia'; specify at instantiation to override</p> <code>None</code> <code>mass_quantity</code> <code>None</code> <code>version</code> <p>default is '3.1'</p> <code>EI_LCIA_VERSION</code> <code>ns_uuid</code> <p>required; default / convention is '46802ca5-8b25-398c-af10-2376adaa4623'</p> <code>EI_LCIA_NSUUID</code> <code>static</code> <p>this archive type is always static</p> <code>True</code> <code>kwargs</code> <p>quiet, upstream</p> <code>{}</code>"},{"location":"reference/providers/ecospold/","title":"ecospold","text":"<p>With inspiration from bw2data/io/import_ecospold2.py and affiliated files</p> <p>The purpose of this archive (and ILCD alike) is to provide a common interface, a la the semantic web paper, to a collection of process data, to wit:  - list of process metadata:    UUID | Name | Spatial | Temporal | Ref Product | Comment |</p>"},{"location":"reference/providers/ecospold/#providers.ecospold.tail","title":"<code>tail = re.compile('/([^/]+)$')</code>  <code>module-attribute</code>","text":"<p>Used to install conversion factors between different flow reference units.  Satisfies the requirement: conversion_dict[(k1, k2)] = f implies 1 k1 = f k2</p> <p>Note: one conversion factor that was omitted is required by the 2015-era US LCI database: The process \"Biodegradable loose fill [RNA]\" requires \"natural gas, combusted in equipment\" measured in kWh, but there is no conversion from m3 of natural gas combusted to kWh.  My best guess is on a GCV basis of fuel input, so ~40 MJ/m3 = 11.111 kWh / m3</p> <p>This value must be entered by hand when the USLCI database is loaded.</p>"},{"location":"reference/providers/ecospold/#providers.ecospold.EcospoldV1Archive","title":"<code>EcospoldV1Archive</code>","text":"<p>               Bases: <code>LcArchive</code></p> <p>Create an Ecospold Archive object from a path.  By default, assumes the path points to a literal .7z file, of the type that one can download from the ecoinvent website.  Creates an accessor for files in that archive and allows a user to</p>"},{"location":"reference/providers/ecospold/#providers.ecospold.EcospoldV1Archive.__init__","title":"<code>__init__(source, prefix=None, ns_uuid=None, **kwargs)</code>","text":"<p>Just instantiates the parent class.</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <p>physical data source</p> required <code>prefix</code> <p>difference between the internal path (ref) and the ILCD base</p> <code>None</code> <code>ns_uuid</code> <p>NS UUID not allowed for ecospold ve</p> <code>None</code> <p>Returns:</p> Type Description"},{"location":"reference/providers/file_store/","title":"file_store","text":"<p>This is the oldest code in Antelope (and among my first ever pieces of python code).  Please don't judge.</p> <p>Written to access ILCD and ecospold archives in either zipped or unzipped or 7z format and GaBi web databases equally</p> <p>Unfortunately, the 7z format has some kind of bug where time per read grows linearly with the number of reads. I should report it.</p>"},{"location":"reference/providers/file_store/#providers.file_store.FileStore","title":"<code>FileStore</code>","text":"<p>               Bases: <code>object</code></p> <p>A strictly local archive of files to be used as a repository</p>"},{"location":"reference/providers/file_store/#providers.file_store.FileStore.__init__","title":"<code>__init__(path, internal_prefix=None, query_string=None, cache=True)</code>","text":"<p>Create a FileStore object from a path.  Basically encapsulates the compression algorithm and presents a common interface to client code: self.listfiles() self.countfiles() self.readfile(filename)</p> <p>writing providers is not presently supported.</p> <p>By default remote archives create a local cache to store downloaded files- this cache is mounted as an ordinary archive and is checked first when readfile() is called.  You can force a re-download by specifying .readfile(..., force_download=True)</p> <p>Parameters:</p> Name Type Description Default <code>path</code> required <code>internal_prefix</code> <p>if present, silently absorb / conceal the specified prefix (prepend to requests, trim from responses).</p> <code>None</code> <code>query_string</code> <p>for remote repositories, append the supplied string after '?' in the URL</p> <code>None</code> <code>cache</code> <p>(True) for remote repositories, cache downloaded files locally and use first</p> <code>True</code> <p>Returns:</p> Type Description <p>an archive object</p>"},{"location":"reference/providers/file_store/#providers.file_store.FileStore.listfiles","title":"<code>listfiles(in_prefix='')</code>","text":"<p>generate files in the archive, removing internal prefix, optionally filtering to specified prefix.</p> <p>Parameters:</p> Name Type Description Default <code>in_prefix</code> <p>optional prefix to limit</p> <code>''</code> <p>Returns:</p> Type Description"},{"location":"reference/providers/file_store/#providers.file_store.FileStore.readfile","title":"<code>readfile(fname, force_download=False)</code>","text":"<p>Have to decide what this does. I think it should return the raw data- since there's no way to get a pointer to a file in a generic archive</p> <p>Parameters:</p> Name Type Description Default <code>fname</code> required <code>force_download</code> <p>for remote caching archives:</p> <code>False</code> <p>Returns:</p> Type Description"},{"location":"reference/providers/parse_math/","title":"parse_math","text":""},{"location":"reference/providers/parse_math/#providers.parse_math.parse_math","title":"<code>parse_math(expression)</code>","text":"<p>A function I got off stackoverflow that enables python to parse user input as a mathematical expression. probably a huge security risk. but it enables the user to enter missing characterization values during runtime.</p> <p>Parameters:</p> Name Type Description Default <code>expression</code> required <p>Returns:</p> Type Description"},{"location":"reference/providers/xl_dict/","title":"xl_dict","text":""},{"location":"reference/providers/xl_dict/#providers.xl_dict.XlDict","title":"<code>XlDict</code>","text":"<p>               Bases: <code>object</code></p> <p>wrapper class for xlrd-like API that exposes a simple pandas-like interface to access tabular spreadsheet data with iterrows.</p>"},{"location":"reference/providers/xl_dict/#providers.xl_dict.XlDict.__init__","title":"<code>__init__(sheet, nulls=None)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>sheet</code> <p>an xlrd.sheet.Sheet</p> required <code>nulls</code> <p>What value to assign to empty entries.  Default is to set them to None.  Pass in the desired literal</p> <code>None</code>"},{"location":"reference/providers/xl_dict/#providers.xl_dict.XlDict.iterrows","title":"<code>iterrows()</code>","text":"<p>Using the first row as a list of headers, yields a dict for each subsequent row using the header names as keys. returning index, row for pandas compatibility</p> <p>Returns:</p> Type Description"},{"location":"reference/providers/xl_dict/#providers.xl_dict.XlDict.unique_units","title":"<code>unique_units(internal=False)</code>","text":"<pre><code>    unitname = 'unit' if self.internal else 'unitName'\n</code></pre> <p>units = set(_elementary[unitname].unique().tolist()).union(     set(_intermediate[unitname].unique().tolist())) for u in units:     self._create_quantity(u)</p> <p>Parameters:</p> Name Type Description Default <code>internal</code> <code>False</code> <p>Returns:</p> Type Description"},{"location":"reference/providers/xml_widgets/","title":"xml_widgets","text":"<p>Deals with ILCD namespaces</p>"},{"location":"reference/providers/xml_widgets/#providers.xml_widgets.find_tag","title":"<code>find_tag(o, tag, ns=None)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>o</code> <p>objectified element</p> required <code>tag</code> required <p>Returns:</p> Type Description"},{"location":"reference/providers/xml_widgets/#providers.xml_widgets.find_tags","title":"<code>find_tags(o, tag, ns=None)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>o</code> <p>objectified element</p> required <code>tag</code> required <p>Returns:</p> Type Description"},{"location":"reference/providers/xml_widgets/#providers.xml_widgets.render_text_block","title":"<code>render_text_block(el, ns=None)</code>","text":"<p>Created for EcoSpold2.  Take all the children of an objectified element and render them as a text block. Implement variable substitution (!!!)</p> <p>Parameters:</p> Name Type Description Default <code>el</code> <p>Element with tags including 'text' and 'variable'</p> required <code>ns</code> <p>[None] namespace</p> <code>None</code> <p>Returns:</p> Type Description"},{"location":"reference/providers/data/__init__/","title":"data","text":""},{"location":"reference/providers/ecospold2/__init__/","title":"init","text":""},{"location":"reference/providers/ecospold2/ecospold2/","title":"ecospold2","text":"<p>Import ecospold2 files</p>"},{"location":"reference/providers/ecospold2/ecospold2/#providers.ecospold2.ecospold2.EcospoldV2Archive","title":"<code>EcospoldV2Archive</code>","text":"<p>               Bases: <code>LcArchive</code></p> <p>class for loading metadata from ecospold v2 files. Now I know ecoinvent supplies a whole ton of supplementary information in files that are outside the ecospold archives- and that information is going to be IGNORED. or loaded separately. But not handled here.</p>"},{"location":"reference/providers/ecospold2/ecospold2/#providers.ecospold2.ecospold2.EcospoldV2Archive.__init__","title":"<code>__init__(source, prefix=None, linked=True, **kwargs)</code>","text":"<p>Just instantiates the parent class.</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <p>physical data source</p> required <code>prefix</code> <p>relative path for datasets from the archive root</p> <code>None</code> <code>linked</code> <p>[True] whether the archive includes unlinked or linked datasets. Reference exchanges get detected differently in one case versus the other (see _create_process)</p> <code>True</code> <p>Returns:</p> Type Description"},{"location":"reference/providers/ecospold2/ecospold2/#providers.ecospold2.ecospold2.EcospoldV2Archive.retrieve_lcia_scores","title":"<code>retrieve_lcia_scores(process_uuid, rf_uuid, quantities=None)</code>","text":"<p>This function retrieves LCIA scores from an Ecospold02 file and stores them as characterizations in an LcFlow entity corresponding to the first (and presumably, only) reference intermediate flow</p> <p>Only stores cfs for quantities that exist locally.</p> <p>Parameters:</p> Name Type Description Default <code>process_uuid</code> required <code>rf_uuid</code> required <code>quantities</code> <p>list of quantity entities to look for (defaults to all local lcia_methods)</p> <code>None</code> <p>Returns:</p> Type Description <p>a dict of quantity uuid to score</p>"},{"location":"reference/providers/ecospold2/ecospold2/#providers.ecospold2.ecospold2.find_tag","title":"<code>find_tag(o, tag, ns=None)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>o</code> <p>objectified element</p> required <code>tag</code> required <p>Returns:</p> Type Description"},{"location":"reference/providers/ecospold2/ecospold2/#providers.ecospold2.ecospold2.find_tags","title":"<code>find_tags(o, tag, ns=None)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>o</code> <p>objectified element</p> required <code>tag</code> required <p>Returns:</p> Type Description"},{"location":"reference/providers/ecospold2/ecospold2/#providers.ecospold2.ecospold2.render_text_block","title":"<code>render_text_block(el, ns=None)</code>","text":"<p>Created for EcoSpold2.  Take all the children of an objectified element and render them as a text block. Implement variable substitution (!!!)</p> <p>Parameters:</p> Name Type Description Default <code>el</code> <p>Element with tags including 'text' and 'variable'</p> required <code>ns</code> <p>[None] namespace</p> <code>None</code> <p>Returns:</p> Type Description"},{"location":"reference/providers/ecospold2/ecospold2/#providers.ecospold2.ecospold2.spold_reference_flow","title":"<code>spold_reference_flow(filename)</code>","text":"<p>second UUID, first match should be reference flow uuid</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> required <p>Returns:</p> Type Description <p>first uuid, second uuid</p>"},{"location":"reference/providers/ecospold2/ecospold2_index/","title":"ecospold2_index","text":""},{"location":"reference/providers/ecospold2/ecospold2_index/#providers.ecospold2.ecospold2_index.EcoSpold2IndexImplementation","title":"<code>EcoSpold2IndexImplementation</code>","text":"<p>               Bases: <code>IndexImplementation</code></p>"},{"location":"reference/providers/ecospold2/ecospold2_index/#providers.ecospold2.ecospold2_index.EcoSpold2IndexImplementation.re_index","title":"<code>re_index(cutoffs=False)</code>","text":"<p>do nothing here as termination index is not subject to change.</p> <p>Parameters:</p> Name Type Description Default <code>cutoffs</code> <code>False</code> <p>Returns:</p> Type Description"},{"location":"reference/providers/ecospold2/master_data/","title":"master_data","text":""},{"location":"reference/providers/ilcd/","title":"index","text":""},{"location":"reference/providers/ilcd/__init__/","title":"init","text":""},{"location":"reference/providers/ilcd/ilcd/","title":"ilcd","text":""},{"location":"reference/providers/ilcd/ilcd/#providers.ilcd.ilcd.IlcdArchive","title":"<code>IlcdArchive</code>","text":"<p>               Bases: <code>LcArchive</code></p> <p>This class handles de-referencing for ILCD archives</p>"},{"location":"reference/providers/ilcd/ilcd/#providers.ilcd.ilcd.IlcdArchive.__init__","title":"<code>__init__(source, prefix=None, **kwargs)</code>","text":"<p>Just instantiates the parent class.</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <p>root of the archive</p> required <code>prefix</code> <p>difference between the internal path (ref) and the ILCD base (note: for local archives, this defaults to 'ILCD'; for remote arcnives it defaults to empty)</p> <code>None</code> <code>quiet</code> <p>forwarded to ArchiveInterface</p> required <p>Returns:</p> Type Description"},{"location":"reference/providers/ilcd/ilcd/#providers.ilcd.ilcd.find_tag","title":"<code>find_tag(o, tag, ns=None)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>o</code> <p>objectified element</p> required <code>tag</code> required <p>Returns:</p> Type Description"},{"location":"reference/providers/ilcd/ilcd/#providers.ilcd.ilcd.find_tags","title":"<code>find_tags(o, tag, ns=None)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>o</code> <p>objectified element</p> required <code>tag</code> required <p>Returns:</p> Type Description"},{"location":"reference/providers/ilcd/ilcd/#providers.ilcd.ilcd.render_text_block","title":"<code>render_text_block(el, ns=None)</code>","text":"<p>Created for EcoSpold2.  Take all the children of an objectified element and render them as a text block. Implement variable substitution (!!!)</p> <p>Parameters:</p> Name Type Description Default <code>el</code> <p>Element with tags including 'text' and 'variable'</p> required <code>ns</code> <p>[None] namespace</p> <code>None</code> <p>Returns:</p> Type Description"},{"location":"reference/providers/ilcd/ilcd_flowables/","title":"ilcd_flowables","text":""},{"location":"reference/providers/ilcd/ilcd_flowables/#providers.ilcd.ilcd_flowables.find_tag","title":"<code>find_tag(o, tag, ns=None)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>o</code> <p>objectified element</p> required <code>tag</code> required <p>Returns:</p> Type Description"},{"location":"reference/providers/ilcd/ilcd_flowables/#providers.ilcd.ilcd_flowables.find_tags","title":"<code>find_tags(o, tag, ns=None)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>o</code> <p>objectified element</p> required <code>tag</code> required <p>Returns:</p> Type Description"},{"location":"reference/providers/ilcd/ilcd_flowables/#providers.ilcd.ilcd_flowables.ilcd_flow_generator","title":"<code>ilcd_flow_generator(archive=ELCD, **kwargs)</code>","text":"<p>This generates flows from the current reference ELCD archive.</p> <p>Parameters:</p> Name Type Description Default <code>archive</code> <code>ELCD</code> <code>kwargs</code> <code>{}</code> <p>Returns:</p> Type Description"},{"location":"reference/providers/ilcd/ilcd_flowables/#providers.ilcd.ilcd_flowables.render_text_block","title":"<code>render_text_block(el, ns=None)</code>","text":"<p>Created for EcoSpold2.  Take all the children of an objectified element and render them as a text block. Implement variable substitution (!!!)</p> <p>Parameters:</p> Name Type Description Default <code>el</code> <p>Element with tags including 'text' and 'variable'</p> required <code>ns</code> <p>[None] namespace</p> <code>None</code> <p>Returns:</p> Type Description"},{"location":"reference/providers/ilcd/ilcd_flowables/#providers.ilcd.ilcd_flowables.synonyms_from_ilcd_flow","title":"<code>synonyms_from_ilcd_flow(flow, skip_syns=False)</code>","text":"<p>ILCD flow files have long synonym blocks at the top. They also have a CAS number and a basename.</p> <p>Skips synonym blocks for ILCD flows known to have bad synonyms:   * \"Crude Oil; 42.3 MJ/kg\" is not a synonym for \"Benzene, pure\", etc.   * \"Carbon [resource, in ground]\" is not a synonym for the variety of compounds that may be manufactured from it   * \"Wood;  14.7 MJ/kg\" says synonyms removed but weren't.</p> <p>Skips 'wood' from any list, which is abused badly in the ILCD synonyms list. Methanol and wood are not synonymous.</p> <p>Parameters:</p> Name Type Description Default <code>flow</code> required <code>skip_syns</code> <p>return name, uuid, and cas but skip synonyms</p> <code>False</code> <p>Returns:</p> Type Description <p>uuid (str), name (str), syns (set, includes name, excludes uuid)</p>"},{"location":"reference/providers/ilcd/ilcd_lcia/","title":"ilcd_lcia","text":""},{"location":"reference/providers/ilcd/ilcd_lcia/#providers.ilcd.ilcd_lcia.IlcdLcia","title":"<code>IlcdLcia</code>","text":"<p>               Bases: <code>IlcdArchive</code></p> <p>Slightly extends the IlcdArchive with a set of functions for loading LCIA factors and adding them as quantities + charaterizations</p>"},{"location":"reference/providers/ilcd/ilcd_lcia/#providers.ilcd.ilcd_lcia.IlcdLcia.load_lcia_method","title":"<code>load_lcia_method(u, version=None, load_all_flows=False)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>u</code> required <code>version</code> <code>None</code> <code>load_all_flows</code> <p>[False] If False, load CFs only for already-loaded flows. If True, load all flows</p> <code>False</code> <p>Returns:</p> Type Description"},{"location":"reference/providers/ilcd/ilcd_lcia/#providers.ilcd.ilcd_lcia.find_tag","title":"<code>find_tag(o, tag, ns=None)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>o</code> <p>objectified element</p> required <code>tag</code> required <p>Returns:</p> Type Description"},{"location":"reference/providers/ilcd/ilcd_lcia/#providers.ilcd.ilcd_lcia.find_tags","title":"<code>find_tags(o, tag, ns=None)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>o</code> <p>objectified element</p> required <code>tag</code> required <p>Returns:</p> Type Description"},{"location":"reference/providers/ilcd/ilcd_lcia/#providers.ilcd.ilcd_lcia.render_text_block","title":"<code>render_text_block(el, ns=None)</code>","text":"<p>Created for EcoSpold2.  Take all the children of an objectified element and render them as a text block. Implement variable substitution (!!!)</p> <p>Parameters:</p> Name Type Description Default <code>el</code> <p>Element with tags including 'text' and 'variable'</p> required <code>ns</code> <p>[None] namespace</p> <code>None</code> <p>Returns:</p> Type Description"},{"location":"reference/providers/ilcd/quantity/","title":"quantity","text":""},{"location":"reference/providers/ilcd/quantity/#providers.ilcd.quantity.IlcdQuantityImplementation","title":"<code>IlcdQuantityImplementation</code>","text":"<p>               Bases: <code>QuantityImplementation</code></p>"},{"location":"reference/providers/ilcd/quantity/#providers.ilcd.quantity.IlcdQuantityImplementation.compartments","title":"<code>compartments(quantity=None, flowable=None, **kwargs)</code>","text":"<p>Return a list of compartment strings. Use quantity and flowable parameters to narrow the result set to those characterized for a specific quantity, those with a specific flowable, or both</p> <p>Parameters:</p> Name Type Description Default <code>quantity</code> <code>None</code> <code>flowable</code> <code>None</code> <p>Returns:</p> Type Description <p>list of strings</p>"},{"location":"reference/providers/ilcd/quantity/#providers.ilcd.quantity.IlcdQuantityImplementation.factors","title":"<code>factors(quantity, flowable=None, context=None, **kwargs)</code>","text":"<p>Return characterization factors for the given quantity, subject to optional flowable and compartment filter constraints. This is ill-defined because the reference unit is not explicitly reported in current serialization for characterizations (it is implicit in the flow)-- but it can be added to a web service layer.</p> <p>Parameters:</p> Name Type Description Default <code>quantity</code> required <code>flowable</code> <code>None</code> <code>context</code> <p>not implemented</p> <code>None</code> <p>Returns:</p> Type Description"},{"location":"reference/providers/ilcd/quantity/#providers.ilcd.quantity.IlcdQuantityImplementation.flowables","title":"<code>flowables(quantity=None, compartment=None, **kwargs)</code>","text":"<p>Return a list of flowable strings. Use quantity and compartment parameters to narrow the result set to those characterized by a specific quantity, those exchanged with a specific compartment, or both</p> <p>Parameters:</p> Name Type Description Default <code>quantity</code> <code>None</code> <code>compartment</code> <p>filter by compartment not implemented</p> <code>None</code> <p>Returns:</p> Type Description <p>list of pairs: CAS number, name</p>"},{"location":"reference/providers/ilcd/quantity/#providers.ilcd.quantity.IlcdQuantityImplementation.get_canonical","title":"<code>get_canonical(quantity, **kwargs)</code>","text":"<p>Retrieve a canonical quantity from a qdb</p> <p>Parameters:</p> Name Type Description Default <code>quantity</code> <p>external_id of quantity</p> required <p>Returns:</p> Type Description <p>quantity entity</p>"},{"location":"reference/providers/ilcd/quantity/#providers.ilcd.quantity.IlcdQuantityImplementation.quantity_relation","title":"<code>quantity_relation(flowable, ref_quantity, query_quantity, context, locale='GLO', **kwargs)</code>","text":"<p>Return a single number that converts the a unit of the reference quantity into the query quantity for the given flowable, compartment, and locale (default 'GLO').  If no locale is found, this would be a great place to run a spatial best-match algorithm.</p> <p>Parameters:</p> Name Type Description Default <code>flowable</code> required <code>ref_quantity</code> required <code>query_quantity</code> required <code>context</code> required <code>locale</code> <code>'GLO'</code> <p>Returns:</p> Type Description"},{"location":"reference/providers/ilcd/tests/__init__/","title":"tests","text":""},{"location":"reference/providers/openlca/__init__/","title":"init","text":""},{"location":"reference/providers/openlca/olca_accessor/","title":"olca_accessor","text":""},{"location":"reference/providers/openlca/olca_accessor/#providers.openlca.olca_accessor.OlcaAccessorV2","title":"<code>OlcaAccessorV2</code>","text":"<p>               Bases: <code>object</code></p> <p>To access the reformed GreenDelta/data repository</p>"},{"location":"reference/providers/openlca/olca_accessor/#providers.openlca.olca_accessor.OlcaAccessorV2.factors_for_method","title":"<code>factors_for_method(q)</code>","text":"<p>LCIA category,Flow,Flow property,Flow unit,Location,Factor</p> <p>Parameters:</p> Name Type Description Default <code>q</code> required <p>Returns:</p> Type Description"},{"location":"reference/providers/openlca/olca_accessor/#providers.openlca.olca_accessor.OlcaAccessorV2.read_locales","title":"<code>read_locales()</code>","text":"<p>locations.csv has ID,Name,Description,Category,Code,Latitude,Longitude columns, but: - \"Category\" is empty for all records - \"ID\" we're skipping - \"Latitude\" and \"Longitude\" we have no use for at the moment - and we don't need \"Description\" either. but let's just keep em all.</p> <p>Returns:</p> Type Description"},{"location":"reference/providers/openlca/olca_accessor/#providers.openlca.olca_accessor.OlcaAccessorV2.read_unit_groups","title":"<code>read_unit_groups()</code>","text":"<p>This returns a DICT whose KEYS are the Unit Group Name, and whose VALUES are UnitGroup objects That dict is then accessed later on</p> <p>Returns:</p> Type Description"},{"location":"reference/providers/openlca/olca_ps_interpreter/","title":"olca_ps_interpreter","text":""},{"location":"reference/providers/openlca/olca_ps_interpreter/#providers.openlca.olca_ps_interpreter.OlcaProductSystemInterpreter","title":"<code>OlcaProductSystemInterpreter</code>","text":"<p>               Bases: <code>object</code></p> <p>A convenience layer for interacting with an OpenLCA product system object</p>"},{"location":"reference/providers/openlca/olca_ps_interpreter/#providers.openlca.olca_ps_interpreter.OlcaProductSystemInterpreter.__init__","title":"<code>__init__(ps_json, parameter_set=None)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>ps_json</code> <p>supply the json object corresponding to the named product system</p> required"},{"location":"reference/providers/openlca/olca_ps_interpreter/#providers.openlca.olca_ps_interpreter.OlcaProductSystemInterpreter.get_target_flow","title":"<code>get_target_flow(context, exchange_id)</code>","text":"<p>ps links specify anchor_flow, which must be used to build our model because bg engine expects it</p> <p>Parameters:</p> Name Type Description Default <code>context</code> required <code>exchange_id</code> required <p>Returns:</p> Type Description"},{"location":"reference/providers/openlca/olca_ref_data/","title":"olca_ref_data","text":"<p>supplies an Antelope archive that contains the ref data.</p>"},{"location":"reference/providers/openlca/olca_ref_data/#providers.openlca.olca_ref_data.OlcaRefQuantityImplementation","title":"<code>OlcaRefQuantityImplementation</code>","text":"<p>               Bases: <code>BasicImplementation</code>, <code>QuantityInterface</code></p>"},{"location":"reference/providers/openlca/olca_ref_data/#providers.openlca.olca_ref_data.OlcaRefQuantityImplementation.factors","title":"<code>factors(quantity, flowable=None, context=None, **kwargs)</code>","text":"<p>always retrieving these from file when asked allows the files to be updated but maybe it would be smrter just to add them locally what would be smrtest would be to just store them in a dumb rdbms instead of from file. but think of the immediate use case. that is all for qdb</p> <p>Parameters:</p> Name Type Description Default <code>quantity</code> required <code>flowable</code> <code>None</code> <code>context</code> <code>None</code> <code>kwargs</code> <code>{}</code> <p>Returns:</p> Type Description <p>generate Characterization objects</p>"},{"location":"reference/providers/openlca/olca_ref_data/#providers.openlca.olca_ref_data.OpenLcaRefData","title":"<code>OpenLcaRefData</code>","text":"<p>               Bases: <code>BasicArchive</code></p> <p>Modern OLCA data format should be easy to use. We are ignoring their unit conversions (which, fair, should be incorporated) ... categories is gone ... and they hve no flow properties to speak of (that I can find) so we simply do what we did below, adapted to the simpler data format.</p> <p>first flow properties then we replicate the meta-quantities load sequence from json-LD and we do on-demand CF synthesis via a custom Quantity implementation and we're done</p>"},{"location":"reference/providers/openlca/olca_ref_data/#providers.openlca.olca_ref_data.OpenLcaRefData.factors_to_csv","title":"<code>factors_to_csv(quantity, filepath)</code>","text":"<p>Utility to output processed CFs to a file for easy analysis, debug unit conversions, duplicate CFs, etc</p> <p>Parameters:</p> Name Type Description Default <code>quantity</code> required <code>filepath</code> required <p>Returns:</p> Type Description"},{"location":"reference/providers/openlca/openlca_jsonld/","title":"openlca_jsonld","text":"<p>GreenDelta has updated OpenLCA JSON-LD to version 2 with a number of changes, tersely documented here: https://greendelta.github.io/olca-schema/CHANGES.html</p> <p>There are changes throughout, and this forces us to decide whether to kludge our code or branch it.</p> <p>Data ETL is the forever bane of the LCA lone wolf.</p> <p>For simple naming changes, we can just introduce a constant mapping, detect whether it's version 1 or version 2, and use the correct one.</p> <p>Whether there's a better way to do this is something we can think intensely about as we dive into deep interoperability with OpenLCA.</p> <p>The most immediate material change is that Categories are no longer entities with UUIDs but merely forward-slash-separated strings. This is actually fine because this is much closer to our native approach. But we do need to rework the plumbing around this.</p>"},{"location":"reference/providers/openlca/openlca_jsonld/#providers.openlca.openlca_jsonld.OpenLcaJsonLdArchive","title":"<code>OpenLcaJsonLdArchive</code>","text":"<p>               Bases: <code>LcArchive</code></p> <p>Opens JSON-LD archives formatted according to the OpenLCA schema</p>"},{"location":"reference/providers/openlca/openlca_jsonld/#providers.openlca.openlca_jsonld.OpenLcaJsonLdArchive.openlca_category","title":"<code>openlca_category(name_or_full_list)</code>","text":"<p>returns an olca id for a name or a list of hierarchical names, if one exists</p> <p>Parameters:</p> Name Type Description Default <code>name_or_full_list</code> required <p>Returns:</p> Type Description <p>either a known context or raise KeyError</p>"},{"location":"reference/providers/openlca/parameters/","title":"parameters","text":""},{"location":"reference/providers/openlca/parameters/#providers.openlca.parameters.ConditionalParam","title":"<code>ConditionalParam</code>","text":"<p>               Bases: <code>object</code></p> <p>Evaluate an expression, and return a if true, b if false this is nuts--- they're even nested. ChatGPT tells me I could use simple regexes to change e.g. IF(expr1; expr2; expr3) to (expr2 if expr1 else expr3) but trying to handle nested expressions with regexp seems foolhardy.</p> <p>I mean, look at this: IF(auto_calc_wtr=1;IF(0.474454781149916-(pct_fresh_srf-0.167302119871893)(0.4744547811499161/(0.358243098978191+0.474454781149916))&gt;0.0424528301886793;0.474454781149916-(pct_fresh_srf-0.167302119871893)(0.4744547811499161/(0.358243098978191+0.474454781149916));0.0424528301886793);usr_fresh_gnd)</p>"},{"location":"reference/providers/openlca/parameters/#providers.openlca.parameters.FormulaParser","title":"<code>FormulaParser</code>","text":"<p>               Bases: <code>_Param</code></p> <p>give it a parameter spec; it will act as a dynamic calculator. 'param' api: dict with keys 'name' (str), 'value' (float), 'formula' (str with elementary operations + groups)</p>"},{"location":"reference/providers/openlca/parameters/#providers.openlca.parameters.FormulaParser.dependencies","title":"<code>dependencies</code>  <code>property</code>","text":"<p>Generates input variables that are used to calculate the parameter value</p> <p>Returns:</p> Type Description"},{"location":"reference/providers/openlca/parameters/#providers.openlca.parameters.NodeCalculator","title":"<code>NodeCalculator</code>","text":"<p>               Bases: <code>NodeTransformer</code></p> <p>substitutes constant values in for parameter names, and evaluates the expression</p>"},{"location":"reference/providers/openlca/parameters/#providers.openlca.parameters.NodeIdentifier","title":"<code>NodeIdentifier</code>","text":"<p>               Bases: <code>NodeVisitor</code></p> <p>identifies all the parameters named in an expression</p>"},{"location":"reference/providers/openlca/parameters/#providers.openlca.parameters.OlcaParameterResolver","title":"<code>OlcaParameterResolver</code>","text":"<p>               Bases: <code>object</code></p> <p>A class to handle and compute parameters in the OLCA framework. Ultimately we want to be able to represent computed parameters involving sums as balance flows (and products as child flows)</p>"},{"location":"reference/providers/openlca/parameters/#providers.openlca.parameters.OlcaParameterResolver.outputs","title":"<code>outputs</code>  <code>property</code>","text":"<pre><code>    parameters that are linked to an exchange\n</code></pre> <p>``        :return:</p>"},{"location":"reference/providers/openlca/parameters/#providers.openlca.parameters.OlcaParameterResolver.__init__","title":"<code>__init__(process_json, noisy=False, v2=True, process_ref=None)</code>","text":"<p>Supply the json object.  will:  - extract input parameters  - extract and order derived parameters  - confirm parameter values</p> <p>Parameters:</p> Name Type Description Default <code>process_json</code> required <code>noisy</code> <p>[False] print extensive debugging info</p> <code>False</code> <code>v2</code> <p>[True] whether to use the v2 schema or not</p> <code>True</code>"},{"location":"reference/providers/openlca/parameters/#providers.openlca.parameters.OlcaParameterResolver.param_unit","title":"<code>param_unit(param)</code>","text":"<p>This is inaccurate because the same param can be used for multiple exchanges regardless of their flow property. This will only capture the units applied to ONE USE of the parameter name (nondeterministically)</p> <p>Parameters:</p> Name Type Description Default <code>param</code> required <p>Returns:</p> Type Description"},{"location":"reference/providers/openlca/parameters/#providers.openlca.parameters.ParamConstant","title":"<code>ParamConstant</code>","text":"<p>               Bases: <code>_Param</code></p> <p>An input.  'param' API: dict. keys: 'name', 'value' (a float), 'unit' (an optional string)</p>"},{"location":"reference/providers/openlca/schema_mapping/","title":"schema_mapping","text":""},{"location":"reference/providers/tests/__init__/","title":"tests","text":""},{"location":"reference/providers/traci/","title":"index","text":""},{"location":"reference/providers/traci/#providers.traci.index.Traci21IndexImplementation","title":"<code>Traci21IndexImplementation</code>","text":"<p>               Bases: <code>IndexImplementation</code></p> <p>The main purpose of this is to enable iteration over elements without requiring load_all() No need to override lcia methods or quantities- since those all get initialized with the constructor-- only flowables needs to be init from scratch-- but not right now</p>"},{"location":"reference/providers/traci/__init__/","title":"init","text":""},{"location":"reference/providers/traci/q_info/","title":"q_info","text":""},{"location":"reference/providers/traci/quantity/","title":"quantity","text":""},{"location":"reference/providers/traci/traci_2_1_spreadsheet/","title":"traci_2_1_spreadsheet","text":"<p>This provider needs some work:  - the open_workbook call should not happen in the constructor, but in _load_all  - then the provider should be marked 'static'  - that would enable the init to be instantaneous, and the load to occur through normal channels in LcResource  - that would also allow the loaded result to be cached in JSON  = model: Ecoinvent LCIA</p> <p>This suggests that maybe there should be a versioned LCIA base class-- probably in the data_sources hierarchy and not the providers hierarchy though... On that topic, it is simply foolhardy to try to build a version-agnostic provider class in the ABSENCE of multiple versions (as is the case with TRACI)</p>"},{"location":"reference/providers/xdb_client/__init__/","title":"init","text":""},{"location":"reference/providers/xdb_client/implementation/","title":"implementation","text":""},{"location":"reference/providers/xdb_client/implementation/#providers.xdb_client.implementation.XdbImplementation","title":"<code>XdbImplementation</code>","text":"<p>               Bases: <code>BasicImplementation</code>, <code>IndexInterface</code>, <code>ExchangeInterface</code>, <code>QuantityInterface</code>, <code>BackgroundInterface</code></p> <p>The implementation is very thin, so pile everything into one class</p>"},{"location":"reference/providers/xdb_client/implementation/#providers.xdb_client.implementation.XdbImplementation.bg_lcia","title":"<code>bg_lcia(process, query_qty=None, ref_flow=None, **kwargs)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>process</code> required <code>query_qty</code> <code>None</code> <code>ref_flow</code> <code>None</code> <code>kwargs</code> <code>{}</code> <p>Returns:</p> Type Description"},{"location":"reference/providers/xdb_client/implementation/#providers.xdb_client.implementation.XdbImplementation.cf","title":"<code>cf(flow, quantity, ref_quantity=None, context=None, locale='GLO', **kwargs)</code>","text":"<p>We still want to retain the ability to ask the remote server for CFs, even if we may prefer to get that info locally for local flows</p> <p>Parameters:</p> Name Type Description Default <code>flow</code> required <code>quantity</code> required <code>ref_quantity</code> <p>NOT USED</p> <code>None</code> <code>context</code> <code>None</code> <code>locale</code> <code>'GLO'</code> <code>kwargs</code> <code>{}</code> <p>Returns:</p> Type Description"},{"location":"reference/providers/xdb_client/implementation/#providers.xdb_client.implementation.XdbImplementation.consumers","title":"<code>consumers(process, ref_flow=None, **kwargs)</code>","text":"<p>This returns reference exchanges for activities that consume the named reference exchange the puzzle here is how to generate the RxRefs-- I guess we should just do it here</p> <p>Parameters:</p> Name Type Description Default <code>process</code> required <code>ref_flow</code> <code>None</code> <code>kwargs</code> <code>{}</code> <p>Returns:</p> Type Description"},{"location":"reference/providers/xdb_client/implementation/#providers.xdb_client.implementation.XdbImplementation.count","title":"<code>count(entity_type, **kwargs)</code>","text":"<p>Naturally the first route is problematic- because we allow incompletely-specified origins. We should sum them.</p> <p>Parameters:</p> Name Type Description Default <code>entity_type</code> required <code>kwargs</code> <code>{}</code> <p>Returns:</p> Type Description"},{"location":"reference/providers/xdb_client/implementation/#providers.xdb_client.implementation.XdbImplementation.do_lcia","title":"<code>do_lcia(quantity, inventory, locale='GLO', **kwargs)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>quantity</code> required <code>inventory</code> required <code>locale</code> <code>'GLO'</code> <code>kwargs</code> <code>{}</code> <p>Returns:</p> Type Description"},{"location":"reference/providers/xdb_client/implementation/#providers.xdb_client.implementation.XdbImplementation.exchange_values","title":"<code>exchange_values(process, flow, direction=None, termination=None, reference=None, **kwargs)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>process</code> required <code>flow</code> required <code>direction</code> <code>None</code> <code>termination</code> <code>None</code> <code>reference</code> <code>None</code> <code>kwargs</code> <code>{}</code> <p>Returns:</p> Type Description"},{"location":"reference/providers/xdb_client/implementation/#providers.xdb_client.implementation.XdbImplementation.exchanges","title":"<code>exchanges(process, **kwargs)</code>","text":"<p>Client code (process_ref.ProcessRef) already turns them into ExchangeRefs</p> <p>Parameters:</p> Name Type Description Default <code>process</code> required <code>kwargs</code> <code>{}</code> <p>Returns:</p> Type Description"},{"location":"reference/providers/xdb_client/implementation/#providers.xdb_client.implementation.XdbImplementation.factors","title":"<code>factors(quantity, flowable=None, context=None, **kwargs)</code>","text":"<p>We need to construct operable characterizations with quantities that are recognized by the LciaEngine- in other words, with refs from our archive</p> <p>Parameters:</p> Name Type Description Default <code>quantity</code> required <code>flowable</code> <code>None</code> <code>context</code> <p>not implemented at the API</p> <code>None</code> <code>kwargs</code> <code>{}</code> <p>Returns:</p> Type Description"},{"location":"reference/providers/xdb_client/implementation/#providers.xdb_client.implementation.XdbImplementation.get_factors","title":"<code>get_factors(quantity, flow_specs, **kwargs)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>quantity</code> required <code>flow_specs</code> required <code>kwargs</code> <code>{}</code> <p>Returns:</p> Type Description"},{"location":"reference/providers/xdb_client/implementation/#providers.xdb_client.implementation.XdbImplementation.get_uuid","title":"<code>get_uuid(external_ref)</code>","text":"<p>Stopgap: don't support UUIDs</p> <p>Parameters:</p> Name Type Description Default <code>external_ref</code> required <p>Returns:</p> Type Description"},{"location":"reference/providers/xdb_client/implementation/#providers.xdb_client.implementation.XdbImplementation.inventory","title":"<code>inventory(node, ref_flow=None, scenario=None, **kwargs)</code>","text":"<p>Client code (process_ref.ProcessRef) already turns them into ExchangeRefs</p> <p>Parameters:</p> Name Type Description Default <code>node</code> required <code>ref_flow</code> <p>if node is a process, optionally provide its reference flow</p> <code>None</code> <code>scenario</code> <p>if node is a fragment, optionally provide a scenario- as string or tuple</p> <code>None</code> <code>kwargs</code> <code>{}</code> <p>Returns:</p> Type Description"},{"location":"reference/providers/xdb_client/implementation/#providers.xdb_client.implementation.XdbImplementation.quantity_relation","title":"<code>quantity_relation(flowable, ref_quantity, query_quantity, context, locale='GLO', **kwargs)</code>","text":"<p>not yet implemented</p> <p>Parameters:</p> Name Type Description Default <code>flowable</code> required <code>ref_quantity</code> required <code>query_quantity</code> required <code>context</code> required <code>locale</code> <code>'GLO'</code> <code>kwargs</code> <code>{}</code> <p>Returns:</p> Type Description"},{"location":"reference/providers/xdb_client/implementation/#providers.xdb_client.implementation.XdbImplementation.sys_lcia","title":"<code>sys_lcia(process, query_qty, observed=None, ref_flow=None, **kwargs)</code>","text":"<p>We want to override the interface implementation and send a simple request to the backend</p> <p>Parameters:</p> Name Type Description Default <code>process</code> required <code>query_qty</code> required <code>observed</code> <p>iterable of DirectedFlows</p> <code>None</code> <code>ref_flow</code> <code>None</code> <code>kwargs</code> <p>locale, quell_biogenic_co2</p> <code>{}</code> <p>Returns:</p> Type Description"},{"location":"reference/providers/xdb_client/requester/","title":"requester","text":""},{"location":"reference/providers/xdb_client/requester/#providers.xdb_client.requester.XdbRequester","title":"<code>XdbRequester</code>","text":"<p>               Bases: <code>RestClient</code></p> <p>A RestClient that encapsulates translating the HTTP responses to Pydantic models.  A token is structurally required but is still None default (will just give 401 unauthorized).  On initialization, queries API_root/origins to determine the set of origins the query knows.</p> <p>ref is optional and if supplied, the origin will be automatically prefixed to every query. Escape this behavior by using origin_x routes to supply origin explicitly. (if None, a client will be expected to specify origin in every query</p> <p>{{What is the difference between .origin and .ref? anyway? why the absurd machinations around catalog_names?    ans: something (perhaps superstitious) about provenance- it's about mapping the ref to a 'physical' source }}</p> <p>pydantic operations use specified ref as origin  -get_one  -get_many  -post_return_one  -post_return_many user supplies origin as a positional parameter  -origin_get_one  -origin_get_many  -origin_post_return_one  -origin_post_return_many</p>"},{"location":"reference/providers/xdb_client/requester/#providers.xdb_client.requester.XdbRequester.origins","title":"<code>origins</code>  <code>property</code>","text":"<p>generates OriginMeta objects obtained by the server when the token was first authenticated Returns OriginMeta data-- this should probably include config information !</p> <p>Returns:</p> Type Description"},{"location":"reference/providers/xdb_client/rest_client/","title":"rest_client","text":""},{"location":"reference/providers/xdb_client/rest_client/#providers.xdb_client.rest_client.RestClient","title":"<code>RestClient</code>","text":"<p>               Bases: <code>object</code></p> <p>A REST client that uses pydantic models to interpret response data</p>"},{"location":"reference/providers/xdb_client/rest_client/#providers.xdb_client.rest_client.RestClient.authenticate","title":"<code>authenticate(username, password=None, save_credentials=None, **kwargs)</code>","text":"<p>POSTs an OAuth2-compliant form to obtain a bearer token. Be sure to set the 'auth_route' property either in a subclass or manually (e.g. on init)</p> <p>Parameters:</p> Name Type Description Default <code>username</code> required <code>password</code> <code>None</code> <code>save_credentials</code> <p>whether to save credentials</p> <code>None</code> <code>kwargs</code> <code>{}</code> <p>Returns:</p> Type Description"},{"location":"reference/providers/xdb_client/rest_client/#providers.xdb_client.rest_client.RestClient.reauthenticate","title":"<code>reauthenticate(save_credentials=None, **kwargs)</code>","text":"<p>If we have saved credentials, pass them along. update the flag</p> <p>Parameters:</p> Name Type Description Default <code>save_credentials</code> <code>None</code> <code>kwargs</code> <code>{}</code> <p>Returns:</p> Type Description"},{"location":"reference/providers/xdb_client/rest_client/#providers.xdb_client.rest_client.RestClient.set_token","title":"<code>set_token(token)</code>","text":"<p>we accept: - a string with a plain token - a string with 'token_type token' - an OauthToken</p> <p>Parameters:</p> Name Type Description Default <code>token</code> required <p>Returns:</p> Type Description"},{"location":"reference/providers/xdb_client/xdb_client/","title":"xdb_client","text":"<p>Client for the xdb Antelope server</p> <p>The concept here is to pass received requests straight into the Pydantic models, and then use those for easy (though manual) deserialization into EntityRefs.</p>"},{"location":"reference/providers/xdb_client/xdb_client/#providers.xdb_client.xdb_client.XdbClient","title":"<code>XdbClient</code>","text":"<p>               Bases: <code>LcArchive</code></p> <p>An XdbClient accesses xdb at a named URL using an access token.</p>"},{"location":"reference/providers/xdb_client/xdb_client/#providers.xdb_client.xdb_client.XdbClient.__getitem__","title":"<code>__getitem__(item)</code>","text":"<p>For cursed reasons, our EntityStore getitem method must return None instead of raising a KeyError</p> <p>Parameters:</p> Name Type Description Default <code>item</code> required <p>Returns:</p> Type Description"},{"location":"reference/providers/xdb_client/xdb_client/#providers.xdb_client.xdb_client.XdbClient.get_or_make","title":"<code>get_or_make(model)</code>","text":"<p>Retrieve or create an entity, when we have already received its model data from the server</p> <p>Parameters:</p> Name Type Description Default <code>model</code> required <p>Returns:</p> Type Description"},{"location":"reference/providers/xdb_client/xdb_client/#providers.xdb_client.xdb_client.XdbTermManager","title":"<code>XdbTermManager</code>","text":"<p>               Bases: <code>object</code></p>"},{"location":"reference/providers/xdb_client/xdb_client/#providers.xdb_client.xdb_client.XdbTermManager.__init__","title":"<code>__init__(requester)</code>","text":"<p>The key question here: should I at least cache remote contexts? for now let us cache nothing</p> <p>Except we DO need to cache contexts, or at least create them on the fly (and if we are going to create them, we should cache them) because exterior exchanges need to terminate properly in contexts.</p> <p>SO: we will establish the condition that Xdb MUST only use contexts' canonical names, thereby escaping the need for synonym disambiguation in the client.</p> <p>Parameters:</p> Name Type Description Default <code>requester</code> <code>XdbRequester</code> required"},{"location":"reference/providers/xdb_client/xdb_client/#providers.xdb_client.xdb_client.XdbTermManager.is_context","title":"<code>is_context(item)</code>","text":"<p>The only place this is used is in collision checking- therefore this only needs to check if the name is known locally as a context (why do an http query for literally every new entity?)</p> <p>Parameters:</p> Name Type Description Default <code>item</code> required <p>Returns:</p> Type Description"},{"location":"reference/providers/xdb_client/xdb_entities/","title":"xdb_entities","text":""},{"location":"reference/providers/xdb_client/xdb_entities/#providers.xdb_client.xdb_entities.XdbEntity","title":"<code>XdbEntity</code>","text":"<p>               Bases: <code>BaseEntity</code></p>"},{"location":"reference/providers/xdb_client/xdb_entities/#providers.xdb_client.xdb_entities.XdbEntity.__init__","title":"<code>__init__(model)</code>","text":"<p>XdbEntity is an ephemeral object, basically a way of storing pydantic models PRIOR to their getting made into refs (which is done by this class's make_ref() process)</p> <p>XdbEntities are instantiated by the client on any occasion the client receives info on entities back from the remote server: in XdbClient._fetch(), and in processes() flows() quantities() and anything to do with exchanges.</p> <p>The return objects are immediately used as arguments for BasicQuery.make_ref() or CatalogQuery.make_ref(), either of which calls this class's make_ref() with the query as argument.  Then the make_ref() is responsible for constructing the fully-featured reference object that is stored in the local archive.</p> <p>Must supply the pydantic model that comes out of the query, and also the archive that stores the ref</p> <p>Parameters:</p> Name Type Description Default <code>model</code> required"},{"location":"reference/providers/xdb_client/xdb_entities/#providers.xdb_client.xdb_entities.XdbReferenceRequired","title":"<code>XdbReferenceRequired</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Straight-up entities have no capabilities</p>"},{"location":"reference/tests/__init__/","title":"tests","text":""}]}